<!DOCTYPE html>
<html lang="pt">
<head>
    <title>Busca Sem√¢ntica com Ollama e PostgreSQL | scovl</title>
    <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="Implementando busca sem√¢ntica com PostgreSQL e Ollama">


<link rel="stylesheet" href="/css/styles.css">
<link rel="stylesheet" href="/css/syntax.css">


<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.28.0/themes/prism-tomorrow.min.css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.28.0/themes/prism-dark.min.css">
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.28.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.28.0/components/prism-clojure.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.28.0/components/prism-sql.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.28.0/components/prism-typescript.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.28.0/components/prism-javascript.min.js"></script>





<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.css">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.js"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/contrib/auto-render.min.js"></script>

<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
            delimiters: [
                {left: '$$', right: '$$', display: true},
                {left: '$', right: '$', display: false},
                {left: '\\(', right: '\\)', display: false},
                {left: '\\[', right: '\\]', display: true}
            ]
        });
    });
</script>



<script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
<script>
    document.addEventListener("DOMContentLoaded", function() {
        mermaid.initialize({
            startOnLoad: true,
            theme: 'light',
            align: 'center'
        });
    });
</script>
 
</head>
<body>
    <div class="container">
        
        
        <header class="site-header">
    <div class="header-inner">
        <div class="site-branding">
            <a href="https://scovl.github.io/" class="site-title">scovl</a>
        </div>
        
        <nav class="site-nav">
            <ul>
                
                
                <li>
                    <a href="/page/about/" class="">
                        About
                    </a>
                </li>
                
                <li>
                    <a href="/page/contact/" class="">
                        Contact
                    </a>
                </li>
                
            </ul>
        </nav>
    </div>
</header> 
        
        
        
        <main>
            
<article class="post">
    <header class="post-header">
        <h1 class="post-title">Busca Sem√¢ntica com Ollama e PostgreSQL</h1>
        <div class="post-meta">
            
            <time datetime="2025-03-25T12:00:00Z">
                Tue, Mar 25, 2025
            </time>
            
            
            
            <span class="post-author">por Vitor Lobo Ramos</span>
            
            
            
            <div class="post-tags">
                
                <a href="/tags/rag/" class="tag">RAG</a>
                
                <a href="/tags/postgresql/" class="tag">PostgreSQL</a>
                
                <a href="/tags/pgvector/" class="tag">pgvector</a>
                
                <a href="/tags/pgai/" class="tag">pgai</a>
                
                <a href="/tags/ollama/" class="tag">Ollama</a>
                
                <a href="/tags/semantic-search/" class="tag">Semantic Search</a>
                
            </div>
            
            
            
            <div class="reading-time">
                Estimated reading time: 18 min
            </div>
            
            
            
            <div class="post-description">
                Implementando busca sem√¢ntica com PostgreSQL e Ollama
            </div>
            
        </div>
    </header>
    
    <div class="post-content content-wrapper">
        <h1 id="sum√°rio">Sum√°rio</h1>
<ul>
<li><strong><a href="/2025/03/25/semantic-postgresql/#introdu%c3%a7%c3%a3o">Introdu√ß√£o</a></strong></li>
<li><strong><a href="/2025/03/25/semantic-postgresql/#entendendo-a-arquitetura">Entendendo a Arquitetura</a></strong></li>
<li><strong><a href="/2025/03/25/semantic-postgresql/#pr%c3%a9-requisitos">Pr√©-requisitos</a></strong></li>
<li><strong><a href="/2025/03/25/semantic-postgresql/#passos-para-construir-a-busca-sem%c3%a2ntica">Passos para Construir a Busca Sem√¢ntica</a></strong>
<ul>
<li><a href="/2025/03/25/semantic-postgresql/#1-habilitando-as-extens%c3%b5es">1. Habilitando as Extens√µes</a></li>
<li><a href="/2025/03/25/semantic-postgresql/#2-criando-a-tabela-de-documentos">2. Criando a Tabela de Documentos</a></li>
<li><a href="/2025/03/25/semantic-postgresql/#3-inserindo-documentos">3. Inserindo Documentos</a></li>
<li><a href="/2025/03/25/semantic-postgresql/#4-configurando-o-vectorizer">4. Configurando o Vectorizer</a></li>
<li><a href="/2025/03/25/semantic-postgresql/#5-realizando-busca-sem%c3%a2ntica">5. Realizando Busca Sem√¢ntica</a></li>
</ul>
</li>
<li><strong><a href="/2025/03/25/semantic-postgresql/#integra%c3%a7%c3%a3o-com-clojure">Integra√ß√£o com Clojure</a></strong></li>
<li><strong><a href="/2025/03/25/semantic-postgresql/#persist%c3%aancia-de-modelos-entre-reinicializa%c3%a7%c3%b5es">Persist√™ncia de Modelos entre Reinicializa√ß√µes</a></strong></li>
<li><strong><a href="/2025/03/25/semantic-postgresql/#conclus%c3%a3o">Conclus√£o</a></strong></li>
</ul>
<h2 id="introdu√ß√£o">Introdu√ß√£o</h2>
<p>Ol√°, pessoal! üëã</p>
<p>No <a href="/2025/03/23/rag/">artigo anterior</a>, exploramos como construir um sistema RAG (Retrieval-Augmented Generation) usando <a href="https://clojure.org/">Clojure</a> e <a href="https://ollama.com/">Ollama</a> com uma implementa√ß√£o simples de <a href="/post/tf-idf/">TF-IDF</a>. Embora essa abordagem seja excelente para aprender os fundamentos, quando pensamos em solu√ß√µes de produ√ß√£o, precisamos de algo mais robusto e escal√°vel.</p>
<p>Neste artigo, vamos descobrir como construir um sistema de busca sem√¢ntica poderoso usando <a href="https://ollama.com/">Ollama</a>, <a href="https://www.postgresql.org/">PostgreSQL</a> e suas extens√µes para manipula√ß√£o de vetores. Esta solu√ß√£o √© perfeitamente adequada para aplica√ß√µes de produ√ß√£o e pode servir como base para sistemas RAG, agentes de IA, assistentes em geral. Diferentemente do artigo anterior, vamos usar o <a href="https://ollama.com/">Ollama</a> via Docker assim como o <a href="https://www.postgresql.org/">PostgreSQL</a> e as extens√µes <a href="https://github.com/pgvector/pgvector">pgvector</a> e <a href="https://github.com/timescale/pgai">pgai</a>.</p>
<p>A combina√ß√£o do <a href="https://www.postgresql.org/">PostgreSQL</a> com extens√µes como <a href="https://github.com/pgvector/pgvector">pgvector</a> e <a href="https://github.com/timescale/pgai">pgai</a>, junto com o <a href="https://ollama.com/">Ollama</a> (que permite executar modelos de linguagem localmente), cria uma solu√ß√£o completa e de alto desempenho para <a href="https://en.wikipedia.org/wiki/Semantic_search">processamento sem√¢ntico de dados</a>.</p>
<h2 id="entendendo-a-arquitetura">Entendendo a Arquitetura</h2>
<p>A busca sem√¢ntica vai al√©m da simples correspond√™ncia de palavras-chave, capturando o significado e o contexto da sua consulta. Em vez de depender apenas de correspond√™ncias exatas, ela utiliza <a href="https://en.wikipedia.org/wiki/Embedding_%28machine_learning%29">embeddings vetoriais</a> para representar o conte√∫do sem√¢ntico do texto (ou qualquer dado n√£o estruturado). Essa abordagem permite que seu sistema recupere resultados contextualmente relevantes, mesmo quando as palavras-chave exatas n√£o est√£o presentes.</p>
<p>Por exemplo, se voc√™ pesquisar por &ldquo;melhores lugares para comer&rdquo;, um <a href="https://en.wikipedia.org/wiki/Semantic_search">sistema de busca sem√¢ntica</a> pode recuperar documentos sobre &ldquo;restaurantes bem avaliados nas proximidades&rdquo; ou &ldquo;experi√™ncias gastron√¥micas altamente recomendadas&rdquo;, efetivamente capturando sua inten√ß√£o em vez da formula√ß√£o exata. A arquitetura para busca sem√¢ntica com PostgreSQL envolve quatro componentes principais:</p>


  
    
  
  <div class="mermaid">flowchart LR
    A[Ollama] --&gt; B[pgai]
    B --&gt; C[pgvector]
    C --&gt; D[PostgreSQL]
    
    style A fill:#f9f,stroke:#333,stroke-width:2px
    style D fill:#9ff,stroke:#333,stroke-width:2px</div>
 <ul>
<li><a href="https://ollama.com/"><strong>Ollama</strong></a>: Ferramenta open-source que permite executar e gerenciar modelos de linguagem de grande escala (LLMs) e modelos de vis√£o (VLMs) localmente no seu computador ou em um servidor cloud, proporcionando maior privacidade e controle sobre os dados.</li>
<li><a href="https://github.com/timescale/pgai"><strong>pgai</strong></a>: Extens√£o do PostgreSQL que simplifica o armazenamento e recupera√ß√£o de dados para RAG e outras aplica√ß√µes de IA, automatizando a cria√ß√£o e gest√£o de embeddings, facilitando a busca sem√¢ntica e permitindo a execu√ß√£o de fun√ß√µes de LLM diretamente dentro de consultas SQL.</li>
<li><a href="https://github.com/pgvector/pgvector"><strong>pgvector</strong></a>: Extens√£o do PostgreSQL que adiciona suporte para armazenar, indexar e consultar embeddings vetoriais de alta dimensionalidade.</li>
<li><a href="https://www.postgresql.org/"><strong>PostgreSQL</strong></a>: O sistema de banco de dados relacional que serve como funda√ß√£o robusta e escal√°vel para todo o sistema.</li>
</ul>
<hr>
<h2 id="pr√©-requisitos">Pr√©-requisitos</h2>
<p>Antes de come√ßar, precisamos garantir que voc√™ tenha:</p>
<ol>
<li><strong>Docker e Docker Compose</strong>: Para configurar o ambiente facilmente</li>
<li><strong>PostgreSQL com pgvector e pgai</strong>: Para armazenar e consultar embeddings</li>
</ol>
<blockquote>
<p><strong>NOTA</strong>: No artigo anterior sobre <a href="/2025/03/23/rag/">RAG em Clojure</a>, usamos o <a href="https://ollama.com/">Ollama</a> com <a href="https://ollama.com/models/deepseek-r1">DeepSeek R1</a> baixando o projeto ollama diretamente na m√°quina. Nesta abordagem, vamos usar o Ollama via Docker. Portanto, recomendo que voc√™ feche o Ollama para usar-mos ele inteiramente via Docker aqui nesta abordagem (√© necess√°rio fechar para n√£o conflitar com o endpoint do Ollama que vamos usar no Docker Compose).</p></blockquote>
<p>Vamos configurar tudo isso rapidamente usando Docker Compose:</p>


  <pre><code class="language-bash">name: pgai
services:
  db:
    image: timescale/timescaledb-ha:pg17
    environment:
      POSTGRES_PASSWORD: postgres
      # Definir vari√°veis de ambiente para o host do Ollama
      OLLAMA_HOST: http://ollama:11434
    ports:
      - &#34;5432:5432&#34;
    volumes:
      - data:/home/postgres/pgdata/data
    # N√£o use a extens√£o ai at√© garantir que est√° instalada corretamente
    command: &#34;-c search_path=public&#34;
    depends_on:
      - ollama
    # Adicionar links expl√≠citos para o servi√ßo Ollama
    links:
      - ollama

  vectorizer-worker:
    image: timescale/pgai-vectorizer-worker:latest
    environment:
      PGAI_VECTORIZER_WORKER_DB_URL: postgres://postgres:postgres@db:5432/postgres
      OLLAMA_HOST: http://ollama:11434
    command: [ &#34;--poll-interval&#34;, &#34;5s&#34;, &#34;--log-level&#34;, &#34;DEBUG&#34; ]
    depends_on:
      - db
      - ollama
    links:
      - ollama

  ollama:
    image: ollama/ollama
    ports:
      - &#34;11434:11434&#34;
    volumes:
      - ollama_data:/root/.ollama
    # Comando direto para iniciar o Ollama
    command: serve

volumes:
  data:
  ollama_data: </code></pre>
 <p>O arquivo <code>docker-compose.yml</code> acima configura uma infraestrutura para busca sem√¢ntica com tr√™s servi√ßos interconectados. O servi√ßo <code>db</code> utiliza o <a href="https://www.timescale.com/">TimescaleDB</a> (que nada mais √© que uma vers√£o do <a href="https://www.postgresql.org/">PostgreSQL</a> especializada para otimiza√ß√£o de desempenho para dados de s√©ries temporais) com a vers√£o 17, configurando credenciais, mapeamento de portas e um volume persistente para armazenar os dados. Este servi√ßo √© configurado para se comunicar com o Ollama atrav√©s de vari√°veis de ambiente e links expl√≠citos, garantindo que a comunica√ß√£o entre os cont√™ineres funcione corretamente.</p>


  
  <div class="mermaid">flowchart TD
    subgraph db [&#34;TimescaleDB (pg17)&#34;]
        db_info[&#34;Ports: 5432:5432&lt;br&gt;Volumes: data:/home/postgres/pgdata/data&lt;br&gt;Environment:&lt;br&gt;POSTGRES_PASSWORD=postgres&lt;br&gt;OLLAMA_HOST=http://ollama:11434&#34;]
    end

    subgraph vectorizer_worker [&#34;pgai-vectorizer-worker&#34;]
        vw_info[&#34;Environment:&lt;br&gt;PGAI_VECTORIZER_WORKER_DB_URL=postgres://postgres:postgres@db:5432/postgres&lt;br&gt;OLLAMA_HOST=http://ollama:11434&lt;br&gt;Command: --poll-interval 5s --log-level DEBUG&#34;]
    end

    subgraph ollama [&#34;Ollama&#34;]
        o_info[&#34;Ports: 11434:11434&lt;br&gt;Volumes: ollama_data:/root/.ollama&lt;br&gt;Command: serve&#34;]
    end

    data[&#34;Data Volume&#34;]
    ollama_data[&#34;Ollama Data Volume&#34;]

    db --- data
    ollama --- ollama_data
    vectorizer_worker --- db
    vectorizer_worker --- ollama
    db --- ollama

    style db fill:#f9f,stroke:#333,stroke-width:2px
    style vectorizer_worker fill:#ccf,stroke:#333,stroke-width:2px
    style ollama fill:#ffc,stroke:#333,stroke-width:2px
    style data fill:#eee,stroke:#333,stroke-width:2px
    style ollama_data fill:#eee,stroke:#333,stroke-width:2px</div>
 <p>O diagrama acima ilustra a arquitetura do sistema de busca sem√¢ntica com PostgreSQL. No centro, temos tr√™s componentes principais: o TimescaleDB (uma vers√£o especializada do PostgreSQL), o pgai-vectorizer-worker (respons√°vel por processar e vetorizar os textos) e o Ollama (que fornece os modelos de IA). As conex√µes entre os servi√ßos mostram como eles se comunicam: o vectorizer-worker se conecta tanto ao banco de dados quanto ao Ollama para realizar seu trabalho de transforma√ß√£o de textos em vetores.</p>
<p>Os volumes persistentes (representados em cinza) garantem que tanto os dados do PostgreSQL quanto os modelos do Ollama sejam preservados entre reinicializa√ß√µes. Esta arquitetura modular permite escalar cada componente independentemente conforme necess√°rio, enquanto mant√©m um fluxo de dados eficiente para opera√ß√µes de busca sem√¢ntica.</p>
<p>O servi√ßo <code>vectorizer-worker</code> √© um componente especializado do <a href="https://github.com/timescale/pgai">pgai</a> que monitora o banco de dados a cada 5 segundos, processando automaticamente textos para transform√°-los em embeddings vetoriais. Ele se conecta ao banco <a href="https://www.postgresql.org/">PostgreSQL</a> e ao servi√ßo <a href="https://ollama.com/">Ollama</a> para realizar a vetoriza√ß√£o dos textos, funcionando como uma ponte entre o armazenamento de dados e o modelo de IA, com logs detalhados para facilitar a depura√ß√£o durante o desenvolvimento.</p>
<p>Por fim, o servi√ßo <code>ollama</code> fornece a infraestrutura para executar modelos de IA localmente, expondo uma API REST na porta 11434 e armazenando os modelos baixados em um volume persistente. Este design de tr√™s camadas (banco de dados, processador de vetores e motor de IA) cria um sistema completo para busca sem√¢ntica que pode ser iniciado com um simples <code>docker compose up -d</code>, seguido pelo download do modelo de <a href="https://en.wikipedia.org/wiki/Embedding_%28machine_learning%29">embeddings</a> que transformar√° os textos em vetores.</p>


  <pre><code class="language-bash">docker compose exec ollama ollama pull nomic-embed-text</code></pre>
 <p>Este setup configura um banco de dados PostgreSQL com as extens√µes <a href="https://github.com/timescale/pgai">pgai</a>, <a href="https://github.com/pgvector/pgvector">pgvector</a> e <a href="https://github.com/timescale/pgvectorscale">pgvectorscale</a>. Tamb√©m configura o Ollama, que voc√™ pode usar para implantar LLMs e modelos de embedding.</p>
<hr>
<h2 id="passos-para-construir-a-busca-sem√¢ntica">Passos para Construir a Busca Sem√¢ntica</h2>
<p>Os passos para implementar a busca sem√¢ntica no PostgreSQL s√£o relativamente simples. Primeiro, vamos habilitar as extens√µes necess√°rias, criar uma tabela para armazenar nossos documentos, configurar o <a href="https://github.com/timescale/pgai/tree/main/vectorizer">vectorizer</a> para gerar <a href="https://en.wikipedia.org/wiki/Embedding_%28machine_learning%29">embeddings</a> automaticamente e, finalmente, realizar consultas sem√¢nticas.</p>
<h3 id="1-habilitando-as-extens√µes">1. Habilitando as Extens√µes</h3>
<p>Primeiro, precisamos habilitar as extens√µes necess√°rias no PostgreSQL:</p>


  <pre><code class="language-sql">CREATE EXTENSION IF NOT EXISTS vector CASCADE; 
CREATE EXTENSION IF NOT EXISTS ai CASCADE;</code></pre>
 <h3 id="2-criando-a-tabela-de-documentos">2. Criando a Tabela de Documentos</h3>
<p>Agora, vamos criar uma tabela para armazenar os documentos que queremos pesquisar:</p>


  <pre><code class="language-sql">CREATE TABLE IF NOT EXISTS documentos (
   id SERIAL PRIMARY KEY,
   titulo TEXT NOT NULL,
   conteudo TEXT,
   categoria TEXT,
   data_criacao TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);</code></pre>
 <p>Neste exemplo, criamos uma tabela chamada <code>documentos</code> com quatro colunas: <code>id</code>, <code>titulo</code>, <code>conteudo</code> e <code>categoria</code>. √â importante notar que a coluna <code>id</code> √© a chave prim√°ria da tabela. Outro ponto importante √© que a coluna <code>data_criacao</code> √© uma coluna de metadados que √© gerada automaticamente pelo PostgreSQL.</p>
<h3 id="3-inserindo-documentos">3. Inserindo Documentos</h3>
<p>Podemos inserir documentos manualmente ou usar a fun√ß√£o <code>ai.load_dataset</code> do <a href="https://github.com/timescale/pgai">pgai</a> para carregar dados diretamente do <a href="https://huggingface.co/">Hugging Face</a>:</p>


  <pre><code class="language-sql">SELECT ai.load_dataset(
   name =&gt; &#39;Cohere/movies&#39;,
   table_name =&gt; &#39;documentos&#39;,
   if_table_exists =&gt; &#39;append&#39;,
   field_types =&gt; &#39;{&#34;title&#34;: &#34;titulo&#34;, &#34;overview&#34;: &#34;conteudo&#34;, &#34;genres&#34;: &#34;categoria&#34;}&#39;::jsonb
);</code></pre>
 <p>Alternativamente, podemos inserir registros manualmente:</p>


  <pre><code class="language-sql">INSERT INTO documentos (titulo, conteudo, categoria) VALUES 
(&#39;Guia Clojure&#39;, &#39;Clojure √© uma linguagem funcional moderna...&#39;, &#39;Programa√ß√£o&#39;),
(&#39;Tutorial RAG&#39;, &#39;Sistemas RAG combinam busca e gera√ß√£o...&#39;, &#39;IA&#39;),
(&#39;PostgreSQL Avan√ßado&#39;, &#39;T√©cnicas de otimiza√ß√£o para PostgreSQL...&#39;, &#39;Banco de Dados&#39;);</code></pre>
 <blockquote>
<p><strong>NOTA</strong>: O <a href="https://huggingface.co/">Hugging Face</a> √© uma plataforma de dados e modelos de IA.</p></blockquote>
<p>Agora vamos configurar o vectorizer para gerar embeddings automaticamente.</p>
<h3 id="4-configurando-o-vectorizer">4. Configurando o Vectorizer</h3>
<p>O <a href="https://github.com/timescale/pgai">pgai</a> inclui uma ferramenta chamada <a href="https://github.com/timescale/pgai/tree/main/vectorizer">vectorizer</a> que automatiza a cria√ß√£o e sincroniza√ß√£o de embeddings. Esta √© uma das funcionalidades mais poderosas desta solu√ß√£o, pois elimina a necessidade de ferramentas externas para criar <a href="https://en.wikipedia.org/wiki/Embedding_%28machine_learning%29">embeddings</a>. Vamos configur√°-la:</p>


  <pre><code class="language-sql">SELECT ai.create_vectorizer(
   &#39;public.documentos&#39;::regclass,
   destination =&gt; &#39;documentos_embeddings&#39;,
   embedding =&gt; ai.embedding_ollama(&#39;nomic-embed-text&#39;, 768),
   chunking =&gt; ai.chunking_recursive_character_text_splitter(&#39;conteudo&#39;)
);</code></pre>
 <p>Basicamente, o comando acima faz o seguinte:</p>
<ol>
<li>Cria uma tabela <code>documentos_embeddings</code> para armazenar os vetores</li>
<li>Configura o modelo <code>nomic-embed-text</code> via Ollama para gerar embeddings</li>
<li>Define uma estrat√©gia de chunking para dividir textos longos</li>
<li>Cria automaticamente uma view <code>documentos_embeddings_vectorized</code> que junta os documentos com seus embeddings</li>
</ol>
<p>O <a href="https://github.com/timescale/pgai/tree/main/vectorizer">vectorizer</a> tamb√©m cuida da sincroniza√ß√£o autom√°tica dos embeddings quando documentos s√£o inseridos, atualizados ou removidos - sem necessidade de c√≥digo adicional! Isto simplifica enormemente a manuten√ß√£o do sistema.</p>
<h3 id="5-realizando-busca-sem√¢ntica">5. Realizando Busca Sem√¢ntica</h3>
<p>Agora estamos prontos para realizar buscas sem√¢nticas. Usaremos a fun√ß√£o <code>ai.ollama_embed</code> para gerar embeddings para nossa consulta e o operador de dist√¢ncia de cosseno (<code>&lt;=&gt;</code>) para encontrar documentos similares:</p>


  <pre><code class="language-sql">WITH query_embedding AS (
    -- Gerar embedding para a consulta
    SELECT ai.ollama_embed(&#39;nomic-embed-text&#39;, &#39;Como implementar RAG em sistemas modernos&#39;, 
                          host =&gt; &#39;http://ollama:11434&#39;) AS embedding
)
SELECT
    d.titulo,
    d.conteudo,
    d.categoria,
    t.embedding &lt;=&gt; (SELECT embedding FROM query_embedding) AS distancia
FROM documentos_embeddings t
LEFT JOIN documentos d ON t.id = d.id
ORDER BY distancia
LIMIT 5;</code></pre>
 <p>Este c√≥digo SQL realiza uma <a href="https://en.wikipedia.org/wiki/Semantic_search">busca sem√¢ntica</a> em nossa base de documentos utilizando <a href="https://en.wikipedia.org/wiki/Embedding_%28machine_learning%29">embeddings</a> gerados pelo modelo <code>nomic-embed-text</code> atrav√©s do <a href="https://ollama.com/">Ollama</a>. Primeiro, criamos uma CTE (Common Table Expression) chamada <code>query_embedding</code> que gera o embedding para nossa consulta &ldquo;Como implementar RAG em sistemas modernos&rdquo;. Em seguida, selecionamos os documentos mais relevantes comparando este embedding de consulta com os embeddings armazenados na tabela <code>documentos_embeddings</code> usando o operador de dist√¢ncia de cosseno (<code>&lt;=&gt;</code>).</p>
<p>O resultado √© uma lista ordenada dos documentos mais semanticamente similares √† nossa consulta, independentemente de compartilharem as mesmas palavras exatas. Esta √© a ess√™ncia da busca sem√¢ntica - encontrar conte√∫do conceitualmente relacionado, n√£o apenas correspond√™ncias de palavras-chave. A coluna <code>distancia</code> nos mostra qu√£o pr√≥ximo cada documento est√° da nossa consulta, com valores menores indicando maior similaridade. Limitamos os resultados aos 5 documentos mais relevantes, mas este n√∫mero pode ser ajustado conforme necess√°rio. O PostgreSQL oferece tr√™s operadores para c√°lculo de similaridade:</p>
<ul>
<li><code>&lt;-&gt;</code>: <a href="https://en.wikipedia.org/wiki/Euclidean_distance">Dist√¢ncia L2 (Euclidiana)</a></li>
<li><code>&lt;#&gt;</code>: <a href="https://en.wikipedia.org/wiki/Dot_product">Produto interno</a></li>
<li><code>&lt;=&gt;</code>: <a href="https://en.wikipedia.org/wiki/Cosine_distance">Dist√¢ncia de cosseno</a> (geralmente a melhor op√ß√£o)</li>
</ul>
<p>E pronto! Com apenas esses poucos passos, temos um sistema de busca sem√¢ntica totalmente funcional, diretamente no PostgreSQL. <strong><a href="/2025/03/23/rag/">Para quem acompanhou o artigo anterior sobre a implementa√ß√£o de RAG em Clojure</a></strong>, vale a pena comparar as duas abordagens:</p>
<p>A diferen√ßa entre as duas abordagens √© bem clara quando olhamos lado a lado. <a href="/2025/03/23/rag/">No artigo anterior sobre RAG em Clojure</a>, usamos uma t√©cnica mais simples <a href="/post/tf-idf/">(TF-IDF)</a> que funciona bem para projetos pequenos e did√°ticos. √â como usar uma bicicleta para se locomover para dist√¢ncias curtas. O c√≥digo em Clojure mant√©m tudo em mem√≥ria, o que √© √≥timo para aprender os conceitos, mas come√ßa a dar problema quando a quantidade de documentos cresce.</p>
<p>J√° a abordagem com PostgreSQL + pgai √© como trocar a bicicleta por um carro esportivo! Estamos usando embeddings densos gerados por LLMs, que capturam muito melhor o significado sem√¢ntico dos textos. O PostgreSQL cuida de toda a parte chata de persist√™ncia e indexa√ß√£o, permitindo que voc√™ escale para milh√µes de documentos sem suar. Os √≠ndices especializados para vetores (como HNSW) fazem buscas em bilh√µes de embeddings parecerem instant√¢neas, algo que nossa implementa√ß√£o anterior jamais conseguiria.</p>
<p>O mais legal √© que a manuten√ß√£o fica muito mais simples. Com o <a href="https://github.com/timescale/pgai/tree/main/vectorizer">vectorizer do pgai</a>, voc√™ s√≥ precisa inserir documentos no banco normalmente, e ele cuida automaticamente de gerar e atualizar os embeddings.</p>
<hr>
<h2 id="integra√ß√£o-com-clojure">Integra√ß√£o com Clojure</h2>
<p>O objetivo deste artigo √© mostrar como √© f√°cil construir um sistema de busca sem√¢ntica usando PostgreSQL e pgai. No entanto, √© mostrar tamb√©m como podemos evoluir √† proposta anterior e construir um sistema de busca sem√¢ntica mais robusto e escal√°vel usando PostgreSQL e pgai e Clojure.</p>


  <pre><code class="language-clojure">;; src/docai/pg.clj
(ns docai.pg
  (:require [next.jdbc :as jdbc]
            [clojure.data.json :as json]))

(def db-spec
  {:dbtype &#34;postgresql&#34;
   :dbname &#34;postgres&#34;
   :host &#34;localhost&#34;
   :user &#34;postgres&#34;
   :password &#34;password&#34;})

(defn query-semantic-search
  &#34;Realiza busca sem√¢ntica via PostgreSQL&#34;
  [query limit]
  (let [conn (jdbc/get-connection db-spec)
        sql (str &#34;WITH query_embedding AS (&#34;
                 &#34;  SELECT ai.ollama_embed(&#39;nomic-embed-text&#39;, ?, host =&gt; &#39;http://ollama:11434&#39;) AS embedding&#34;
                 &#34;)&#34;
                 &#34;SELECT&#34;
                 &#34;  d.titulo,&#34;
                 &#34;  d.conteudo,&#34;
                 &#34;  d.categoria,&#34;
                 &#34;  t.embedding &lt;=&gt; (SELECT embedding FROM query_embedding) AS distancia&#34;
                 &#34; FROM documentos_embeddings t&#34;
                 &#34; LEFT JOIN documentos d ON t.id = d.id&#34;
                 &#34; ORDER BY distancia&#34;
                 &#34; LIMIT ?&#34;)
        results (jdbc/execute! conn [sql query limit])]
    results))</code></pre>
 <blockquote>
<p><strong>NOTA</strong>: O c√≥digo acima √© um exemplo de como integrar a busca sem√¢ntica no PostgreSQL com uma aplica√ß√£o Clojure. O c√≥digo completo est√° dispon√≠vel no <a href="https://github.com/scovl/docai">https://github.com/scovl/docai</a>.</p></blockquote>
<h2 id="configura√ß√£o-de-cont√™ineres-e-resolu√ß√£o-de-problemas">Configura√ß√£o de Cont√™ineres e Resolu√ß√£o de Problemas</h2>
<p>Ao trabalhar com cont√™ineres Docker ou Podman, voc√™ pode encontrar alguns desafios espec√≠ficos relacionados √† comunica√ß√£o entre servi√ßos. Vamos explorar algumas dicas para garantir que sua configura√ß√£o funcione sem problemas:</p>
<h3 id="nomea√ß√£o-de-cont√™ineres-e-comunica√ß√£o-entre-servi√ßos">Nomea√ß√£o de Cont√™ineres e Comunica√ß√£o entre Servi√ßos</h3>
<p>Quando os servi√ßos est√£o em cont√™ineres separados, a comunica√ß√£o entre eles pode ser complicada. Existem v√°rias maneiras de referenciar um cont√™iner a partir de outro:</p>


  <pre><code class="language-clojure">;; Exemplo de diferentes URLs para alcan√ßar o servi√ßo Ollama
(def alternative-hosts 
  [&#34;http://pgai-ollama-1:11434&#34;    ;; Nome do cont√™iner espec√≠fico (mais confi√°vel)
   &#34;http://ollama:11434&#34;           ;; Nome do servi√ßo (conforme definido no arquivo docker/podman-compose)
   &#34;http://172.18.0.2:11434&#34;       ;; IP do cont√™iner (pode mudar entre reinicializa√ß√µes)
   &#34;http://host.docker.internal:11434&#34; ;; Especial para acessar o host a partir do cont√™iner
   &#34;http://localhost:11434&#34;])      ;; Funciona apenas se mapeado para a porta do host</code></pre>
 <p>O m√©todo mais confi√°vel √© usar o nome exato do cont√™iner (algo como <code>pgai-ollama-1</code>), que pode ser descoberto com o comando <code>docker ps</code> ou <code>podman ps</code>.</p>
<h3 id="solu√ß√£o-de-problemas-de-conex√£o">Solu√ß√£o de Problemas de Conex√£o</h3>
<p>Se voc√™ estiver enfrentando problemas de conex√£o, uma abordagem robusta √© implementar um sistema de fallback que tente diferentes URLs:</p>


  <pre><code class="language-clojure">(defn call-ollama-api
  &#34;Chama a API do Ollama com m√∫ltiplas tentativas de conex√£o&#34;
  [prompt]
  (let [primary-url &#34;http://ollama:11434/api/generate&#34;
        options {:headers {&#34;Content-Type&#34; &#34;application/json&#34;}
                 :body (json/write-str {:model &#34;deepseek-r1&#34;
                                       :prompt prompt})}
        
        ;; Tentar primeiro com a URL prim√°ria
        primary-result (try-single-url primary-url options)]
    
    (if (:success primary-result)
      (:result primary-result)
      (do
        (println &#34;‚ö†Ô∏è Erro na chamada prim√°ria, tentando URLs alternativas...&#34;)
        
        ;; Tentar URLs alternativas
        (let [alternative-hosts [&#34;http://pgai-ollama-1:11434&#34; 
                                &#34;http://172.18.0.2:11434&#34; 
                                &#34;http://host.docker.internal:11434&#34; 
                                &#34;http://localhost:11434&#34;]
              successful-result (some (fn [host]
                                       (let [alt-url (str host &#34;/api/generate&#34;)
                                             result (try-single-url alt-url options)]
                                         (when (:success result)
                                           (println &#34;‚úÖ Conex√£o bem-sucedida com&#34; alt-url)
                                           (:result result))))
                                     alternative-hosts)]
          (or successful-result
              (str &#34;N√£o foi poss√≠vel conectar ao Ollama usando nenhum dos endpoints dispon√≠veis.&#34;)))))))</code></pre>
 <p>Esta abordagem tenta v√°rios endpoints diferentes e usa o primeiro que funcionar. A fun√ß√£o <code>call-ollama-api</code> primeiro tenta se conectar a uma URL prim√°ria e, caso falhe, percorre uma lista de URLs alternativas at√© encontrar uma conex√£o bem-sucedida. Para cada tentativa, ela utiliza a fun√ß√£o auxiliar <code>try-single-url</code> que encapsula a l√≥gica de tratamento de erros.</p>
<p>A implementa√ß√£o segue um padr√£o de fallback, onde a fun√ß√£o retorna o resultado da primeira conex√£o bem-sucedida ou uma mensagem de erro caso todas as tentativas falhem. Este m√©todo √© particularmente √∫til em ambientes containerizados, onde os endere√ßos de rede podem variar dependendo da configura√ß√£o do <a href="https://www.docker.com/">Docker</a> ou <a href="https://podman.io/">Podman</a> e da rede interna, garantindo maior resili√™ncia √† aplica√ß√£o.</p>
<p>Acessando <a href="https://github.com/scovl/docai">https://github.com/scovl/docai</a>, voc√™ pode ver o c√≥digo completo e testar a aplica√ß√£o. Ao executar por exemplo <code>./run.bat postgres</code> temos o seguinte output:</p>


  <pre><code class="language-bash">Inicializando DocAI...
Modo PostgreSQL ativado!
‚ÑπÔ∏è Para usar o Ollama, certifique-se de que ele est√° em execu√ß√£o com o comando: ollama serve
‚ÑπÔ∏è Usando o modelo deepseek-r1. Se voc√™ ainda n√£o o baixou, execute: ollama pull deepseek-r1
Configurando ambiente PostgreSQL para RAG...
‚úÖ Configurado para usar Ollama dentro do cont√™iner Docker/Podman
üöÄ Configurando PostgreSQL para RAG...
‚úÖ Extens√µes vector e ai habilitadas com sucesso
‚úÖ Tabela de documentos criada com sucesso
‚úÖ Configurado para usar Ollama dentro do cont√™iner Docker/Podman
‚úÖ Vectorizer j√° configurado (tabela documentos_embeddings j√° existe)
Importando documentos para o PostgreSQL...
‚úÖ Documento inserido com ID: 5
‚úÖ Arquivo importado com sucesso: resources\docs\example.md
PostgreSQL RAG pronto! Fa√ßa sua pergunta:
Como implementar JWT em Clojure?
Processando...
DEBUG - Processando query no PostgreSQL: Como implementar JWT em Clojure?
DEBUG - Detectada consulta relacionada a JWT, usando busca especial
DEBUG - Encontrados 5 documentos relacionados a JWT
DEBUG - Enviando prompt para o Ollama usando o modelo deepseek-r1
DEBUG - Tamanho do prompt ap√≥s truncamento: 4442 caracteres
DEBUG - Usando URL do Ollama: http://ollama:11434/api/generate
‚ö†Ô∏è Erro na chamada prim√°ria: Erro ao chamar a API do Ollama:  - 
üîÑ Tentando URLs alternativas...
üîÑ Tentando conectar ao Ollama em http://pgai-ollama-1:11434/api/generate
‚ö†Ô∏è Erro ao chamar a API do Ollama:  Erro ao chamar a API do Ollama:  - 
üîÑ Tentando conectar ao Ollama em http://172.18.0.2:11434/api/generate
‚ö†Ô∏è Erro ao chamar a API do Ollama:  Erro ao chamar a API do Ollama:  - 
üîÑ Tentando conectar ao Ollama em http://host.docker.internal:11434/api/generate
‚ö†Ô∏è Erro ao chamar a API do Ollama:  Erro ao chamar a API do Ollama:  - 
üîÑ Tentando conectar ao Ollama em http://localhost:11434/api/generate
‚úÖ Conex√£o bem-sucedida com http://localhost:11434/api/generate
&lt;think&gt;
Primeiro, preciso entender como a implementa√ß√£o de JWT em Clojure est√° relacionada com a integra√ß√£o do Ollama. Sabemos que o documento aborda a cria√ß√£o de tokens JWT usando a biblioteca `buddy.sign.jwt` e a manipula√ß√£o de chaves privadas com `clojure.java.security`. Al√©m disso, √© usada a biblioteca `http-kit` para intera√ß√£o HTTP com o Ollama.

Vou come√ßar analisando os passos necess√°rios para criar um token JWT. Primeiro, √© preciso definir os claims que compreendem informa√ß√µes como ID do usu√°rio, nome de usu√°rio e roles. Em seguida, associar um secret key ao token. No documento, h√° exemplos de como usar uma string secreta ou chaves assim√©tricas. 

A seguir, entendo que √© necess√°rio configurar as depend√™ncias no arquivo `project.clj` para incluir as bibliotecas necess√°rias: `buddy/sign` e `http-kit`. Tamb√©m √© importante garantir que o Ollama esteja rodando com a comando adequado para pulling os modelos e executar as infer√™ncias.

Para testar, seria √∫til executar uma requisi√ß√£o POST para /login usando curl, passando os dados de login como JSON. Depois, usar o token obtido na requisi√ß√£o POST para /rag/query, Including o campo Authorization com o Bearer do token.

Al√©m disso, devo considerar como lidar com as fun√ß√µes de Wrapping em Clojure para garantir que as requisi√ß√µes HTTP sejam encadeadas corretamente. Talvez seja √∫til estabelecer uma rotina de login que gera o token e a envia, seguida de usar esse token nas consultas RAG.

Finalmente, tenho que lidar com poss√≠veis erros, como se o Ollama n√£o est√° executando ou houver problemas de autentica√ß√£o. √â importante inspecionar os logs e verificar as respostas das requisi√ß√µes HTTP para entender quais erros estiverem ocorrendo.

No final, vou needear a documenta√ß√£o officially para confirmar se h√° mais funcionalidades dispon√≠veis que posso explorar ap√≥s a implementa√ß√£o b√°sica de JWT.
&lt;/think&gt;

Para implementar a autentica√ß√£o com JWT em Clojure juntamente com a integra√ß√£o do Ollama, siga os passos abaixo. Isso permitir√° que voc√™ utilize tokens JWT para proteger suas requisi√ß√µes RAG.

### Passo 1: Configurar as depend√™ncias

Adicione as seguintes depend√™ncias ao seu `project.clj`:

[buddy/sign &#34;3.4.0&#34;]    ; Para gera√ß√£o de signatures e verifica√ß√£o de validade
[buddy/auth &#34;2.6.1&#34;]     ; Para fun√ß√µes de autentica√ß√£o
[http-kit &#34;2.6.0&#34;]      ; Para manipula√ß√£o de requisi√ß√µes HTTP
[buddy.core.keys :as keys]  ; Para gera√ß√£o de chaves privadas
[buddy.data.json :as json]  ; Para processamento JSON</code></pre>
 <p>Sucesso total!
Temos um sistema de busca sem√¢ntica com PostgreSQL, pgvector, pgai e Ollama em Clojure funcionando! üéâ</p>
<p>Este projeto de busca sem√¢ntica com PostgreSQL pode ser expandido de v√°rias maneiras interessantes. Uma possibilidade √© implementar um sistema de feedback do usu√°rio que capture as intera√ß√µes e avalia√ß√µes das respostas geradas, permitindo o refinamento cont√≠nuo dos resultados. Isso poderia ser feito adicionando uma tabela <code>feedback_usuarios</code> que registre a consulta original, a resposta fornecida e a avalia√ß√£o do usu√°rio (positiva ou negativa). Esses dados poderiam ent√£o ser utilizados para ajustar os par√¢metros de similaridade ou at√© mesmo para treinar um modelo de reranking que melhore a relev√¢ncia dos resultados ao longo do tempo.</p>
<p>Outra expans√£o valiosa seria a integra√ß√£o com fontes de dados externas em tempo real. Por exemplo, poder√≠amos criar um sistema de ingest√£o autom√°tica que monitore feeds RSS, APIs ou reposit√≥rios Git espec√≠ficos, extraindo novos conte√∫dos periodicamente e atualizando nossa base de conhecimento. Isso manteria o sistema sempre atualizado com as informa√ß√µes mais recentes, especialmente √∫til em dom√≠nios que evoluem rapidamente como tecnologia e ci√™ncia. A implementa√ß√£o poderia utilizar workers ass√≠ncronos em Clojure que processam novas entradas em background, vetorizam o conte√∫do e o inserem automaticamente no PostgreSQL sem interrup√ß√£o do servi√ßo principal. Muito legal n√£o √©?</p>
<hr>
<h3 id="persist√™ncia-de-modelos-entre-reinicializa√ß√µes">Persist√™ncia de Modelos entre Reinicializa√ß√µes</h3>
<p>Um problema comum ao trabalhar com Ollama em cont√™ineres √© que os modelos s√£o baixados repetidamente quando os cont√™ineres s√£o recriados. Para evitar isso:</p>
<ol>
<li>
<p>Use volumes para armazenar os dados do Ollama:</p>


  <pre><code class="language-yaml">volumes:
  ollama_data:/root/.ollama</code></pre>
 </li>
<li>
<p>Ao parar os cont√™ineres, evite remover os volumes:</p>


  <pre><code class="language-bash"># Incorreto (remove volumes)
docker compose down --volumes

# Correto (preserva volumes)
docker compose down</code></pre>
 </li>
<li>
<p>Implemente verifica√ß√µes antes de baixar modelos:</p>


  <pre><code class="language-bash"># Verificar se o modelo j√° existe antes de baix√°-lo
docker exec pgai-ollama-1 ollama list | grep &#34;nomic-embed-text&#34; &gt; /dev/null
if [ $? -ne 0 ]; then
  echo &#34;Baixando modelo nomic-embed-text...&#34;
  docker exec pgai-ollama-1 ollama pull nomic-embed-text
else
  echo &#34;Modelo nomic-embed-text j√° est√° dispon√≠vel&#34;
fi</code></pre>
 </li>
</ol>
<p>Seguindo essas pr√°ticas, voc√™ economizar√° largura de banda e tempo, al√©m de melhorar significativamente a experi√™ncia do usu√°rio.</p>
<h3 id="buscas-especializadas-para-t√≥picos-espec√≠ficos">Buscas Especializadas para T√≥picos Espec√≠ficos</h3>
<p>Ao implementar seu sistema RAG, considere adicionar rotas especializadas de busca para certos t√≥picos. Por exemplo, se seu sistema precisa responder bem a consultas sobre JWT (JSON Web Tokens):</p>


  <pre><code class="language-clojure">(defn query-pg-rag
  &#34;Processa uma consulta com tratamento especial para certos t√≥picos&#34;
  [query]
  ;; Verificar primeiro se √© uma consulta relacionada a JWT
  (let [lower-query (str/lower-case query)
        jwt-keywords [&#34;jwt&#34; &#34;token&#34; &#34;autentica√ß√£o&#34;]]
    
    (if (some #(str/includes? lower-query %) jwt-keywords)
      ;; Busca especializada para JWT usando SQL direto
      (let [conn (jdbc/get-connection db-spec)
            docs (jdbc/execute! 
                   conn 
                   [&#34;SELECT id, titulo, conteudo FROM documentos 
                     WHERE LOWER(conteudo) LIKE ? LIMIT 5&#34;
                    &#34;%jwt%&#34;])]
        ;; Processar resultados espec√≠ficos de JWT...
        )
      
      ;; Busca sem√¢ntica padr√£o para outros t√≥picos
      (semantic-search query 5))))</code></pre>
 <p>Esta abordagem h√≠brida combina busca por palavras-chave para t√≥picos espec√≠ficos com busca sem√¢ntica para consultas gerais, melhorando a precis√£o global do sistema.</p>
<hr>
<h2 id="conclus√£o">Conclus√£o</h2>
<p>Neste artigo, exploramos como construir um sistema de busca sem√¢ntica robusto usando PostgreSQL, pgvector, pgai e Ollama. Esta abordagem n√£o s√≥ oferece melhor precis√£o em compara√ß√£o com m√©todos tradicionais baseados em palavras-chave, mas tamb√©m √© altamente escal√°vel e adequada para ambientes de produ√ß√£o.</p>
<p>Vimos como configurar o ambiente usando Docker/Podman, como lidar com desafios comuns de comunica√ß√£o entre cont√™ineres, e implementamos estrat√©gias para manter a persist√™ncia de modelos e melhorar a experi√™ncia do usu√°rio. A combina√ß√£o de busca sem√¢ntica com t√©cnicas espec√≠ficas para t√≥picos especiais, como JWT, demonstra a flexibilidade desta abordagem.</p>
<p>Para quem j√° trabalhou com RAG usando abordagens mais simples, como TF-IDF, esta implementa√ß√£o representa um salto significativo em termos de capacidades, mantendo a simplicidade operacional gra√ßas √†s ferramentas modernas que utilizamos.</p>
<p>Quer saber mais sobre como implementar sistemas RAG avan√ßados em seus projetos? Confira nossos outros artigos sobre o assunto e experimente o c√≥digo completo dispon√≠vel no <a href="https://github.com/scovl/docai">reposit√≥rio do DocAI</a>. Estamos ansiosos para ver o que voc√™ vai construir!</p>
<hr>
<h2 id="refer√™ncias">Refer√™ncias</h2>
<ul>
<li><a href="https://github.com/pgvector/pgvector">Documenta√ß√£o do pgvector</a> - Extens√£o do PostgreSQL para armazenar, indexar e consultar embeddings vetoriais de alta dimensionalidade.</li>
<li><a href="https://github.com/timescale/pgai">Documenta√ß√£o do pgai</a> - Extens√£o do PostgreSQL que simplifica o armazenamento e recupera√ß√£o de dados para RAG e outras aplica√ß√µes de IA.</li>
<li><a href="https://supabase.com/blog/openai-embeddings-postgres-vector">Embeddings Eficientes com PostgreSQL</a> - Artigo sobre como usar embeddings com PostgreSQL.</li>
<li><a href="https://www.pinecone.io/learn/hnsw-ivfflat/">HNSW vs. IVFFlat para Busca de Similaridade</a> - Artigo sobre as diferen√ßas entre HNSW e IVFFlat para busca de similaridade.</li>
<li><a href="https://ollama.com/">Ollama - Rodando LLMs localmente</a> - Documenta√ß√£o do Ollama, uma ferramenta open-source para executar modelos de linguagem de grande escala localmente.</li>
<li><a href="/2025/03/23/rag/">Artigo anterior sobre RAG com Clojure</a> - Artigo sobre como implementar RAG com Clojure.</li>
</ul>

    </div>
    
    
    <div class="post-comments">
        <div id="disqus_thread"></div>
<script>
    window.disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "scovl" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
    </div>
    
</article>

        </main>
        
        
        
        <footer class="site-footer">
    <div class="footer-inner">
        <div class="footer-content">
            <div class="copyright">
                &copy; 2025 Vitor Lobo
            </div>
            
            <div class="social-links">
                
                <a href="https://github.com/scovl" target="_blank" rel="noopener noreferrer" class="social-link">
                    GitHub
                </a>
                
                
                
                <a href="https://linkedin.com/in/vitor-lobo" target="_blank" rel="noopener noreferrer" class="social-link">
                    LinkedIn
                </a>
                
                
                
                <a href="mailto:lobocode@gmail.com" class="social-link">
                    Email
                </a>
                

                
                <a href="https://hachyderm.io/@lobocode" target="_blank" rel="noopener noreferrer" class="social-link">
                    Mastodon
                </a>
                

                
                <a href="https://scovl.github.io/index.xml" target="_blank" rel="noopener noreferrer" class="social-link">
                    RSS
                </a>
                

            </div>
        </div>
    </div>
</footer>


<script src="/js/code-escaper.js"></script>


<script>
  document.addEventListener("DOMContentLoaded", function() {
    
    if (typeof Prism !== 'undefined') {
      Prism.highlightAll();
    }
  });
</script>

</body>
</html> 
        
    </div>
    
    
    <script src="/js/main.js"></script>
    
    
    
</body>
</html> 