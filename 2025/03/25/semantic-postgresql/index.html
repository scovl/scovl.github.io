<!DOCTYPE html>
<html lang="pt">
<head>
    <title>Busca Semântica com Ollama e PostgreSQL | scovl</title>
    <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="Implementando busca semântica com PostgreSQL e Ollama">



<link rel="preload" href="/vendor/fonts/inter/Inter-400.ttf" as="font" type="font/ttf" crossorigin>
<link rel="preload" href="/vendor/fonts/inter/Inter-600.ttf" as="font" type="font/ttf" crossorigin>
<link rel="preload" href="/vendor/fonts/jetbrains-mono/JetBrainsMono-400.ttf" as="font" type="font/ttf" crossorigin>



<link rel="dns-prefetch" href="//giscus.app">
<link rel="preconnect" href="//giscus.app">



<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="format-detection" content="telephone=no"> 


<link rel="stylesheet" href="/css/main.css?v=1757193683">


<link rel="stylesheet" href="/vendor/fonts/fonts.css?v=1757193683">


<link rel="preload" href="/fonts/abril-fatface.woff2" as="font" type="font/woff2" crossorigin>
<link rel="preload" href="/fonts/rokkitt.woff2" as="font" type="font/woff2" crossorigin>


<link rel="stylesheet" href="/vendor/prism/prism-tomorrow.min.css?v=1757193683">



<script src="/vendor/mermaid/mermaid.min.js?v=1757193683"></script>
<script>
    document.addEventListener("DOMContentLoaded", function() {
        mermaid.initialize({
            startOnLoad: true,
            theme: 'light',
            align: 'center'
        });SS
    });
</script>












<script>

const I18n = {
    currentLang: 'pt',
    isRTL:  false ,
    
    
    formatDate(date, options = {}) {
        const defaultOptions = {
            year: 'numeric',
            month: 'long',
            day: 'numeric'
        };
        
        const locale = this.getLocale();
        const finalOptions = { ...defaultOptions, ...options };
        
        return new Intl.DateTimeFormat(locale, finalOptions).format(date);
    },
    
    
    formatNumber(number, options = {}) {
        const defaultOptions = {
            style: 'decimal',
            minimumFractionDigits: 0,
            maximumFractionDigits: 2
        };
        
        const locale = this.getLocale();
        const finalOptions = { ...defaultOptions, ...options };
        
        return new Intl.NumberFormat(locale, finalOptions).format(number);
    },
    
    
    formatCurrency(amount, currency = 'USD') {
        const locale = this.getLocale();
        return new Intl.NumberFormat(locale, {
            style: 'currency',
            currency: currency
        }).format(amount);
    },
    
    
    formatRelativeTime(date) {
        const locale = this.getLocale();
        const now = new Date();
        const diff = now - date;
        const diffInMinutes = Math.floor(diff / (1000 * 60));
        const diffInHours = Math.floor(diff / (1000 * 60 * 60));
        const diffInDays = Math.floor(diff / (1000 * 60 * 60 * 24));
        
        if (diffInMinutes < 1) {
            return new Intl.RelativeTimeFormat(locale).format(0, 'minute');
        } else if (diffInMinutes < 60) {
            return new Intl.RelativeTimeFormat(locale).format(-diffInMinutes, 'minute');
        } else if (diffInHours < 24) {
            return new Intl.RelativeTimeFormat(locale).format(-diffInHours, 'hour');
        } else {
            return new Intl.RelativeTimeFormat(locale).format(-diffInDays, 'day');
        }
    },
    
    
    getLocale() {
        const localeMap = {
            'en': 'en-US',
            'pt': 'pt-BR',
            'es': 'es-ES',
            'fr': 'fr-FR',
            'de': 'de-DE',
            'it': 'it-IT',
            'ar': 'ar-SA',
            'he': 'he-IL',
            'fa': 'fa-IR',
            'ur': 'ur-PK',
            'zh': 'zh-CN',
            'ja': 'ja-JP',
            'ko': 'ko-KR'
        };
        
        return localeMap[this.currentLang] || 'en-US';
    },
    
    
    t(key, params = {}) {
        const translations = {
            'en': {
                'read_more': 'Read more',
                'back_to_top': 'Back to top',
                'loading': 'Loading...',
                'error': 'Error',
                'success': 'Success',
                'warning': 'Warning',
                'info': 'Information',
                'comments': 'Comments',
                'related_posts': 'Related Posts',
                'tags': 'Tags',
                'categories': 'Categories',
                'search': 'Search',
                'menu': 'Menu',
                'close': 'Close',
                'language': 'Language',
                'theme': 'Theme',
                'dark_mode': 'Dark Mode',
                'light_mode': 'Light Mode'
            },
            'pt': {
                'read_more': 'Ler mais',
                'back_to_top': 'Voltar ao topo',
                'loading': 'Carregando...',
                'error': 'Erro',
                'success': 'Sucesso',
                'warning': 'Aviso',
                'info': 'Informação',
                'comments': 'Comentários',
                'related_posts': 'Posts Relacionados',
                'tags': 'Tags',
                'categories': 'Categorias',
                'search': 'Pesquisar',
                'menu': 'Menu',
                'close': 'Fechar',
                'language': 'Idioma',
                'theme': 'Tema',
                'dark_mode': 'Modo Escuro',
                'light_mode': 'Modo Claro'
            },
            'es': {
                'read_more': 'Leer más',
                'back_to_top': 'Volver arriba',
                'loading': 'Cargando...',
                'error': 'Error',
                'success': 'Éxito',
                'warning': 'Advertencia',
                'info': 'Información',
                'comments': 'Comentarios',
                'related_posts': 'Posts Relacionados',
                'tags': 'Etiquetas',
                'categories': 'Categorías',
                'search': 'Buscar',
                'menu': 'Menú',
                'close': 'Cerrar',
                'language': 'Idioma',
                'theme': 'Tema',
                'dark_mode': 'Modo Oscuro',
                'light_mode': 'Modo Claro'
            },
            'ar': {
                'read_more': 'اقرأ المزيد',
                'back_to_top': 'العودة إلى الأعلى',
                'loading': 'جاري التحميل...',
                'error': 'خطأ',
                'success': 'نجح',
                'warning': 'تحذير',
                'info': 'معلومات',
                'comments': 'التعليقات',
                'related_posts': 'المقالات ذات الصلة',
                'tags': 'العلامات',
                'categories': 'الفئات',
                'search': 'بحث',
                'menu': 'القائمة',
                'close': 'إغلاق',
                'language': 'اللغة',
                'theme': 'المظهر',
                'dark_mode': 'الوضع المظلم',
                'light_mode': 'الوضع الفاتح'
            }
        };
        
        const langTranslations = translations[this.currentLang] || translations['en'];
        let text = langTranslations[key] || key;
        
        
        Object.keys(params).forEach(param => {
            text = text.replace(`{${param}}`, params[param]);
        });
        
        return text;
    },
    
    
    init() {
        this.updatePageDirection();
        this.updateDateFormats();
        this.updateNumberFormats();
        this.updateTranslations();
    },
    
    
    updatePageDirection() {
        if (this.isRTL) {
            document.documentElement.setAttribute('dir', 'rtl');
            document.documentElement.setAttribute('lang', this.currentLang);
        }
    },
    
    
    updateDateFormats() {
        const dateElements = document.querySelectorAll('[data-date]');
        dateElements.forEach(element => {
            const date = new Date(element.getAttribute('data-date'));
            const format = element.getAttribute('data-date-format') || 'default';
            
            let formattedDate;
            switch (format) {
                case 'relative':
                    formattedDate = this.formatRelativeTime(date);
                    break;
                case 'short':
                    formattedDate = this.formatDate(date, { month: 'short', day: 'numeric' });
                    break;
                case 'long':
                    formattedDate = this.formatDate(date, { 
                        weekday: 'long',
                        year: 'numeric',
                        month: 'long',
                        day: 'numeric'
                    });
                    break;
                default:
                    formattedDate = this.formatDate(date);
            }
            
            element.textContent = formattedDate;
        });
    },
    
    
    updateNumberFormats() {
        const numberElements = document.querySelectorAll('[data-number]');
        numberElements.forEach(element => {
            const number = parseFloat(element.getAttribute('data-number'));
            const format = element.getAttribute('data-number-format') || 'decimal';
            
            let formattedNumber;
            switch (format) {
                case 'currency':
                    const currency = element.getAttribute('data-currency') || 'USD';
                    formattedNumber = this.formatCurrency(number, currency);
                    break;
                case 'percent':
                    formattedNumber = this.formatNumber(number / 100, { style: 'percent' });
                    break;
                default:
                    formattedNumber = this.formatNumber(number);
            }
            
            element.textContent = formattedNumber;
        });
    },
    
    
    updateTranslations() {
        const translationElements = document.querySelectorAll('[data-i18n]');
        translationElements.forEach(element => {
            const key = element.getAttribute('data-i18n');
            const params = {};
            
            
            const paramAttributes = element.getAttribute('data-i18n-params');
            if (paramAttributes) {
                try {
                    Object.assign(params, JSON.parse(paramAttributes));
                } catch (e) {
                    console.warn('Invalid i18n params:', paramAttributes);
                }
            }
            
            element.textContent = this.t(key, params);
        });
    }
};


window.I18n = I18n;
</script>


<script>
    if ('serviceWorker' in navigator) {
        window.addEventListener('load', function() {
            navigator.serviceWorker.register('\/sw.js')
                .then(function(registration) {
                    console.log('Service Worker registrado com sucesso:', registration.scope);
                })
                .catch(function(error) {
                    console.log('Falha no registro do Service Worker:', error);
                });
        });
    }
</script> 
</head>
<body>
    
    
    <header class="header">
    <div class="container">
        <div class="header-content">
            <a href="https://scovl.github.io/" class="site-title">scovl</a>
            
            <div class="header-actions">
                
                <nav class="nav-menu">
                    <ul>
                        
                        <li><a href="/page/about/">About</a></li>
                        
                        <li><a href="/page/contact/">Contact</a></li>
                        
                    </ul>
                </nav>
                
                
                



<div class="language-switcher" id="language-switcher">
    <button class="language-btn" onclick="toggleLanguageMenu()">
        <span class="current-lang">Português</span>
        <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
            <polyline points="6,9 12,15 18,9"></polyline>
        </svg>
    </button>
    <div class="language-menu" id="language-menu">
        
            
                <a href="https://scovl.github.io/" class="language-option active">
                    Português
                </a>
            
        
            
                <a href="https://scovl.github.io/en/" class="language-option ">
                    English
                </a>
            
        
    </div>
</div>
                
                
                <button id="dark-mode-toggle" class="theme-toggle" aria-label="Toggle dark mode">
                    <svg class="sun-icon" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <circle cx="12" cy="12" r="5"/>
                        <line x1="12" y1="1" x2="12" y2="3"/>
                        <line x1="12" y1="21" x2="12" y2="23"/>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/>
                        <line x1="1" y1="12" x2="3" y2="12"/>
                        <line x1="21" y1="12" x2="23" y2="12"/>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/>
                    </svg>
                    <svg class="moon-icon" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"/>
                    </svg>
                </button>
            </div>
        </div>
    </div>
</header> 
    
    
    
    <main>
        <div class="container">
            
<article class="post">
    <header class="post-header">
        <h1 class="post-title">Busca Semântica com Ollama e PostgreSQL</h1>
        
        <div class="post-meta">
            <time datetime="2025-03-25T12:00:00Z">
                📅 25/03/2025
            </time>
            
            <span>👤 Vitor Lobo Ramos</span>
            
            
            
            <div class="post-tags">
                
                <a href="/tags/rag" class="tag">RAG</a>
                
                <a href="/tags/postgresql" class="tag">PostgreSQL</a>
                
                <a href="/tags/pgvector" class="tag">pgvector</a>
                
                <a href="/tags/pgai" class="tag">pgai</a>
                
                <a href="/tags/ollama" class="tag">Ollama</a>
                
                <a href="/tags/semantic-search" class="tag">Semantic Search</a>
                
            </div>
            
        </div>
        
    </header>
    
    
    















  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  



<aside class="toc" id="toc" aria-labelledby="toc-title">
    <div class="toc-container">
        <div class="toc-header">
            <h3 id="toc-title" class="toc-title">
                <svg class="toc-icon" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                    <path d="M3 6h18M3 12h18M3 18h18"/>
                </svg>
                Sumário
            </h3>
            <button class="toc-toggle" id="toc-toggle" aria-expanded="true" aria-controls="toc-content" aria-label="Mostrar/Ocultar Sumário">
                <svg class="toc-toggle-icon" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                    <path d="m6 9 6 6 6-6"/>
                </svg>
            </button>
        </div>
        <div class="toc-content" id="toc-content">
            <div class="toc-progress">
                <div class="toc-progress-bar" id="toc-progress-bar"></div>
            </div>
            <nav class="toc-nav">
                <nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#entendendo-a-arquitetura">Entendendo a Arquitetura</a></li>
        <li><a href="#pré-requisitos">Pré-requisitos</a></li>
        <li><a href="#passos-para-construir-a-busca-semântica">Passos para Construir a Busca Semântica</a>
          <ul>
            <li><a href="#1-habilitando-as-extensões">1. Habilitando as Extensões</a></li>
            <li><a href="#2-criando-a-tabela-de-documentos">2. Criando a Tabela de Documentos</a></li>
            <li><a href="#3-inserindo-documentos">3. Inserindo Documentos</a></li>
            <li><a href="#4-configurando-o-vectorizer">4. Configurando o Vectorizer</a></li>
            <li><a href="#5-realizando-busca-semântica">5. Realizando Busca Semântica</a></li>
          </ul>
        </li>
        <li><a href="#integração-com-clojure">Integração com Clojure</a></li>
        <li><a href="#configuração-de-contêineres-e-resolução-de-problemas">Configuração de Contêineres e Resolução de Problemas</a>
          <ul>
            <li><a href="#nomeação-de-contêineres-e-comunicação-entre-serviços">Nomeação de Contêineres e Comunicação entre Serviços</a></li>
            <li><a href="#solução-de-problemas-de-conexão">Solução de Problemas de Conexão</a></li>
            <li><a href="#persistência-de-modelos-entre-reinicializações">Persistência de Modelos entre Reinicializações</a></li>
            <li><a href="#buscas-especializadas-para-tópicos-específicos">Buscas Especializadas para Tópicos Específicos</a></li>
          </ul>
        </li>
        <li><a href="#conclusão">Conclusão</a></li>
        <li><a href="#referências">Referências</a></li>
      </ul>
    </li>
  </ul>
</nav>
            </nav>
        </div>
    </div>
    
    
    <button class="toc-mobile-toggle" id="toc-mobile-toggle" aria-label="Mostrar Sumário">
        <svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
            <path d="M3 6h18M3 12h18M3 18h18"/>
        </svg>
    </button>
</aside>



    
    <div class="post-content">
        <p>Olá, pessoal! 👋</p>
<p>No <a href="/2025/03/23/rag/">artigo anterior</a>, exploramos como construir um sistema RAG (Retrieval-Augmented Generation) usando <a href="https://clojure.org/">Clojure</a> e <a href="https://ollama.com/">Ollama</a> com uma implementação simples de <a href="/post/tf-idf/">TF-IDF</a>. Embora essa abordagem seja excelente para aprender os fundamentos, quando pensamos em soluções de produção, precisamos de algo mais robusto e escalável.</p>
<p>Neste artigo, vamos descobrir como construir um sistema de busca semântica poderoso usando <a href="https://ollama.com/">Ollama</a>, <a href="https://www.postgresql.org/">PostgreSQL</a> e suas extensões para manipulação de vetores. Esta solução é perfeitamente adequada para aplicações de produção e pode servir como base para sistemas RAG, agentes de IA, assistentes em geral. Diferentemente do artigo anterior, vamos usar o <a href="https://ollama.com/">Ollama</a> via Docker assim como o <a href="https://www.postgresql.org/">PostgreSQL</a> e as extensões <a href="https://github.com/pgvector/pgvector">pgvector</a> e <a href="https://github.com/timescale/pgai">pgai</a>.</p>
<p>A combinação do <a href="https://www.postgresql.org/">PostgreSQL</a> com extensões como <a href="https://github.com/pgvector/pgvector">pgvector</a> e <a href="https://github.com/timescale/pgai">pgai</a>, junto com o <a href="https://ollama.com/">Ollama</a> (que permite executar modelos de linguagem localmente), cria uma solução completa e de alto desempenho para <a href="https://en.wikipedia.org/wiki/Semantic_search">processamento semântico de dados</a>.</p>
<h2 id="entendendo-a-arquitetura">Entendendo a Arquitetura</h2>
<p>A busca semântica vai além da simples correspondência de palavras-chave, capturando o significado e o contexto da sua consulta. Em vez de depender apenas de correspondências exatas, ela utiliza <a href="https://en.wikipedia.org/wiki/Embedding_%28machine_learning%29">embeddings vetoriais</a> para representar o conteúdo semântico do texto (ou qualquer dado não estruturado). Essa abordagem permite que seu sistema recupere resultados contextualmente relevantes, mesmo quando as palavras-chave exatas não estão presentes.</p>
<p>Por exemplo, se você pesquisar por &ldquo;melhores lugares para comer&rdquo;, um <a href="https://en.wikipedia.org/wiki/Semantic_search">sistema de busca semântica</a> pode recuperar documentos sobre &ldquo;restaurantes bem avaliados nas proximidades&rdquo; ou &ldquo;experiências gastronômicas altamente recomendadas&rdquo;, efetivamente capturando sua intenção em vez da formulação exata. A arquitetura para busca semântica com PostgreSQL envolve quatro componentes principais:</p>


  
    
  
  <div class="mermaid">flowchart LR
    A[Ollama] --&gt; B[pgai]
    B --&gt; C[pgvector]
    C --&gt; D[PostgreSQL]
    
    style A fill:#f9f,stroke:#333,stroke-width:2px
    style D fill:#9ff,stroke:#333,stroke-width:2px</div>
 <ul>
<li><a href="https://ollama.com/"><strong>Ollama</strong></a>: Ferramenta open-source que permite executar e gerenciar modelos de linguagem de grande escala (LLMs) e modelos de visão (VLMs) localmente no seu computador ou em um servidor cloud, proporcionando maior privacidade e controle sobre os dados.</li>
<li><a href="https://github.com/timescale/pgai"><strong>pgai</strong></a>: Extensão do PostgreSQL que simplifica o armazenamento e recuperação de dados para RAG e outras aplicações de IA, automatizando a criação e gestão de embeddings, facilitando a busca semântica e permitindo a execução de funções de LLM diretamente dentro de consultas SQL.</li>
<li><a href="https://github.com/pgvector/pgvector"><strong>pgvector</strong></a>: Extensão do PostgreSQL que adiciona suporte para armazenar, indexar e consultar embeddings vetoriais de alta dimensionalidade.</li>
<li><a href="https://www.postgresql.org/"><strong>PostgreSQL</strong></a>: O sistema de banco de dados relacional que serve como fundação robusta e escalável para todo o sistema.</li>
</ul>
<hr>
<h2 id="pré-requisitos">Pré-requisitos</h2>
<p>Antes de começar, precisamos garantir que você tenha:</p>
<ol>
<li><strong>Docker e Docker Compose</strong>: Para configurar o ambiente facilmente</li>
<li><strong>PostgreSQL com pgvector e pgai</strong>: Para armazenar e consultar embeddings</li>
</ol>
<blockquote>
<p><strong>NOTA</strong>: No artigo anterior sobre <a href="/2025/03/23/rag/">RAG em Clojure</a>, usamos o <a href="https://ollama.com/">Ollama</a> com <a href="https://ollama.com/models/deepseek-r1">DeepSeek R1</a> baixando o projeto ollama diretamente na máquina. Nesta abordagem, vamos usar o Ollama via Docker. Portanto, recomendo que você feche o Ollama para usar-mos ele inteiramente via Docker aqui nesta abordagem (é necessário fechar para não conflitar com o endpoint do Ollama que vamos usar no Docker Compose).</p></blockquote>
<p>Vamos configurar tudo isso rapidamente usando Docker Compose:</p>


  <pre><code class="language-bash">name: pgai
services:
  db:
    image: timescale/timescaledb-ha:pg17
    environment:
      POSTGRES_PASSWORD: postgres
      # Definir variáveis de ambiente para o host do Ollama
      OLLAMA_HOST: http://ollama:11434
    ports:
      - &#34;5432:5432&#34;
    volumes:
      - data:/home/postgres/pgdata/data
    # Não use a extensão ai até garantir que está instalada corretamente
    command: &#34;-c search_path=public&#34;
    depends_on:
      - ollama
    # Adicionar links explícitos para o serviço Ollama
    links:
      - ollama

  vectorizer-worker:
    image: timescale/pgai-vectorizer-worker:latest
    environment:
      PGAI_VECTORIZER_WORKER_DB_URL: postgres://postgres:postgres@db:5432/postgres
      OLLAMA_HOST: http://ollama:11434
    command: [ &#34;--poll-interval&#34;, &#34;5s&#34;, &#34;--log-level&#34;, &#34;DEBUG&#34; ]
    depends_on:
      - db
      - ollama
    links:
      - ollama

  ollama:
    image: ollama/ollama
    ports:
      - &#34;11434:11434&#34;
    volumes:
      - ollama_data:/root/.ollama
    # Comando direto para iniciar o Ollama
    command: serve

volumes:
  data:
  ollama_data: </code></pre>
 <p>O arquivo <code>docker-compose.yml</code> acima configura uma infraestrutura para busca semântica com três serviços interconectados. O serviço <code>db</code> utiliza o <a href="https://www.timescale.com/">TimescaleDB</a> (que nada mais é que uma versão do <a href="https://www.postgresql.org/">PostgreSQL</a> especializada para otimização de desempenho para dados de séries temporais) com a versão 17, configurando credenciais, mapeamento de portas e um volume persistente para armazenar os dados. Este serviço é configurado para se comunicar com o Ollama através de variáveis de ambiente e links explícitos, garantindo que a comunicação entre os contêineres funcione corretamente.</p>


  
  <div class="mermaid">flowchart TD
    subgraph db [&#34;TimescaleDB (pg17)&#34;]
        db_info[&#34;Ports: 5432:5432&lt;br&gt;Volumes: data:/home/postgres/pgdata/data&lt;br&gt;Environment:&lt;br&gt;POSTGRES_PASSWORD=postgres&lt;br&gt;OLLAMA_HOST=http://ollama:11434&#34;]
    end

    subgraph vectorizer_worker [&#34;pgai-vectorizer-worker&#34;]
        vw_info[&#34;Environment:&lt;br&gt;PGAI_VECTORIZER_WORKER_DB_URL=postgres://postgres:postgres@db:5432/postgres&lt;br&gt;OLLAMA_HOST=http://ollama:11434&lt;br&gt;Command: --poll-interval 5s --log-level DEBUG&#34;]
    end

    subgraph ollama [&#34;Ollama&#34;]
        o_info[&#34;Ports: 11434:11434&lt;br&gt;Volumes: ollama_data:/root/.ollama&lt;br&gt;Command: serve&#34;]
    end

    data[&#34;Data Volume&#34;]
    ollama_data[&#34;Ollama Data Volume&#34;]

    db --- data
    ollama --- ollama_data
    vectorizer_worker --- db
    vectorizer_worker --- ollama
    db --- ollama

    style db fill:#f9f,stroke:#333,stroke-width:2px
    style vectorizer_worker fill:#ccf,stroke:#333,stroke-width:2px
    style ollama fill:#ffc,stroke:#333,stroke-width:2px
    style data fill:#eee,stroke:#333,stroke-width:2px
    style ollama_data fill:#eee,stroke:#333,stroke-width:2px</div>
 <p>O diagrama acima ilustra a arquitetura do sistema de busca semântica com PostgreSQL. No centro, temos três componentes principais: o TimescaleDB (uma versão especializada do PostgreSQL), o pgai-vectorizer-worker (responsável por processar e vetorizar os textos) e o Ollama (que fornece os modelos de IA). As conexões entre os serviços mostram como eles se comunicam: o vectorizer-worker se conecta tanto ao banco de dados quanto ao Ollama para realizar seu trabalho de transformação de textos em vetores.</p>
<p>Os volumes persistentes (representados em cinza) garantem que tanto os dados do PostgreSQL quanto os modelos do Ollama sejam preservados entre reinicializações. Esta arquitetura modular permite escalar cada componente independentemente conforme necessário, enquanto mantém um fluxo de dados eficiente para operações de busca semântica.</p>
<p>O serviço <code>vectorizer-worker</code> é um componente especializado do <a href="https://github.com/timescale/pgai">pgai</a> que monitora o banco de dados a cada 5 segundos, processando automaticamente textos para transformá-los em embeddings vetoriais. Ele se conecta ao banco <a href="https://www.postgresql.org/">PostgreSQL</a> e ao serviço <a href="https://ollama.com/">Ollama</a> para realizar a vetorização dos textos, funcionando como uma ponte entre o armazenamento de dados e o modelo de IA, com logs detalhados para facilitar a depuração durante o desenvolvimento.</p>
<p>Por fim, o serviço <code>ollama</code> fornece a infraestrutura para executar modelos de IA localmente, expondo uma API REST na porta 11434 e armazenando os modelos baixados em um volume persistente. Este design de três camadas (banco de dados, processador de vetores e motor de IA) cria um sistema completo para busca semântica que pode ser iniciado com um simples <code>docker compose up -d</code>, seguido pelo download do modelo de <a href="https://en.wikipedia.org/wiki/Embedding_%28machine_learning%29">embeddings</a> que transformará os textos em vetores.</p>


  <pre><code class="language-bash">docker compose exec ollama ollama pull nomic-embed-text</code></pre>
 <p>Este setup configura um banco de dados PostgreSQL com as extensões <a href="https://github.com/timescale/pgai">pgai</a>, <a href="https://github.com/pgvector/pgvector">pgvector</a> e <a href="https://github.com/timescale/pgvectorscale">pgvectorscale</a>. Também configura o Ollama, que você pode usar para implantar LLMs e modelos de embedding.</p>
<hr>
<h2 id="passos-para-construir-a-busca-semântica">Passos para Construir a Busca Semântica</h2>
<p>Os passos para implementar a busca semântica no PostgreSQL são relativamente simples. Primeiro, vamos habilitar as extensões necessárias, criar uma tabela para armazenar nossos documentos, configurar o <a href="https://github.com/timescale/pgai/tree/main/vectorizer">vectorizer</a> para gerar <a href="https://en.wikipedia.org/wiki/Embedding_%28machine_learning%29">embeddings</a> automaticamente e, finalmente, realizar consultas semânticas.</p>
<h3 id="1-habilitando-as-extensões">1. Habilitando as Extensões</h3>
<p>Primeiro, precisamos habilitar as extensões necessárias no PostgreSQL:</p>


  <pre><code class="language-sql">CREATE EXTENSION IF NOT EXISTS vector CASCADE; 
CREATE EXTENSION IF NOT EXISTS ai CASCADE;</code></pre>
 <h3 id="2-criando-a-tabela-de-documentos">2. Criando a Tabela de Documentos</h3>
<p>Agora, vamos criar uma tabela para armazenar os documentos que queremos pesquisar:</p>


  <pre><code class="language-sql">CREATE TABLE IF NOT EXISTS documentos (
   id SERIAL PRIMARY KEY,
   titulo TEXT NOT NULL,
   conteudo TEXT,
   categoria TEXT,
   data_criacao TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);</code></pre>
 <p>Neste exemplo, criamos uma tabela chamada <code>documentos</code> com quatro colunas: <code>id</code>, <code>titulo</code>, <code>conteudo</code> e <code>categoria</code>. É importante notar que a coluna <code>id</code> é a chave primária da tabela. Outro ponto importante é que a coluna <code>data_criacao</code> é uma coluna de metadados que é gerada automaticamente pelo PostgreSQL.</p>
<h3 id="3-inserindo-documentos">3. Inserindo Documentos</h3>
<p>Podemos inserir documentos manualmente ou usar a função <code>ai.load_dataset</code> do <a href="https://github.com/timescale/pgai">pgai</a> para carregar dados diretamente do <a href="https://huggingface.co/">Hugging Face</a>:</p>


  <pre><code class="language-sql">SELECT ai.load_dataset(
   name =&gt; &#39;Cohere/movies&#39;,
   table_name =&gt; &#39;documentos&#39;,
   if_table_exists =&gt; &#39;append&#39;,
   field_types =&gt; &#39;{&#34;title&#34;: &#34;titulo&#34;, &#34;overview&#34;: &#34;conteudo&#34;, &#34;genres&#34;: &#34;categoria&#34;}&#39;::jsonb
);</code></pre>
 <p>Alternativamente, podemos inserir registros manualmente:</p>


  <pre><code class="language-sql">INSERT INTO documentos (titulo, conteudo, categoria) VALUES 
(&#39;Guia Clojure&#39;, &#39;Clojure é uma linguagem funcional moderna...&#39;, &#39;Programação&#39;),
(&#39;Tutorial RAG&#39;, &#39;Sistemas RAG combinam busca e geração...&#39;, &#39;IA&#39;),
(&#39;PostgreSQL Avançado&#39;, &#39;Técnicas de otimização para PostgreSQL...&#39;, &#39;Banco de Dados&#39;);</code></pre>
 <blockquote>
<p><strong>NOTA</strong>: O <a href="https://huggingface.co/">Hugging Face</a> é uma plataforma de dados e modelos de IA.</p></blockquote>
<p>Agora vamos configurar o vectorizer para gerar embeddings automaticamente.</p>
<h3 id="4-configurando-o-vectorizer">4. Configurando o Vectorizer</h3>
<p>O <a href="https://github.com/timescale/pgai">pgai</a> inclui uma ferramenta chamada <a href="https://github.com/timescale/pgai/tree/main/vectorizer">vectorizer</a> que automatiza a criação e sincronização de embeddings. Esta é uma das funcionalidades mais poderosas desta solução, pois elimina a necessidade de ferramentas externas para criar <a href="https://en.wikipedia.org/wiki/Embedding_%28machine_learning%29">embeddings</a>. Vamos configurá-la:</p>


  <pre><code class="language-sql">SELECT ai.create_vectorizer(
   &#39;public.documentos&#39;::regclass,
   destination =&gt; &#39;documentos_embeddings&#39;,
   embedding =&gt; ai.embedding_ollama(&#39;nomic-embed-text&#39;, 768),
   chunking =&gt; ai.chunking_recursive_character_text_splitter(&#39;conteudo&#39;)
);</code></pre>
 <p>Basicamente, o comando acima faz o seguinte:</p>
<ol>
<li>Cria uma tabela <code>documentos_embeddings</code> para armazenar os vetores</li>
<li>Configura o modelo <code>nomic-embed-text</code> via Ollama para gerar embeddings</li>
<li>Define uma estratégia de chunking para dividir textos longos</li>
<li>Cria automaticamente uma view <code>documentos_embeddings_vectorized</code> que junta os documentos com seus embeddings</li>
</ol>
<p>O <a href="https://github.com/timescale/pgai/tree/main/vectorizer">vectorizer</a> também cuida da sincronização automática dos embeddings quando documentos são inseridos, atualizados ou removidos - sem necessidade de código adicional! Isto simplifica enormemente a manutenção do sistema.</p>
<h3 id="5-realizando-busca-semântica">5. Realizando Busca Semântica</h3>
<p>Agora estamos prontos para realizar buscas semânticas. Usaremos a função <code>ai.ollama_embed</code> para gerar embeddings para nossa consulta e o operador de distância de cosseno (<code>&lt;=&gt;</code>) para encontrar documentos similares:</p>


  <pre><code class="language-sql">WITH query_embedding AS (
    -- Gerar embedding para a consulta
    SELECT ai.ollama_embed(&#39;nomic-embed-text&#39;, &#39;Como implementar RAG em sistemas modernos&#39;, 
                          host =&gt; &#39;http://ollama:11434&#39;) AS embedding
)
SELECT
    d.titulo,
    d.conteudo,
    d.categoria,
    t.embedding &lt;=&gt; (SELECT embedding FROM query_embedding) AS distancia
FROM documentos_embeddings t
LEFT JOIN documentos d ON t.id = d.id
ORDER BY distancia
LIMIT 5;</code></pre>
 <p>Este código SQL realiza uma <a href="https://en.wikipedia.org/wiki/Semantic_search">busca semântica</a> em nossa base de documentos utilizando <a href="https://en.wikipedia.org/wiki/Embedding_%28machine_learning%29">embeddings</a> gerados pelo modelo <code>nomic-embed-text</code> através do <a href="https://ollama.com/">Ollama</a>. Primeiro, criamos uma CTE (Common Table Expression) chamada <code>query_embedding</code> que gera o embedding para nossa consulta &ldquo;Como implementar RAG em sistemas modernos&rdquo;. Em seguida, selecionamos os documentos mais relevantes comparando este embedding de consulta com os embeddings armazenados na tabela <code>documentos_embeddings</code> usando o operador de distância de cosseno (<code>&lt;=&gt;</code>).</p>
<p>O resultado é uma lista ordenada dos documentos mais semanticamente similares à nossa consulta, independentemente de compartilharem as mesmas palavras exatas. Esta é a essência da busca semântica - encontrar conteúdo conceitualmente relacionado, não apenas correspondências de palavras-chave. A coluna <code>distancia</code> nos mostra quão próximo cada documento está da nossa consulta, com valores menores indicando maior similaridade. Limitamos os resultados aos 5 documentos mais relevantes, mas este número pode ser ajustado conforme necessário. O PostgreSQL oferece três operadores para cálculo de similaridade:</p>
<ul>
<li><code>&lt;-&gt;</code>: <a href="https://en.wikipedia.org/wiki/Euclidean_distance">Distância L2 (Euclidiana)</a></li>
<li><code>&lt;#&gt;</code>: <a href="https://en.wikipedia.org/wiki/Dot_product">Produto interno</a></li>
<li><code>&lt;=&gt;</code>: <a href="https://en.wikipedia.org/wiki/Cosine_distance">Distância de cosseno</a> (geralmente a melhor opção)</li>
</ul>
<p>E pronto! Com apenas esses poucos passos, temos um sistema de busca semântica totalmente funcional, diretamente no PostgreSQL. <strong><a href="/2025/03/23/rag/">Para quem acompanhou o artigo anterior sobre a implementação de RAG em Clojure</a></strong>, vale a pena comparar as duas abordagens:</p>
<p>A diferença entre as duas abordagens é bem clara quando olhamos lado a lado. <a href="/2025/03/23/rag/">No artigo anterior sobre RAG em Clojure</a>, usamos uma técnica mais simples <a href="/post/tf-idf/">(TF-IDF)</a> que funciona bem para projetos pequenos e didáticos. É como usar uma bicicleta para se locomover para distâncias curtas. O código em Clojure mantém tudo em memória, o que é ótimo para aprender os conceitos, mas começa a dar problema quando a quantidade de documentos cresce.</p>
<p>Já a abordagem com PostgreSQL + pgai é como trocar a bicicleta por um carro esportivo! Estamos usando embeddings densos gerados por LLMs, que capturam muito melhor o significado semântico dos textos. O PostgreSQL cuida de toda a parte chata de persistência e indexação, permitindo que você escale para milhões de documentos sem suar. Os índices especializados para vetores (como HNSW) fazem buscas em bilhões de embeddings parecerem instantâneas, algo que nossa implementação anterior jamais conseguiria.</p>
<p>O mais legal é que a manutenção fica muito mais simples. Com o <a href="https://github.com/timescale/pgai/tree/main/vectorizer">vectorizer do pgai</a>, você só precisa inserir documentos no banco normalmente, e ele cuida automaticamente de gerar e atualizar os embeddings.</p>
<hr>
<h2 id="integração-com-clojure">Integração com Clojure</h2>
<p>O objetivo deste artigo é mostrar como é fácil construir um sistema de busca semântica usando PostgreSQL e pgai. No entanto, é mostrar também como podemos evoluir à proposta anterior e construir um sistema de busca semântica mais robusto e escalável usando PostgreSQL e pgai e Clojure.</p>


  <pre><code class="language-clojure">;; src/docai/pg.clj
(ns docai.pg
  (:require [next.jdbc :as jdbc]
            [clojure.data.json :as json]))

(def db-spec
  {:dbtype &#34;postgresql&#34;
   :dbname &#34;postgres&#34;
   :host &#34;localhost&#34;
   :user &#34;postgres&#34;
   :password &#34;password&#34;})

(defn query-semantic-search
  &#34;Realiza busca semântica via PostgreSQL&#34;
  [query limit]
  (let [conn (jdbc/get-connection db-spec)
        sql (str &#34;WITH query_embedding AS (&#34;
                 &#34;  SELECT ai.ollama_embed(&#39;nomic-embed-text&#39;, ?, host =&gt; &#39;http://ollama:11434&#39;) AS embedding&#34;
                 &#34;)&#34;
                 &#34;SELECT&#34;
                 &#34;  d.titulo,&#34;
                 &#34;  d.conteudo,&#34;
                 &#34;  d.categoria,&#34;
                 &#34;  t.embedding &lt;=&gt; (SELECT embedding FROM query_embedding) AS distancia&#34;
                 &#34; FROM documentos_embeddings t&#34;
                 &#34; LEFT JOIN documentos d ON t.id = d.id&#34;
                 &#34; ORDER BY distancia&#34;
                 &#34; LIMIT ?&#34;)
        results (jdbc/execute! conn [sql query limit])]
    results))</code></pre>
 <blockquote>
<p><strong>NOTA</strong>: O código acima é um exemplo de como integrar a busca semântica no PostgreSQL com uma aplicação Clojure. O código completo está disponível no <a href="https://github.com/scovl/docai">https://github.com/scovl/docai</a>.</p></blockquote>
<h2 id="configuração-de-contêineres-e-resolução-de-problemas">Configuração de Contêineres e Resolução de Problemas</h2>
<p>Ao trabalhar com contêineres Docker ou Podman, você pode encontrar alguns desafios específicos relacionados à comunicação entre serviços. Vamos explorar algumas dicas para garantir que sua configuração funcione sem problemas:</p>
<h3 id="nomeação-de-contêineres-e-comunicação-entre-serviços">Nomeação de Contêineres e Comunicação entre Serviços</h3>
<p>Quando os serviços estão em contêineres separados, a comunicação entre eles pode ser complicada. Existem várias maneiras de referenciar um contêiner a partir de outro:</p>


  <pre><code class="language-clojure">;; Exemplo de diferentes URLs para alcançar o serviço Ollama
(def alternative-hosts 
  [&#34;http://pgai-ollama-1:11434&#34;    ;; Nome do contêiner específico (mais confiável)
   &#34;http://ollama:11434&#34;           ;; Nome do serviço (conforme definido no arquivo docker/podman-compose)
   &#34;http://172.18.0.2:11434&#34;       ;; IP do contêiner (pode mudar entre reinicializações)
   &#34;http://host.docker.internal:11434&#34; ;; Especial para acessar o host a partir do contêiner
   &#34;http://localhost:11434&#34;])      ;; Funciona apenas se mapeado para a porta do host</code></pre>
 <p>O método mais confiável é usar o nome exato do contêiner (algo como <code>pgai-ollama-1</code>), que pode ser descoberto com o comando <code>docker ps</code> ou <code>podman ps</code>.</p>
<h3 id="solução-de-problemas-de-conexão">Solução de Problemas de Conexão</h3>
<p>Se você estiver enfrentando problemas de conexão, uma abordagem robusta é implementar um sistema de fallback que tente diferentes URLs:</p>


  <pre><code class="language-clojure">(defn call-ollama-api
  &#34;Chama a API do Ollama com múltiplas tentativas de conexão&#34;
  [prompt]
  (let [primary-url &#34;http://ollama:11434/api/generate&#34;
        options {:headers {&#34;Content-Type&#34; &#34;application/json&#34;}
                 :body (json/write-str {:model &#34;deepseek-r1&#34;
                                       :prompt prompt})}
        
        ;; Tentar primeiro com a URL primária
        primary-result (try-single-url primary-url options)]
    
    (if (:success primary-result)
      (:result primary-result)
      (do
        (println &#34;⚠️ Erro na chamada primária, tentando URLs alternativas...&#34;)
        
        ;; Tentar URLs alternativas
        (let [alternative-hosts [&#34;http://pgai-ollama-1:11434&#34; 
                                &#34;http://172.18.0.2:11434&#34; 
                                &#34;http://host.docker.internal:11434&#34; 
                                &#34;http://localhost:11434&#34;]
              successful-result (some (fn [host]
                                       (let [alt-url (str host &#34;/api/generate&#34;)
                                             result (try-single-url alt-url options)]
                                         (when (:success result)
                                           (println &#34;✅ Conexão bem-sucedida com&#34; alt-url)
                                           (:result result))))
                                     alternative-hosts)]
          (or successful-result
              (str &#34;Não foi possível conectar ao Ollama usando nenhum dos endpoints disponíveis.&#34;)))))))</code></pre>
 <p>Esta abordagem tenta vários endpoints diferentes e usa o primeiro que funcionar. A função <code>call-ollama-api</code> primeiro tenta se conectar a uma URL primária e, caso falhe, percorre uma lista de URLs alternativas até encontrar uma conexão bem-sucedida. Para cada tentativa, ela utiliza a função auxiliar <code>try-single-url</code> que encapsula a lógica de tratamento de erros.</p>
<p>A implementação segue um padrão de fallback, onde a função retorna o resultado da primeira conexão bem-sucedida ou uma mensagem de erro caso todas as tentativas falhem. Este método é particularmente útil em ambientes containerizados, onde os endereços de rede podem variar dependendo da configuração do <a href="https://www.docker.com/">Docker</a> ou <a href="https://podman.io/">Podman</a> e da rede interna, garantindo maior resiliência à aplicação.</p>
<p>Acessando <a href="https://github.com/scovl/docai">https://github.com/scovl/docai</a>, você pode ver o código completo e testar a aplicação. Ao executar por exemplo <code>./run.bat postgres</code> temos o seguinte output:</p>


  <pre><code class="language-bash">Inicializando DocAI...
Modo PostgreSQL ativado!
ℹ️ Para usar o Ollama, certifique-se de que ele está em execução com o comando: ollama serve
ℹ️ Usando o modelo deepseek-r1. Se você ainda não o baixou, execute: ollama pull deepseek-r1
Configurando ambiente PostgreSQL para RAG...
✅ Configurado para usar Ollama dentro do contêiner Docker/Podman
🚀 Configurando PostgreSQL para RAG...
✅ Extensões vector e ai habilitadas com sucesso
✅ Tabela de documentos criada com sucesso
✅ Configurado para usar Ollama dentro do contêiner Docker/Podman
✅ Vectorizer já configurado (tabela documentos_embeddings já existe)
Importando documentos para o PostgreSQL...
✅ Documento inserido com ID: 5
✅ Arquivo importado com sucesso: resources\docs\example.md
PostgreSQL RAG pronto! Faça sua pergunta:
Como implementar JWT em Clojure?
Processando...
DEBUG - Processando query no PostgreSQL: Como implementar JWT em Clojure?
DEBUG - Detectada consulta relacionada a JWT, usando busca especial
DEBUG - Encontrados 5 documentos relacionados a JWT
DEBUG - Enviando prompt para o Ollama usando o modelo deepseek-r1
DEBUG - Tamanho do prompt após truncamento: 4442 caracteres
DEBUG - Usando URL do Ollama: http://ollama:11434/api/generate
⚠️ Erro na chamada primária: Erro ao chamar a API do Ollama:  - 
🔄 Tentando URLs alternativas...
🔄 Tentando conectar ao Ollama em http://pgai-ollama-1:11434/api/generate
⚠️ Erro ao chamar a API do Ollama:  Erro ao chamar a API do Ollama:  - 
🔄 Tentando conectar ao Ollama em http://172.18.0.2:11434/api/generate
⚠️ Erro ao chamar a API do Ollama:  Erro ao chamar a API do Ollama:  - 
🔄 Tentando conectar ao Ollama em http://host.docker.internal:11434/api/generate
⚠️ Erro ao chamar a API do Ollama:  Erro ao chamar a API do Ollama:  - 
🔄 Tentando conectar ao Ollama em http://localhost:11434/api/generate
✅ Conexão bem-sucedida com http://localhost:11434/api/generate
&lt;think&gt;
Primeiro, preciso entender como a implementação de JWT em Clojure está relacionada com a integração do Ollama. Sabemos que o documento aborda a criação de tokens JWT usando a biblioteca `buddy.sign.jwt` e a manipulação de chaves privadas com `clojure.java.security`. Além disso, é usada a biblioteca `http-kit` para interação HTTP com o Ollama.

Vou começar analisando os passos necessários para criar um token JWT. Primeiro, é preciso definir os claims que compreendem informações como ID do usuário, nome de usuário e roles. Em seguida, associar um secret key ao token. No documento, há exemplos de como usar uma string secreta ou chaves assimétricas. 

A seguir, entendo que é necessário configurar as dependências no arquivo `project.clj` para incluir as bibliotecas necessárias: `buddy/sign` e `http-kit`. Também é importante garantir que o Ollama esteja rodando com a comando adequado para pulling os modelos e executar as inferências.

Para testar, seria útil executar uma requisição POST para /login usando curl, passando os dados de login como JSON. Depois, usar o token obtido na requisição POST para /rag/query, Including o campo Authorization com o Bearer do token.

Além disso, devo considerar como lidar com as funções de Wrapping em Clojure para garantir que as requisições HTTP sejam encadeadas corretamente. Talvez seja útil estabelecer uma rotina de login que gera o token e a envia, seguida de usar esse token nas consultas RAG.

Finalmente, tenho que lidar com possíveis erros, como se o Ollama não está executando ou houver problemas de autenticação. É importante inspecionar os logs e verificar as respostas das requisições HTTP para entender quais erros estiverem ocorrendo.

No final, vou needear a documentação officially para confirmar se há mais funcionalidades disponíveis que posso explorar após a implementação básica de JWT.
&lt;/think&gt;

Para implementar a autenticação com JWT em Clojure juntamente com a integração do Ollama, siga os passos abaixo. Isso permitirá que você utilize tokens JWT para proteger suas requisições RAG.

### Passo 1: Configurar as dependências

Adicione as seguintes dependências ao seu `project.clj`:

[buddy/sign &#34;3.4.0&#34;]    ; Para geração de signatures e verificação de validade
[buddy/auth &#34;2.6.1&#34;]     ; Para funções de autenticação
[http-kit &#34;2.6.0&#34;]      ; Para manipulação de requisições HTTP
[buddy.core.keys :as keys]  ; Para geração de chaves privadas
[buddy.data.json :as json]  ; Para processamento JSON</code></pre>
 <p>Sucesso total!
Temos um sistema de busca semântica com PostgreSQL, pgvector, pgai e Ollama em Clojure funcionando! 🎉</p>
<p>Este projeto de busca semântica com PostgreSQL pode ser expandido de várias maneiras interessantes. Uma possibilidade é implementar um sistema de feedback do usuário que capture as interações e avaliações das respostas geradas, permitindo o refinamento contínuo dos resultados. Isso poderia ser feito adicionando uma tabela <code>feedback_usuarios</code> que registre a consulta original, a resposta fornecida e a avaliação do usuário (positiva ou negativa). Esses dados poderiam então ser utilizados para ajustar os parâmetros de similaridade ou até mesmo para treinar um modelo de reranking que melhore a relevância dos resultados ao longo do tempo.</p>
<p>Outra expansão valiosa seria a integração com fontes de dados externas em tempo real. Por exemplo, poderíamos criar um sistema de ingestão automática que monitore feeds RSS, APIs ou repositórios Git específicos, extraindo novos conteúdos periodicamente e atualizando nossa base de conhecimento. Isso manteria o sistema sempre atualizado com as informações mais recentes, especialmente útil em domínios que evoluem rapidamente como tecnologia e ciência. A implementação poderia utilizar workers assíncronos em Clojure que processam novas entradas em background, vetorizam o conteúdo e o inserem automaticamente no PostgreSQL sem interrupção do serviço principal. Muito legal não é?</p>
<hr>
<h3 id="persistência-de-modelos-entre-reinicializações">Persistência de Modelos entre Reinicializações</h3>
<p>Um problema comum ao trabalhar com Ollama em contêineres é que os modelos são baixados repetidamente quando os contêineres são recriados. Para evitar isso:</p>
<ol>
<li>
<p>Use volumes para armazenar os dados do Ollama:</p>


  <pre><code class="language-yaml">volumes:
  ollama_data:/root/.ollama</code></pre>
 </li>
<li>
<p>Ao parar os contêineres, evite remover os volumes:</p>


  <pre><code class="language-bash"># Incorreto (remove volumes)
docker compose down --volumes

# Correto (preserva volumes)
docker compose down</code></pre>
 </li>
<li>
<p>Implemente verificações antes de baixar modelos:</p>


  <pre><code class="language-bash"># Verificar se o modelo já existe antes de baixá-lo
docker exec pgai-ollama-1 ollama list | grep &#34;nomic-embed-text&#34; &gt; /dev/null
if [ $? -ne 0 ]; then
  echo &#34;Baixando modelo nomic-embed-text...&#34;
  docker exec pgai-ollama-1 ollama pull nomic-embed-text
else
  echo &#34;Modelo nomic-embed-text já está disponível&#34;
fi</code></pre>
 </li>
</ol>
<p>Seguindo essas práticas, você economizará largura de banda e tempo, além de melhorar significativamente a experiência do usuário.</p>
<h3 id="buscas-especializadas-para-tópicos-específicos">Buscas Especializadas para Tópicos Específicos</h3>
<p>Ao implementar seu sistema RAG, considere adicionar rotas especializadas de busca para certos tópicos. Por exemplo, se seu sistema precisa responder bem a consultas sobre JWT (JSON Web Tokens):</p>


  <pre><code class="language-clojure">(defn query-pg-rag
  &#34;Processa uma consulta com tratamento especial para certos tópicos&#34;
  [query]
  ;; Verificar primeiro se é uma consulta relacionada a JWT
  (let [lower-query (str/lower-case query)
        jwt-keywords [&#34;jwt&#34; &#34;token&#34; &#34;autenticação&#34;]]
    
    (if (some #(str/includes? lower-query %) jwt-keywords)
      ;; Busca especializada para JWT usando SQL direto
      (let [conn (jdbc/get-connection db-spec)
            docs (jdbc/execute! 
                   conn 
                   [&#34;SELECT id, titulo, conteudo FROM documentos 
                     WHERE LOWER(conteudo) LIKE ? LIMIT 5&#34;
                    &#34;%jwt%&#34;])]
        ;; Processar resultados específicos de JWT...
        )
      
      ;; Busca semântica padrão para outros tópicos
      (semantic-search query 5))))</code></pre>
 <p>Esta abordagem híbrida combina busca por palavras-chave para tópicos específicos com busca semântica para consultas gerais, melhorando a precisão global do sistema.</p>
<hr>
<h2 id="conclusão">Conclusão</h2>
<p>Neste artigo, exploramos como construir um sistema de busca semântica robusto usando PostgreSQL, pgvector, pgai e Ollama. Esta abordagem não só oferece melhor precisão em comparação com métodos tradicionais baseados em palavras-chave, mas também é altamente escalável e adequada para ambientes de produção.</p>
<p>Vimos como configurar o ambiente usando Docker/Podman, como lidar com desafios comuns de comunicação entre contêineres, e implementamos estratégias para manter a persistência de modelos e melhorar a experiência do usuário. A combinação de busca semântica com técnicas específicas para tópicos especiais, como JWT, demonstra a flexibilidade desta abordagem.</p>
<p>Para quem já trabalhou com RAG usando abordagens mais simples, como TF-IDF, esta implementação representa um salto significativo em termos de capacidades, mantendo a simplicidade operacional graças às ferramentas modernas que utilizamos.</p>
<p>Quer saber mais sobre como implementar sistemas RAG avançados em seus projetos? Confira nossos outros artigos sobre o assunto e experimente o código completo disponível no <a href="https://github.com/scovl/docai">repositório do DocAI</a>. Estamos ansiosos para ver o que você vai construir!</p>
<hr>
<h2 id="referências">Referências</h2>
<ul>
<li><a href="https://github.com/pgvector/pgvector">Documentação do pgvector</a> - Extensão do PostgreSQL para armazenar, indexar e consultar embeddings vetoriais de alta dimensionalidade.</li>
<li><a href="https://github.com/timescale/pgai">Documentação do pgai</a> - Extensão do PostgreSQL que simplifica o armazenamento e recuperação de dados para RAG e outras aplicações de IA.</li>
<li><a href="https://supabase.com/blog/openai-embeddings-postgres-vector">Embeddings Eficientes com PostgreSQL</a> - Artigo sobre como usar embeddings com PostgreSQL.</li>
<li><a href="https://www.pinecone.io/learn/hnsw-ivfflat/">HNSW vs. IVFFlat para Busca de Similaridade</a> - Artigo sobre as diferenças entre HNSW e IVFFlat para busca de similaridade.</li>
<li><a href="https://ollama.com/">Ollama - Rodando LLMs localmente</a> - Documentação do Ollama, uma ferramenta open-source para executar modelos de linguagem de grande escala localmente.</li>
<li><a href="/2025/03/23/rag/">Artigo anterior sobre RAG com Clojure</a> - Artigo sobre como implementar RAG com Clojure.</li>
</ul>

    </div>
    
    
    



    
    
    
        
            
            
            
            
                
                    
                
                    
                
                    
                
                    
                
                    
                
            
            
            
        
    
        
            
            
            
            
                
                    
                
                    
                
                    
                
                    
                
                    
                
            
            
            
        
    
        
            
            
            
            
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
            
            
            
        
    
        
            
            
            
            
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
            
            
            
        
    
        
            
            
            
            
                
                    
                        
                        
                    
                
                    
                
                    
                
                    
                
            
            
            
                
            
        
    
        
    
        
            
            
            
            
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
            
            
            
        
    
        
            
            
            
            
                
                    
                        
                        
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                        
                        
                    
                
                    
                        
                        
                    
                
            
            
            
                
            
        
    
        
            
            
            
            
            
            
        
    
        
            
            
            
            
            
            
        
    
    
    
        
        
        
        <div class="related-posts">
            <h3 class="related-posts-title">📚 Posts Relacionados</h3>
            <div class="related-posts-grid">
                
                    
                    <article class="related-post-item animate-on-scroll">
                        <div class="related-post-content">
                            <h4 class="related-post-title">
                                <a href="/2025/03/28/rag02/">Técnicas Avançadas para RAG em Produção</a>
                            </h4>
                            <p class="related-post-excerpt">
                                <h2 id="introdução">Introdução</h2>
<p>Olá pessoal! 👋</p>
<p>Nos artigos anteriores, exploramos como <a href="/2025/03/23/rag/">implementar um RAG básico em Clojure</a> em memória e como <a href="/2025/03/25/semantic-postgresql/">construir um sistema de busca semântica com PostgreSQL e Ollama</a>. Agora, vamos dar o próximo passo: transformar nosso protótipo em um sistema RAG pronto para produção.</p>
<p>Como muitos desenvolvedores já descobriram, criar um protótipo funcional de <a href="https://en.wikipedia.org/wiki/Retrieval-augmented_generation">RAG</a> com alguns documentos é relativamente simples. O verdadeiro desafio começa quando precisamos escalar esse sistema para lidar com milhares de documentos, garantir respostas precisas e manter o desempenho sob carga. Neste artigo, vamos explorar técnicas avançadas para superar esses desafios e levar nosso <a href="https://github.com/scovl/docai">DocAI</a> para um novo patamar de qualidade e confiabilidade.</p>
                            </p>
                            <div class="related-post-meta">
                                <span class="related-post-date">28/03/2025</span>
                                
                                    <div class="related-post-tags">
                                        
                                            <span class="tag">RAG</span>
                                        
                                            <span class="tag">LLM</span>
                                        
                                    </div>
                                
                            </div>
                            <div class="related-post-score">
                                <modern-badge variant="info">3 tags em comum</modern-badge>
                            </div>
                        </div>
                    </article>
                
                    
                    <article class="related-post-item animate-on-scroll">
                        <div class="related-post-content">
                            <h4 class="related-post-title">
                                <a href="/2025/03/23/rag/">01 - RAG Simples com Clojure e Ollama</a>
                            </h4>
                            <p class="related-post-excerpt">
                                <h2 id="introdução">Introdução</h2>
<p>Olá, pessoal! 👋</p>
<p>Neste artigo, vamos explorar como construir uma aplicação <a href="https://pt.wikipedia.org/wiki/Gera%C3%A7%C3%A3o_aumentada_por_recupera%C3%A7%C3%A3o">RAG (Retrieval-Augmented Generation)</a> completa do zero usando <a href="https://clojure.org/">Clojure</a>. Vamos mergulhar em uma implementação prática que combina processamento de texto, busca semântica e geração de respostas com LLMs locais. Se você está interessado em melhorar a precisão e relevância das respostas dos seus modelos de linguagem com informações atualizadas, este guia é para você!</p>
<h2 id="fundamentos-do-rag">Fundamentos do RAG</h2>
<h3 id="o-que-é-rag">O que é RAG?</h3>
<p>Os Modelos de Linguagem de Grande Escala (<a href="https://en.wikipedia.org/wiki/Large_language_model">LLMs</a>), como o <a href="https://openai.com/api/">GPT</a>, <a href="https://openai.com/api/">ChatGPT</a> e outros, revolucionaram a forma como interagimos com a inteligência artificial. Eles são capazes de gerar textos coerentes, responder perguntas complexas e até mesmo criar conteúdo criativo. No entanto, esses modelos possuem uma limitação fundamental: seu conhecimento é &ldquo;congelado&rdquo; no tempo.</p>
                            </p>
                            <div class="related-post-meta">
                                <span class="related-post-date">23/03/2025</span>
                                
                                    <div class="related-post-tags">
                                        
                                            <span class="tag">RAG</span>
                                        
                                            <span class="tag">LLM</span>
                                        
                                    </div>
                                
                            </div>
                            <div class="related-post-score">
                                <modern-badge variant="info">1 tags em comum</modern-badge>
                            </div>
                        </div>
                    </article>
                
            </div>
        </div>
    

    
    
    
    
<div class="comments-section">
    <h3 class="comments-title">💬 Comentários</h3>
    <div class="comments-container">
        <script src="https://giscus.app/client.js"
                data-repo="scovl/scovl.github.io"
                data-repo-id="MDEwOlJlcG9zaXRvcnkxMzg1OTI2ODA="
                data-category="General"
                data-category-id="DIC_kwDOCELBqM4CthUV"
                data-mapping="pathname"
                data-strict="0"
                data-reactions-enabled="1"
                data-emit-metadata="0"
                data-input-position="bottom"
                data-theme="light"
                data-lang="pt"
                crossorigin="anonymous"
                async>
        </script>
    </div>
</div>

    
</article>

        </div>
    </main>
    
    
    
    <footer class="footer">
    <div class="container">
        <div class="footer-content">
            <div class="footer-links">
                
                <a href="https://github.com/scovl" target="_blank" rel="noopener noreferrer" class="footer-link">
                    GitHub
                </a>
                
                
                
                <a href="https://linkedin.com/in/vitor-lobo" target="_blank" rel="noopener noreferrer" class="footer-link">
                    LinkedIn
                </a>
                
                
                
                <a href="mailto:lobocode@gmail.com" class="footer-link">
                    Email
                </a>
                

                
                <a href="https://hachyderm.io/@lobocode" target="_blank" rel="noopener noreferrer" class="footer-link">
                    Mastodon
                </a>
                

                
                <a href="https://scovl.github.io/index.xml" target="_blank" rel="noopener noreferrer" class="footer-link">
                    RSS
                </a>
                
            </div>
            
            
            <div class="back-to-top-container">
                <button id="back-to-top" class="back-to-top-btn" aria-label="Voltar ao topo">
                    <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                        <path d="m18 15-6-6-6 6"/>
                    </svg>
                    <span data-i18n="back_to_top">Voltar ao topo</span>
                </button>
            </div>
            
            <div class="copyright">
                &copy; 2025 scovl
            </div>
        </div>
    </div>
</footer> 
    
    
    
    <script src="/vendor/prism/prism-core.min.js?v=1757193683"></script>
    <script src="/vendor/prism/prism-clike.min.js?v=1757193683"></script>
    <script src="/vendor/prism/prism-c.min.js?v=1757193683"></script>
    <script src="/vendor/prism/prism-cpp.min.js?v=1757193683"></script>
    <script src="/vendor/prism/prism-rust.min.js?v=1757193683"></script>
    <script src="/vendor/prism/prism-clojure.min.js?v=1757193683"></script>
    <script src="/vendor/prism/prism-swift.min.js?v=1757193683"></script>
    <script src="/vendor/prism/prism-bash.min.js?v=1757193683"></script>
    <script src="/vendor/prism/prism-javascript.min.js?v=1757193683"></script>
    <script src="/vendor/prism/prism-typescript.min.js?v=1757193683"></script>
    <script src="/vendor/prism/prism-autoloader.min.js?v=1757193683"></script>
    
    
    <script src="/js/main-minimal.js?v=1757193683"></script>
    <script src="/js/lazy-loading.js?v=1757193683"></script>
    <script src="/js/toc.js?v=1757193683"></script>
    
    
    
</body>
</html> 