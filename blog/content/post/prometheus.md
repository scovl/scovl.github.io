+++
title = "Prometheus e PromQL"
description = "Guia completo"
date = 2025-07-27T23:10:18-03:00
tags = ["Prometheus", "Grafana", "Monitoring", "TSDB", "DevOps", "Observability", "PromQL"]
draft = false
weight = 3
+++


O **[Prometheus](https://prometheus.io/)** √© uma ferramenta open-source de monitoramento de sistemas e aplica√ß√µes que revolucionou a forma de pensar observabilidade em ambientes distribu√≠dos. Ele coleta e armazena m√©tricas como s√©ries temporais, ou seja, valores num√©ricos associados a um carimbo de tempo e a pares chave-valor chamados **[labels](https://prometheus.io/docs/concepts/data_model/#metric-names-and-labels)**. 

> A pot√™ncia do Prometheus vem, em parte, da sua linguagem de consulta pr√≥pria, **[PromQL](https://prometheus.io/docs/prometheus/latest/querying/basics/)**, que permite criar consultas complexas para analisar os dados coletados em tempo real. A interface web integrada (Expression browser) facilita visualizar e explorar m√©tricas, possibilitando an√°lises r√°pidas para identificar tend√™ncias e anomalias.

Desenvolvido inicialmente na SoundCloud em 2012 por [Julius Volz](https://github.com/juliusv) e equipe, o Prometheus foi projetado para ser simples, eficiente e altamente dimension√°vel. Em 2016, o projeto foi adotado pela **[Cloud Native Computing Foundation (CNCF)](https://www.cncf.io/)** como o segundo projeto hospedado (logo ap√≥s o [Kubernetes](https://kubernetes.io/)), refor√ßando sua maturidade e ampla ado√ß√£o pela comunidade. 

> Hoje, o Prometheus √© um pilar no ecossistema de observabilidade cloud-native, frequentemente usado em conjunto com o Grafana para visualiza√ß√µes avan√ßadas, formando uma poderosa stack de monitoramento.

## Tipos de m√©tricas

O Prometheus suporta quatro tipos principais de m√©tricas:

* **[Counter (Contador)](https://prometheus.io/docs/concepts/metric_types/#counter)**: M√©trica cumulativa que apenas aumenta (ou zera). Indicada para quantificar eventos, como n√∫mero de requisi√ß√µes ou erros. Por exemplo, um contador `http_requests_total` incrementa a cada requisi√ß√£o recebida. Contadores nunca diminuem, exceto quando reiniciados. Consultas comuns envolvem a taxa de aumento usando fun√ß√µes como `rate()` ou `increase()`, calculando, por exemplo, quantas requisi√ß√µes por segundo ocorreram em determinado intervalo.

* **[Gauge (Indicador)](https://prometheus.io/docs/concepts/metric_types/#gauge)**: M√©trica que representa um valor em um instante, podendo tanto aumentar quanto diminuir. Indicado para valores como utiliza√ß√£o de CPU, mem√≥ria ou tamanho de fila ‚Äì que sobem e descem livremente. N√£o possui limite m√≠nimo ou m√°ximo fixo. Fun√ß√µes como `avg_over_time()`, `min()`, `max()` e `sum()` s√£o frequentemente aplicadas sobre gauges para obter m√©dias, m√≠nimos, m√°ximos ou somas ao longo do tempo.

* **[Histogram (Histograma)](https://prometheus.io/docs/concepts/metric_types/#histogram)**: M√©trica que contabiliza a distribui√ß√£o de valores observados em *buckets* (faixas) predefinidos. √â muito utilizada para medir lat√™ncias (e.g., dura√ß√£o de requisi√µes) ou outros valores cuja distribui√ß√£o importa. O Prometheus implementa histogramas atrav√©s de v√°rios contadores ‚Äì um por bucket ‚Äì al√©m de contadores especiais para total de observa√ß√µes (`_count`) e soma dos valores (`_sum`). Consultas tipicamente usam `histogram_quantile()` para extrair percentis a partir dos buckets e fun√ß√µes como `rate()` ou `increase()` nos contadores para ver taxas.

* **[Summary (Sum√°rio)](https://prometheus.io/docs/concepts/metric_types/#summary)**: M√©trica similar ao histograma, mas os c√°lculos de percentis e m√©dias s√£o feitos pelo pr√≥prio alvo instrumentado. O summary fornece diretamente percentis (por exemplo, lat√™ncia p95) e contagens/agregados para um conjunto de observa√ß√µes. Entretanto, summaries t√™m a limita√ß√£o de n√£o poderem ser agregados facilmente entre m√∫ltiplas inst√¢ncias (diferente dos histogramas). Em geral, histogramas s√£o preferidos para m√©tricas de lat√™ncia quando se quer combinar valores de v√°rias fontes, enquanto summaries podem ser √∫teis para percentis muito espec√≠ficos em inst√¢ncias isoladas.

> Use Histogramas quando precisar agregar lat√™ncias de m√∫ltiplas inst√¢ncias e calcular percentis globais. Use Sum√°rios quando os percentis calculados no cliente s√£o suficientes e a agrega√ß√£o n√£o √© necess√°ria.

Al√©m desses tipos principais, o Prometheus exp√µe m√©tricas especiais de estado ‚Äì por exemplo, a m√©trica interna `up` indica se um determinado alvo foi coletado com sucesso (valor 1) ou n√£o (0). Essa m√©trica √© muito √∫til para monitorar disponibilidade de servi√ßos: se um **endpoint** monitorado ficar indispon√≠vel, `up{instance="endpoint:porta"} == 0` sinaliza falha. Vale notar que n√£o existe um "tipo" separado para essas m√©tricas de sa√∫de; elas normalmente s√£o gauges (0 ou 1) usadas para esse prop√≥sito.

## Monitoramento pull vs push

Para entender **pull** vs **push**, imagine cuidar de plantas: no modelo **pull** voc√™ vai todo dia verificar se precisam de √°gua; no modelo **push** as pr√≥prias plantas enviam um sinal quando precisam ser regadas. Tecnicamente, no monitoramento **pull** um sistema central (como o Prometheus) consulta periodicamente os alvos para coletar m√©tricas ‚Äì ele "puxa" as informa√ß√µes. J√° no monitoramento **push**, os pr√≥prios alvos enviam (*empurram*) as m√©tricas para um coletor central sem serem solicitados.

![](https://raw.githubusercontent.com/scovl/scovl.github.io/main/post/images/tsdb/prom-pullvspush.png)

No Prometheus, prevalece o modelo pull. O servidor Prometheus periodicamente faz **scrape** (raspagem) dos dados de cada alvo exportador via HTTP, no endpoint padr√£o `/metrics`. Cada scrape coleta o valor atual de todas as s√©ries expostas naquele alvo.

Os alvos podem ser aplica√ß√µes instrumentadas que exp√µem suas m√©tricas diretamente, ou **exporters** (exportadores) que traduzem m√©tricas de sistemas externos para o formato do Prometheus.

Assim, o Prometheus obt√©m em intervalos regulares (por padr√£o a cada 15s) as m√©tricas atuais de cada servi√ßo, armazenando-as localmente.

Na imagem acima, a compara√ß√£o dos modelos de coleta: √† esquerda, no modo push os clientes enviam suas m√©tricas proativamente a um gateway; √† direita, no modo pull o Prometheus consulta cada cliente periodicamente. O modelo pull tem vantagens em simplicidade e confiabilidade ‚Äì se um servi√ßo cair, o Prometheus sabe (a m√©trica `up` fica 0) e n√£o depende de buffers intermedi√°rios. 

J√° o modelo push pode ser √∫til para casos espec√≠ficos, como *jobs* de curta dura√ß√£o ou ambientes onde n√£o √© poss√≠vel expor um endpoint (nesses casos usa-se o **Pushgateway**, discutido adiante). Em suma, o Prometheus, por padr√£o, **n√£o** recebe m√©tricas ativamente; ele mesmo vai colet√°-las, evitando sobrecarga nos aplicativos monitorados e detectando automaticamente indisponibilidades.

## Arquitetura do Prometheus

A arquitetura do Prometheus foi concebida para facilitar a coleta de dados de m√∫ltiplas fontes de forma confi√°vel e distribu√≠da. O cora√ß√£o do sistema √© o **[Prometheus Server](https://prometheus.io/docs/prometheus/latest/components/prometheus/)** principal, respons√°vel por agendar e realizar as coletas (*scrapes*) de cada alvo monitorado e armazenar as s√©ries temporais resultantes localmente. 

A configura√ß√£o dessas coletas √© definida em um arquivo YAML (geralmente `prometheus.yml`), especificando **[jobs](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#job_name)** e **[targets](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#static_configs)** ‚Äì por exemplo, "coletar m√©tricas do servi√ßo X na URL Y a cada 15 segundos". A figura abaixo (extra√≠da da documenta√ß√£o oficial) ilustra a arquitetura e os componentes do ecossistema Prometheus:

![](https://raw.githubusercontent.com/scovl/scovl.github.io/refs/heads/main/blog/content/post/images/tsdb/arch.png)

Em resumo, o fluxo √©: o Prometheus **coleta (pull)** m√©tricas dos jobs instrumentados, diretamente dos servi√ßos ou via um componente intermedi√°rio de push para jobs ef√™meros. Todos os samples coletados s√£o armazenados localmente no banco de dados de s√©ries temporais embutido ([TSDB](https://prometheus.io/docs/prometheus/latest/storage/tsdb/)). 

Regras definidas podem ser executadas continuamente sobre esses dados ‚Äì seja para gravar novas s√©ries agregadas ([recording rules](https://prometheus.io/docs/prometheus/latest/configuration/recording_rules/)) ou para acionar **[alertas](https://prometheus.io/docs/prometheus/latest/configuration/alerting_rules/)**. Os alertas gerados pelo Prometheus s√£o ent√£o enviados para o **[Alertmanager](https://prometheus.io/docs/alerting/latest/alertmanager/)** processar. Por fim, ferramentas de visualiza√ß√£o como o **[Grafana](https://grafana.com/)** podem consultar o Prometheus para exibir dashboards das m√©tricas coletadas.

O ecossistema Prometheus possui diversos componentes (muitos opcionais) que interagem nessa arquitetura:

* **[Servidor Prometheus](https://prometheus.io/docs/prometheus/latest/components/prometheus/)** ‚Äì o servidor principal que coleta e armazena as m√©tricas e processa consultas PromQL.
* **[Bibliotecas cliente](https://prometheus.io/docs/instrumenting/clientlibs/)** ‚Äì usadas para instrumentar c√≥digo de aplica√ß√µes (expondo m√©tricas via /metrics). H√° libs oficiais em Go, Java, Ruby, Python, etc.
* **[Exporters](https://prometheus.io/docs/instrumenting/exporters/)** ‚Äì programas externos que coletam m√©tricas de servi√ßos ou sistemas terceiros (bancos de dados, servidores web, sistemas operacionais) e as exp√µem no formato Prometheus. Exemplos: Node Exporter (m√©tricas de sistema Linux), Blackbox Exporter (monitoramento de endpoints externos), etc.
* **[Pushgateway](https://prometheus.io/docs/instrumenting/pushing/)** ‚Äì gateway para receber m√©tricas *pushed* por aplicativos de curta dura√ß√£o ou ambientes onde n√£o d√° para o Prometheus puxar diretamente.
* **[Alertmanager](https://prometheus.io/docs/alerting/latest/alertmanager/)** ‚Äì componente respons√°vel por receber alertas enviados pelo Prometheus e gerenciar o envio de notifica√ß√µes (email, Slack, PagerDuty etc.), realizando agrupamento, deduplica√ß√£o e silenciamento conforme configurado.
* **[Ferramentas de suporte](https://prometheus.io/docs/prometheus/latest/tools/)** ‚Äì englobam utilit√°rios de linha de comando (como o promtool), exportadores de terceiros, dashboards pr√©-configurados, entre outros, que facilitam operar e integrar o Prometheus.

Essa arquitetura descentralizada (com coleta **[pull](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#pull_interval)** e componentes distintos) torna o Prometheus especialmente adequado a ambientes modernos com microsservi√ßos e orquestra√ß√£o de cont√™ineres ([Docker](https://www.docker.com/), [Kubernetes](https://kubernetes.io/)). 

Ele foi projetado para funcionar de forma aut√¥noma em cada n√≥ (cada servidor Prometheus √© independente, sem depend√™ncia de armazenamento distribu√≠do), privilegiando confiabilidade mesmo durante falhas de rede ou de outros servi√ßos. Em caso de problemas graves na infraestrutura, voc√™ ainda consegue acessar m√©tricas recentes localmente no Prometheus, que atua como fonte de verdade para diagnosticar incidentes.

## Labels e Samples

No Prometheus, **[labels](https://prometheus.io/docs/concepts/data_model/#metric-names-and-labels)** (r√≥tulos) e **[samples](https://prometheus.io/docs/concepts/data_model/#samples-and-series)** (amostras) s√£o conceitos-chave para organizar os dados monitorados.

Uma analogia simples: imagine um guarda-roupa onde cada roupa tem etiquetas indicando cor, tamanho e tipo. Essas etiquetas ajudam a encontrar rapidamente, por exemplo, "camisetas verdes tamanho M".

Da mesma forma, no Prometheus cada m√©trica pode ter v√°rios **[labels](https://prometheus.io/docs/concepts/data_model/#metric-names-and-labels)** (chave=valor) que a qualificam. 

Por exemplo, uma m√©trica `app_memory_usage_bytes` poderia ter labels como `host="servidor1"` e `region="us-east"`. Assim podemos filtrar/consultar "uso de mem√≥ria no servidor1" apenas buscando por `host="servidor1"`.

Os **[labels](https://prometheus.io/docs/concepts/data_model/#metric-names-and-labels)** permitem um modelo de dados multidimensional ‚Äì ou seja, uma mesma m√©trica (ex: `http_requests_total`) √© armazenada separadamente para cada combina√ß√£o de labels (rota="/login", m√©todo="GET", c√≥digo="200", etc.). Isso enriquece as an√°lises, pois podemos agregar ou dividir m√©tricas por essas dimens√µes conforme necess√°rio.

![](https://raw.githubusercontent.com/scovl/scovl.github.io/master/post/images/tsdb/samples01.png)

J√° os **[samples](https://prometheus.io/docs/concepts/data_model/#samples-and-series)** s√£o as unidades de dado coletadas ao longo do tempo ‚Äì cada medi√ß√£o individual de uma m√©trica em um determinado instante.

Voltando √† analogia, se ped√≠ssemos a cada crian√ßa numa pesquisa que escolhesse 3 balas, as balas escolhidas por cada crian√ßa seriam uma **amostra** da prefer√™ncia de balas.

No contexto do Prometheus, a cada scrape o valor de cada m√©trica coletada √© um sample (com timestamp e valor). Esses samples ficam armazenados como uma s√©rie temporal etiquetada, permitindo ver a evolu√ß√£o daquele valor no tempo.

Por exemplo, considere a m√©trica gauge `node_cpu_usage` com label `host`. Para cada host monitorado, teremos uma s√©rie separada, e a cada intervalo de coleta obtemos um sample novo do uso de CPU daquele host. Assim, podemos consultar a s√©rie para ver como a CPU variou ao longo de um dia inteiro para cada m√°quina.

> **Exemplo de s√©ries temporais no Prometheus**: cada ponto representa um sample (valor observado) etiquetado por inst√¢ncia ou outra dimens√£o, armazenado em sequ√™ncia temporal.

Em resumo, **[labels](https://prometheus.io/docs/concepts/data_model/#metric-names-and-labels)** fornecem contexto (quem, onde, o qu√™) e **[samples](https://prometheus.io/docs/concepts/data_model/#samples-and-series)** fornecem o valor num√©rico no tempo. Essa combina√ß√£o √© o que torna o Prometheus poderoso para agregar m√©tricas semelhantes e, ao mesmo tempo, permitir recortes por dimens√£o. Vale ressaltar a import√¢ncia de escolher labels com cardinalidade controlada ‚Äì ou seja, evitar labels que possam assumir valores extremamente variados (como IDs √∫nicos, URLs completas ou timestamps). 

> **Nota:** Labels com varia√ß√£o descontrolada podem causar uma explos√£o de s√©ries e sobrecarregar o Prometheus, conforme discutiremos em melhores pr√°ticas.

## Instala√ß√£o

Existem diversas maneiras de instalar e executar o Prometheus. Aqui vou demonstrar uma configura√ß√£o simples usando **[Docker](https://www.docker.com/)** e **[Docker Compose](https://docs.docker.com/compose/)**, incluindo o Grafana e uma ferramenta de simula√ß√£o de m√©tricas chamada **[PromSim](https://github.com/dmitsh/promsim)** (√∫til para testes). Essa stack de exemplo traz:

* **[Prometheus](https://prometheus.io/)** ‚Äì servidor de m√©tricas.
* **[Grafana](https://grafana.com/)** ‚Äì para dashboards e visualiza√ß√£o.
* **[PromSim](https://github.com/dmitsh/promsim)** ‚Äì um simulador que exp√µe m√©tricas aleat√≥rias para exercitar o Prometheus.

Comece criando um arquivo `docker-compose.yml` com o seguinte conte√∫do:

```yaml
version: "3"
services:
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - "./prometheus.yml:/etc/prometheus/prometheus.yml"
    depends_on:
      - promsim

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3000:3000"

  promsim:
    image: sysdigtraining/promsim:latest
    container_name: promsim
    ports:
      - "8080:8080"
```

No mesmo diret√≥rio, crie o arquivo de configura√ß√£o `prometheus.yml` para o Prometheus:

```yaml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: "promsim"
    static_configs:
      - targets: ["promsim:8080"]
```

Esse arquivo define que o Prometheus far√° scrape a cada 15s (`scrape_interval`) e avalia regras na mesma frequ√™ncia (`evaluation_interval`). Em `scrape_configs`, temos um job chamado "promsim" que coleta m√©tricas do endere√ßo `promsim:8080` (nosso container PromSim simulando um alvo de m√©tricas). Agora suba os servi√ßos:

```bash
docker-compose up -d
```

Isso iniciar√° os containers Prometheus, Grafana e PromSim em segundo plano. Ap√≥s o start, acesse o Grafana em **[http://localhost:3000](http://localhost:3000)** (usu√°rio **admin**, senha **admin** padr√£o). No Grafana, adicione o Prometheus como fonte de dados: v√° em *Configuration (engrenagem) > Data Sources*, adicione nova fonte do tipo Prometheus com URL **[http://prometheus:9090](http://prometheus:9090)** (que, devido ao Docker Compose, resolve para o container do Prometheus).

Feito isso, voc√™ j√° pode importar ou criar pain√©is Grafana usando as m√©tricas do Prometheus (inclusive as geradas pelo PromSim). O PromSim estar√° expondo v√°rias m√©tricas aleat√≥rias ‚Äì por exemplo, simulando CPU, mem√≥ria, requisi√ß√µes ‚Äì permitindo testar consultas e alertas sem precisar de uma aplica√ß√£o real por tr√°s. Para mais detalhes do PromSim, veja **[a documenta√ß√£o oficial](https://github.com/dmitsh/promsim)**.

Caso queira rodar apenas o Prometheus isoladamente, basta executar o container oficial: `docker run -p 9090:9090 prom/prometheus`. Depois acesse **[http://localhost:9090](http://localhost:9090)** para abrir a UI nativa do Prometheus:

![](https://raw.githubusercontent.com/scovl/scovl.github.io/master/post/images/tsdb/ui01.png)

A interface web padr√£o do Prometheus inclui os seguintes menus no topo:

* **[Alerts](/alerts)**: lista os alertas ativos e suas informa√ß√µes. Mostra tamb√©m alertas pendentes e silenciados.
* **[Graph](/graph)**: permite rodar consultas PromQL e visualizar o resultado em formato gr√°fico (ou tabela). √â √∫til para explorar interativamente as m√©tricas.
* **[Status](/status)**: informa√ß√µes sobre o status do servidor Prometheus ‚Äì mem√≥ria usada, n√∫mero de s√©ries ativas, status das coletas, etc.
  * **[Targets](/targets)** (na se√ß√£o Status): mostra todos os alvos configurados e se a coleta est√° OK (up) ou falhou.
  * **[Service Discovery](/service-discovery)** (tamb√©m em Status): lista os servi√ßos descobertos via mecanismos din√¢micos (Kubernetes, DNS, etc.).
* **[Help](/classic/targets)**: link para documenta√ß√£o e ajuda do Prometheus.

Al√©m disso, logo abaixo dos menus, a UI oferece algumas op√ß√µes e campos importantes:

* **[Time range e refresh](https://prometheus.io/docs/prometheus/latest/querying/basics/#time-range-and-resolution-selection)**: controles para selecionar o intervalo de tempo da consulta e atualizar automaticamente.
* **[Use local time](https://prometheus.io/docs/prometheus/latest/querying/basics/#time-range-and-resolution-selection)**: alterna entre exibir os timestamps no seu fuso hor√°rio local ou em UTC.
* **[Query history](https://prometheus.io/docs/prometheus/latest/querying/basics/#query-history)**: op√ß√£o para habilitar hist√≥rico das consultas feitas (facilita repetir queries recentes).
* **[Autocomplete](https://prometheus.io/docs/prometheus/latest/querying/basics/#autocomplete)**: op√ß√£o para habilitar auto-completar de m√©tricas e fun√ß√µes no campo de consulta.
* **[Campo de consulta PromQL](https://prometheus.io/docs/prometheus/latest/querying/basics/#expression-language-promql)**: onde voc√™ escreve a express√£o a ser consultada. O Prometheus traz sugest√µes enquanto voc√™ digita (se autocomplete ligado).
* **[Bot√µes Execute / Reset](https://prometheus.io/docs/prometheus/latest/querying/basics/#execute-and-reset)**: para executar a consulta ou limpar o campo.
* **[Aba Graph / Table](https://prometheus.io/docs/prometheus/latest/querying/basics/#graph-and-table)**: seleciona se o resultado ser√° plotado em um gr√°fico ou mostrado como tabela bruta de valores.
* **[Evaluation time](https://prometheus.io/docs/prometheus/latest/querying/basics/#evaluation-time)**: permite fixar um timestamp espec√≠fico para avaliar a query (por padr√£o √© "now", mas voc√™ pode ver valores hist√≥ricos escolhendo um hor√°rio passado).

> **Dica:** a UI do Prometheus √© √≥tima para explorar e depurar m√©tricas rapidamente, mas para dashboards permanentes e mais bonitos geralmente usamos o Grafana. O Grafana se conecta ao Prometheus via API e permite combinar m√∫ltiplas consultas em gr√°ficos customizados.

### Configura√ß√£o

Ap√≥s instalar, o principal arquivo a ajustar √© o de **[configura√ß√£o do Prometheus](https://prometheus.io/docs/prometheus/latest/configuration/configuration/)** (`prometheus.yml`). Nele definimos os par√¢metros globais, jobs de scrape, regras de alerta, etc. Vamos examinar a estrutura b√°sica e algumas customiza√ß√µes comuns. Um exemplo m√≠nimo de `prometheus.yml` poderia ser:

```yaml
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']
```

Nesse caso, definimos um intervalo global de scrape de 15s e um job para monitorar o pr√≥prio Prometheus (expondo m√©tricas em [localhost:9090](http://localhost:9090)). Para monitorar outras aplica√ß√µes, adicionamos novos blocos em `scrape_configs`. Por exemplo, para monitorar uma aplica√ß√£o web rodando na porta 8080 de um host chamado `my-app`:

```yaml
scrape_configs:
  - job_name: 'my-app'
    static_configs:
      - targets: ['my-app:8080']
```

Isso instruir√° o Prometheus a coletar periodicamente m√©tricas em **[http://my-app:8080/metrics](http://my-app:8080/metrics)**. Podemos repetir o processo para cada servi√ßo ou componente que queremos incluir, definindo um `job_name` descritivo e a lista de endpoints (targets).

Para ambientes com muitos alvos ou infraestrutura din√¢mica, √© invi√°vel gerenciar esses targets manualmente. Nesses casos, o Prometheus oferece integra√ß√µes de **Service Discovery** ([Kubernetes](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#kubernetes_sd_config), [AWS EC2](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#ec2_sd_config), [Consul](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#consul_sd_config), [DNS](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#dns_sd_config), etc.) e tamb√©m o **file-based discovery** (descoberta via arquivos). 

> Este √∫ltimo permite apontar para um ou mais arquivos JSON externos contendo a lista de targets. Assim, ferramentas externas ou scripts podem atualizar esses arquivos conforme os servi√ßos mudam, e o Prometheus percebe as altera√ß√µes automaticamente. Por exemplo, poder√≠amos alterar o job acima para usar arquivo:

```yaml
scrape_configs:
  - job_name: 'my-app'
    file_sd_configs:
      - files:
          - /etc/prometheus/targets/my-app.json
```

E no arquivo `/etc/prometheus/targets/my-app.json` colocar algo como:

```json
[
  {
    "labels": {
      "job": "my-app",
      "env": "production"
    },
    "targets": [
      "my-app1:8080",
      "my-app2:8080"
    ]
  }
]
```

Nesse JSON, especificamos dois targets (dois inst√¢ncias da aplica√ß√£o `my-app`) e tamb√©m atribu√≠mos labels adicionais a essas inst√¢ncias (`env: production`, por exemplo). Assim, se futuramente adicionarmos `my-app3:8080`, basta atualizar o JSON ‚Äì o Prometheus recarrega periodicamente ou quando o arquivo muda. Esse m√©todo facilita escalabilidade e automa√ß√£o da configura√ß√£o de alvos.

Outro ponto de configura√ß√£o importante √© a **reten√ß√£o de dados**. Por padr√£o, o Prometheus guarda as s√©ries temporais localmente por 15 dias. Em ambientes de produ√ß√£o, pode ser necess√°rio ajustar esse per√≠odo.

Voc√™ pode definir a flag de inicializa√ß√£o `--storage.tsdb.retention.time` (ou configurar no servi√ßo) para algo maior, por exemplo `30d` para reter \~1 m√™s de m√©tricas. Tenha em mente que aumentar a reten√ß√£o aumenta proporcionalmente o consumo de disco e mem√≥ria. 

Tamb√©m √© poss√≠vel limitar por tamanho de disco (`--storage.tsdb.retention.size`), se preferir. Caso precise de reten√ß√£o muito longa (meses/anos), √© recomend√°vel integrar com solu√ß√µes de armazenamento remoto em vez de manter tudo no Prometheus (falaremos disso em *Melhores Pr√°ticas*).

Exemplo de defini√ß√£o de reten√ß√£o no **[systemd](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#configuration-file)** (ExecStart):

```bash
/opt/prometheus/prometheus \
  --config.file=/opt/prometheus/prometheus.yml \
  --storage.tsdb.retention.time=30d
```

> **Nota:** O formato aceita unidades como `h`, `d`, `w`, `y`. Voc√™ tamb√©m pode usar a op√ß√£o `--storage.tsdb.retention.size` para definir um tamanho m√°ximo (por ex: `50GB`), o que ocorrer primeiro (tempo ou tamanho) aciona a limpeza de dados antigos.

Em instala√ß√µes via pacote ou container, normalmente a estrutura de diret√≥rios do Prometheus √© assim:

```
/opt/prometheus/
‚îú‚îÄ‚îÄ prometheus (bin√°rio)
‚îú‚îÄ‚îÄ promtool   (bin√°rio utilit√°rio)
‚îú‚îÄ‚îÄ prometheus.yml (configura√ß√£o)
‚îú‚îÄ‚îÄ consoles/  (arquivos HTML da UI "classic")
‚îú‚îÄ‚îÄ console_libraries/ (bibliotecas JS para consoles)
‚îî‚îÄ‚îÄ data/      (armazenamento local das s√©ries temporais)
```

A pasta `data/` merece destaque ‚Äì ali ficam todos os dados das m√©tricas coletadas. Abordaremos sua estrutura interna na se√ß√£o "Under the Hood".

> Em resumo, ap√≥s instalar, voc√™ deve editar o `prometheus.yml` para incluir todos os targets que deseja monitorar (seja listando estaticamente ou via mecanismos din√¢micos) e ajustar par√¢metros globais (intervalos, regras, reten√ß√£o). 

Depois reinicie o servi√ßo/container do Prometheus para aplicar as altera√ß√µes. Para validar se a sintaxe do arquivo est√° correta antes de reiniciar, podemos usar o **[promtool](https://prometheus.io/docs/prometheus/latest/tools/promtool/)** conforme abaixo.

## üîç Instrumenta√ß√£o

A **instrumenta√ß√£o** √© o processo de inserir coleta de m√©tricas em sistemas e aplica√ß√µes. No contexto Prometheus, podemos dividir em dois tipos:

### üìä Instrumenta√ß√£o direta (na aplica√ß√£o)

Significa instrumentar o pr√≥prio c√≥digo da aplica√ß√£o ou servi√ßo para expor m√©tricas de neg√≥cio ou de desempenho relevantes. Voc√™ adiciona pontos de m√©trica no c√≥digo ([counters](https://prometheus.io/docs/concepts/metric_types/#counter), [gauges](https://prometheus.io/docs/concepts/metric_types/#gauge), etc.) usando uma biblioteca cliente do Prometheus.

Assim, a pr√≥pria aplica√ß√£o passa a expor um endpoint `/metrics` com dados em tempo real sobre si mesma (lat√™ncia de requisi√ß√µes, uso de mem√≥ria interno, tamanho de fila, etc.).

Essa abordagem d√° controle granular ‚Äì os desenvolvedores escolhem o que medir ‚Äì e tende a fornecer m√©tricas altamente espec√≠ficas e √∫teis para diagnosticar o comportamento da aplica√ß√£o.

### üîÑ Instrumenta√ß√£o indireta (via exporters)

Refere-se a coletar m√©tricas de sistemas externos ou legados atrav√©s de componentes intermedi√°rios chamados **[exporters](https://prometheus.io/docs/instrumenting/exporters/)**. Em vez de modificar o sistema alvo, voc√™ roda um exporter que coleta informa√ß√µes daquele sistema (geralmente via APIs existentes, comandos ou leitura de arquivos) e as exp√µe no formato Prometheus. 

O Prometheus ent√£o faz scrape nesse exporter. Essa abordagem √© comum para: sistemas operacionais, bancos de dados, servidores web, ou qualquer software que n√£o tenha suporte nativo ao Prometheus.

Por exemplo, h√° exporters para **[MySQL](https://github.com/prometheus/mysqld_exporter)**, **[PostgreSQL](https://github.com/prometheus/postgres_exporter)**, **[Apache/Nginx](https://github.com/nginxinc/nginx-prometheus-exporter)**, **[Redis](https://github.com/oliver006/redis_exporter)**, entre muitos outros, que traduzem m√©tricas desses sistemas para o formato esperado.

Ambos os tipos s√£o importantes. A instrumenta√ß√£o direta fornece m√©tricas sob medida da aplica√ß√£o (por exemplo, quantas transa√ß√µes processou, quantos usu√°rios ativos, etc.), enquanto a indireta garante visibilidade de componentes de infraestrutura e softwares de terceiros sem precisar alterar eles.

A seguir, veremos exemplos de instrumenta√ß√£o indireta (principais exporters) e de instrumenta√ß√£o direta em algumas linguagens.

### Instrumenta√ß√£o indireta: Exporters

**Ecossistema nativo:** O Prometheus j√° oferece diversos exporters oficiais ou mantidos pela comunidade para sistemas populares. Alguns exemplos:

* **[Node Exporter](https://github.com/prometheus/node_exporter)** (Linux): Coleta m√©tricas de sistema operacional Linux ‚Äì CPU, mem√≥ria, disco, rede, entropia, stats de kernel, etc. √â imprescind√≠vel para monitorar VMs ou servidores bare metal. Basta executar o bin√°rio do node\_exporter no host; ele abre :9100/metrics com dezenas de m√©tricas padronizadas (cpu\_seconds\_total, node\_filesystem\_usage\_bytes, etc.). Essas m√©tricas d√£o uma visibilidade completa do estado do host, permitindo identificar gargalos de recurso.

* **[Windows Exporter](https://github.com/prometheus/wmic_exporter)** (Windows): Equivalente para plataformas Windows (antigo WMI exporter). Coleta CPU, mem√≥ria, disco, contadores do Windows, etc., expondo em :9182/metrics (porta padr√£o). Assim, ambiente heterog√™neos tamb√©m podem ser monitorados.

* **[Blackbox Exporter](https://github.com/prometheus/blackbox_exporter)**: √ötil para monitorar *externamente* a disponibilidade de servi√ßos. Ele executa *probes* do tipo ICMP (ping), HTTP(S), DNS, TCP, etc., simulando a experi√™ncia do usu√°rio externo. Voc√™ configura m√≥dulos de probe (ex: checar HTTP 200 em determinada URL dentro de 2s) e o Prometheus chama o Blackbox passando o alvo a testar. Se a resposta falha ou excede tempo, m√©tricas como `probe_success`=0 ou `probe_duration_seconds` indicam problema. √â excelente para monitorar uptime de sites e endpoints de fora para dentro.

* **[Exporters de aplica√ß√µes](https://prometheus.io/docs/instrumenting/exporters/)**: H√° muitos: PostgreSQL exporter, Redis exporter, JMX exporter (Java), SNMP exporter (equipamentos de rede), etc. Em geral, se voc√™ usar alguma tecnologia popular, provavelmente j√° existe um exporter pronto (a documenta√ß√£o oficial lista dezenas: **[Exporters e integra√ß√µes](https://prometheus.io/docs/instrumenting/exporters/)**).

> **Como usar exporters?** Normalmente √© executar o bin√°rio do exporter pr√≥ximo do servi√ßo alvo, e ent√£o adicionar um job no `prometheus.yml` apontando para o endpoint do exporter. Por exemplo, para Node Exporter em v√°rias m√°quinas, voc√™ rodaria node\_exporter em cada host (porta 9100) e adicionaria algo como:

```yaml
scrape_configs:
  - job_name: 'node'
    static_configs:
      - targets: ['host1:9100', 'host2:9100', ...]
```

Assim o Prometheus coletar√° as m√©tricas de cada m√°quina. Cada m√©trica vir√° automaticamente com labels como `instance="host1:9100"` e outras espec√≠ficas (o Node Exporter adiciona label `job="node"` e por vezes labels como `cpu="0"` para m√©tricas por CPU, etc.).

> Em resumo, a instrumenta√ß√£o indireta via exporters √© fundamental para trazer para o Prometheus dados de componentes que n√£o exp√µem nativamente as m√©tricas. √â um jeito de *bridge* (ponte) entre sistemas legados e o moderno mundo do Prometheus.

## Configura√ß√£o Avan√ßada

### Discovery Din√¢mico e Relabeling

Em ambientes modernos com infraestrutura din√¢mica (Kubernetes, cloud, microsservi√ßos), configurar targets manualmente no `prometheus.yml` torna-se invi√°vel. O Prometheus oferece mecanismos de **Service Discovery** que permitem descobrir automaticamente alvos para monitoramento, e o **Relabeling** permite transformar dinamicamente essas descobertas durante o processo de configura√ß√£o.

#### Service Discovery

O Prometheus suporta diversos mecanismos de descoberta autom√°tica:

* **[Kubernetes](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#kubernetes_sd_config)**: Descobre pods, servi√ßos, endpoints automaticamente baseado em labels e anota√ß√µes.
* **[AWS EC2](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#ec2_sd_config)**: Encontra inst√¢ncias EC2 baseado em tags.
* **[Consul](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#consul_sd_config)**: Usa o Consul como fonte de verdade para servi√ßos.
* **[DNS](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#dns_sd_config)**: Resolve nomes DNS para descobrir alvos.
* **[File-based](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#file_sd_config)**: L√™ targets de arquivos JSON/YAML que podem ser atualizados externamente.

**Exemplo de discovery Kubernetes:**

```yaml
scrape_configs:
  - job_name: 'kubernetes-pods'
    kubernetes_sd_configs:
      - role: pod
    relabel_configs:
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: true
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
        action: replace
        target_label: __metrics_path__
        regex: (.+)
      - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
        action: replace
        regex: ([^:]+)(?::\d+)?;(\d+)
        replacement: $1:$2
        target_label: __address__
```

#### Relabeling

O **relabeling** √© uma funcionalidade poderosa que permite transformar labels, nomes de targets, endere√ßos e outros metadados durante o processo de discovery. √â fundamental para:

* **Filtrar targets indesejados** (ex: excluir pods de teste)
* **Adicionar/remover labels** dinamicamente
* **Transformar endere√ßos** (ex: mascarar IPs internos)
* **Agrupar targets** logicamente

**Exemplo pr√°tico de relabeling:**

```yaml
relabel_configs:
  # Manter apenas pods com annotation prometheus.io/scrape=true
  - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
    action: keep
    regex: true
  
  # Extrair namespace como label
  - source_labels: [__meta_kubernetes_namespace]
    action: replace
    target_label: namespace
  
  # Adicionar label de ambiente baseado no namespace
  - source_labels: [namespace]
    regex: 'prod-.*'
    replacement: 'production'
    target_label: environment
  
  # Remover porta padr√£o se n√£o especificada
  - source_labels: [__address__]
    regex: '(.+):8080'
    target_label: instance
    replacement: '$1'
  
  # Filtrar targets que come√ßam com 'test'
  - action: drop
    source_labels: [__meta_kubernetes_pod_name]
    regex: 'test.*'
```

**Casos de uso comuns:**

* **Filtros de ambiente**: Manter apenas pods de produ√ß√£o, excluindo dev/test
* **Mascaramento de dados sens√≠veis**: Remover IPs internos ou informa√ß√µes de debug
* **Agrega√ß√£o por labels**: Agrupar targets por regi√£o, datacenter, time
* **Normaliza√ß√£o de nomes**: Padronizar nomes de inst√¢ncias ou servi√ßos

> **Importante**: O relabeling √© aplicado **antes** do scrape, ent√£o voc√™ pode usar `__meta_*` labels (metadados do discovery) para tomar decis√µes sobre quais targets monitorar e como rotul√°-los.

## PromQL: Os Fundamentos

PromQL √© a linguagem de consulta poderosa usada pelo Prometheus para extrair dados de m√©tricas e configurar alertas. Seu principal objetivo √© possibilitar a an√°lise e monitoramento de m√©tricas (como requisi√ß√µes HTTP por segundo ou a m√©dia de utiliza√ß√£o de CPU por servidor) por meio de express√µes que definem c√°lculos espec√≠ficos. 

O PromQL suporta fun√ß√µes matem√°ticas, opera√ß√µes booleanas e de compara√ß√£o, al√©m de agrupamento de dados e agrega√ß√µes. Ela tamb√©m conta com recursos avan√ßados, como subconsultas e fun√ß√µes de an√°lise temporal.

As consultas PromQL podem ser executadas atrav√©s da interface web do Prometheus, de APIs ou de bibliotecas de clientes. Em resumo, a PromQL √© essencial para monitorar e analisar o desempenho de sistemas com efici√™ncia e precis√£o.

A linguagem tamb√©m possibilita a cria√ß√£o de gr√°ficos e pain√©is de visualiza√ß√£o para m√©tricas, utilizando ferramentas como o Grafana. Desta forma, a PromQL se mostra fundamental para obter insights r√°pidos sobre o comportamento de aplica√ß√µes e infraestruturas.

Nesta se√ß√£o, vamos explorar os fundamentos da PromQL ‚Äî incluindo seletores, tipos de vetores e operadores b√°sicos ‚Äî e demonstrar como criar consultas simples para analisar dados de m√©tricas.

### Time Series Database (TSDB)

O Prometheus armazena os dados em um formato bin√°rio chamado TSDB (Time Series Database). O TSDB √© um banco de dados de s√©ries temporais otimizado para armazenar m√©tricas de forma eficiente.

Para simplificar o entendimento, imagine que voc√™ tem um di√°rio onde registra, todos os dias e nos mesmos hor√°rios, informa√ß√µes como a temperatura do ar, velocidade do vento e press√£o atmosf√©rica. 

> Essas informa√ß√µes s√£o armazenadas em ordem cronol√≥gica (por tempo) e podem ser consultadas para ver como variam ao longo do tempo. Essa √© a ess√™ncia de um banco de dados de s√©rie temporal: armazenar e consultar dados que possuem uma dimens√£o temporal.


Monitorar m√©tricas a partir de um banco de dados de s√©ries temporais traz v√°rias vantagens:

* **An√°lise hist√≥rica:** Por armazenar dados em ordem cronol√≥gica, √© poss√≠vel analisar tend√™ncias e padr√µes ao longo do tempo. Isso ajuda a entender como o desempenho do sistema evolui e identificar tend√™ncias que possam indicar problemas futuros.
* **Identifica√ß√£o de problemas:** Com dados hist√≥ricos, podemos investigar incidentes passados para identificar causas raiz de problemas de desempenho ou disponibilidade.
* **Alertas baseados no tempo:** Dados hist√≥ricos permitem criar alertas que consideram tend√™ncias temporais, como alertar quando um recurso tem desempenho abaixo do normal em hor√°rios espec√≠ficos ou quando h√° tend√™ncias de crescimento preocupantes.
* **Armazenamento escal√°vel:** Bancos de dados de s√©ries temporais s√£o projetados para lidar com grandes volumes de dados e escalar horizontalmente, permitindo armazenar m√©tricas sem perda de desempenho.
* **Integra√ß√£o com outras ferramentas:** A maioria das ferramentas de monitoramento suporta a coleta de dados de TSDBs, facilitando a integra√ß√£o com diversos sistemas de an√°lise e observabilidade.

Em resumo, usar um banco de dados de s√©rie temporal permite coletar, armazenar e analisar dados de m√©tricas de desempenho ao longo do tempo, possibilitando identificar problemas, tend√™ncias e padr√µes com facilidade.

O PromQL (Prometheus Query Language) √© a linguagem usada para consultar essas m√©tricas armazenadas no Prometheus. Com o PromQL, os usu√°rios criam consultas complexas para extrair informa√ß√µes acion√°veis das m√©tricas. Algumas capacidades importantes do PromQL incluem:

* **Fun√ß√µes de agrega√ß√£o:** Permitem resumir dados ao longo do tempo ou por categorias, como m√©dia, soma, m√°ximo e m√≠nimo. Por exemplo, podemos usar `avg()` para calcular a m√©dia de uma m√©trica ao longo de um per√≠odo.
* **Fun√ß√µes de filtragem:** Permitem selecionar subconjuntos das m√©tricas com base em crit√©rios. Por exemplo, podemos usar seletores para filtrar por r√≥tulos (labels) espec√≠ficos, como pegar apenas m√©tricas de um servi√ßo ou data center espec√≠fico.
* **Fun√ß√µes de transforma√ß√£o:** Permitem transformar os dados brutos em valores mais √∫teis. Por exemplo, a fun√ß√£o `rate()` calcula a taxa de mudan√ßa de um contador (como n√∫mero de requisi√ß√µes por segundo) a partir da diferen√ßa entre dois pontos no tempo.

PromQL tamb√©m suporta opera√ß√µes matem√°ticas b√°sicas (adi√ß√£o, subtra√ß√£o, multiplica√ß√£o e divis√£o) para combinar m√©tricas ou ajustar seus valores. Al√©m disso, permite o uso de operadores l√≥gicos (como `and` e `or`) para combinar express√µes e criar consultas ainda mais complexas.

Recursos avan√ßados, como uso de r√≥tulos (labels) para selecionar s√©ries espec√≠ficas e subconsultas aninhadas, tornam a PromQL uma linguagem poderosa e flex√≠vel. A seguir, exploraremos em detalhes esses conceitos e como utiliz√°-los na pr√°tica.

### Seletores de m√©tricas

Os seletores em PromQL funcionam como filtros que permitem escolher uma ou mais s√©ries de m√©tricas espec√≠ficas para consulta. Existem dois tipos principais de seletores:

* **Seletor por nome de m√©trica:** Seleciona s√©ries pelo nome da m√©trica. Por exemplo, `http_requests_total` retorna todas as s√©ries temporais cuja m√©trica tenha esse nome.
* **Seletor por label:** Seleciona s√©ries com base em um ou mais labels (r√≥tulos) e seus valores. Por exemplo, se uma m√©trica `http_requests_total` possui os labels `method` e `handler`, podemos filtrar pelas s√©ries onde `method="GET"` e `handler="/api/v1/users"` escrevendo:

```promql
http_requests_total{method="GET", handler="/api/v1/users"}
```

Para combinar seletores de label, usamos operadores de correspond√™ncia (matchers) como `=`, `!=`, `=~` (regex correspondente) e `!~` (regex negativa). Esses operadores servem para comparar valores de labels (ou aplicar express√µes regulares) ao selecionar as s√©ries desejadas. Veja alguns exemplos:

* **Selecionar todas as m√©tricas cujo nome come√ßa com "http":**

```promql
{__name__=~"http.*"}
```

  Aqui, usamos o label especial `__name__` (que representa o nome da m√©trica) com uma express√£o regular para corresponder qualquer m√©trica cujo nome comece com "http".

* **Selecionar s√©ries que possuem o label `status` com valor exatamente "error":**

```promql
{status="error"}
```

* **Selecionar s√©ries que possuem o label `app` com valor "frontend" ou "backend":**

```promql
{app=~"frontend|backend"}
```

  Nesse caso, o operador regex `=~` com o padr√£o `frontend|backend` faz o seletor pegar s√©ries cujo label `app` seja "frontend" **ou** "backend".

Ao usar express√µes regulares em seletores, √© importante ter cuidado para n√£o selecionar s√©ries indesejadas. Por exemplo, um seletor como `{job=~"prom.*"}` traria **todas** as s√©ries cujos labels `job` come√ßam com "prom" ‚Äî isso poderia incluir s√©ries que n√£o eram o alvo pretendido (como um job auxiliar relacionado).

Portanto, sempre procure ser o mais espec√≠fico poss√≠vel nos seletores para evitar correspond√™ncias acidentais.

### Tipos de express√µes em PromQL

PromQL oferece v√°rios tipos de express√µes para manipular as s√©ries temporais coletadas pelo Prometheus. As principais incluem:

* **Express√µes aritm√©ticas:** Realizam c√°lculos matem√°ticos entre s√©ries de m√©tricas ou entre s√©ries e constantes. Por exemplo, podemos somar duas m√©tricas (`metric_a + metric_b`), subtrair (`metric_a - metric_b`), multiplicar (`metric_a * 100` para converter em porcentagem), etc. Exemplo:

```promql
node_cpu_seconds_total{mode="system"} / node_cpu_seconds_total{mode="idle"} * 100
```

  Aqui calculamos a porcentagem de tempo que a CPU est√° no modo `"system"` em rela√ß√£o ao tempo no modo `"idle"`.

* **Fun√ß√µes de agrega√ß√£o:** Agrupam e resumem s√©ries temporais. As fun√ß√µes incluem `sum` (soma), `avg` (m√©dia), `max` (m√°ximo), `min` (m√≠nimo), `count` (contagem), entre outras. Por exemplo:

```promql
sum(rate(http_requests_total[5m])) by (job)
```

  Nesta consulta, calculamos a taxa de requisi√ß√µes HTTP nos √∫ltimos 5 minutos (`rate(http_requests_total[5m])`) e em seguida somamos por `job`, ou seja, obtemos a taxa total por job.

* **Fun√ß√µes de filtro:** Filtram s√©ries temporais com base em valores ou labels. Por exemplo, a fun√ß√£o `topk(5, metric)` retorna as 5 s√©ries com os maiores valores para a m√©trica especificada. Exemplo:

```promql
topk(5, http_requests_total)
```

  Isso retornar√° as 5 s√©ries de `http_requests_total` com os maiores valores.

* **Fun√ß√µes de transforma√ß√£o:** Transformam s√©ries temporais de maneiras espec√≠ficas. Exemplos incluem:

  * `rate()`: calcula a taxa de aumento por segundo de um contador (derivada primeira) em uma janela de tempo.
  * `irate()`: similar ao `rate()`, mas calcula a taxa instant√¢nea entre os dois pontos de dados mais recentes.
  * `increase()`: calcula o total acumulado que o contador aumentou durante o per√≠odo.
  * `delta()`: calcula a diferen√ßa absoluta entre o primeiro e o √∫ltimo valor em uma janela de tempo.
  * `histogram_quantile()`: calcula um quantil (por exemplo, 0.95 para 95¬∫ percentil) a partir de um histograma.

  Exemplo de transforma√ß√£o com `histogram_quantile`:

  ```promql
  histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))
  ```

  Acima, estamos calculando o 95¬∫ percentil da distribui√ß√£o de dura√ß√£o de requisi√ß√µes HTTP nos √∫ltimos 5 minutos, usando as s√©ries `_bucket` do histograma de dura√ß√£o.

* **Express√µes booleanas (compara√ß√µes):** Avaliam condi√ß√µes verdadeiras ou falsas sobre os valores de s√©ries temporais. Os operadores de compara√ß√£o incluem `==` (igual), `!=` (diferente), `>` (maior que), `<` (menor que), `>=` (maior ou igual) e `<=` (menor ou igual). Por padr√£o, ao comparar duas s√©ries, o resultado √© uma s√©rie booleana (1 para true, 0 para false) **apenas para as combina√ß√µes de s√©ries que correspondem exatamente nos labels** (veremos mais sobre correspond√™ncia de vetores adiante). Tamb√©m √© poss√≠vel usar o modificador `bool` para for√ßar o resultado booleano a ser retornado.

  Um exemplo de express√£o booleana combinada com c√°lculo:

```promql
rate(http_requests_total{status_code=~"5.."}[1m]) 
  > rate(http_requests_total{status_code=~"2.."}[1m]) * 0.1
```

Esta consulta verifica se a taxa de requisi√ß√µes HTTP com c√≥digos de status 5xx no √∫ltimo minuto √© maior que 10% da taxa de requisi√ß√µes 2xx no mesmo per√≠odo. O resultado ser√° uma s√©rie temporal booleana indicando, para cada combina√ß√£o de labels, se a condi√ß√£o √© verdadeira (1) ou falsa (0). Essa abordagem √© √∫til em alertas.

### Vector vs. Range Vector

Em PromQL, existem dois tipos principais de vetor que podem ser retornados em consultas: **Instant Vector** (vetor instant√¢neo) e **Range Vector** (vetor de intervalo).

* **Instant Vector (Vetor Instant√¢neo):** Representa um conjunto de amostras (valor + timestamp) de m√∫ltiplas s√©ries temporais, todas no mesmo instante no tempo. Cada s√©rie temporal no resultado possui os mesmos labels originais e um √∫nico valor correspondente ao momento da avalia√ß√£o. Por exemplo, a express√£o `cpu_usage{instance="webserver-1"}` retornaria, no momento atual, o valor mais recente da m√©trica `cpu_usage` para a inst√¢ncia `webserver-1`.

* **Range Vector (Vetor de Intervalo):** Representa um conjunto de s√©ries temporais, onde cada s√©rie cont√©m um conjunto de amostras dentro de um intervalo de tempo especificado. Em vez de um √∫nico valor, cada s√©rie traz todos os pontos (timestamp, valor) coletados naquele intervalo. Range vectors s√£o obtidos usando a sintaxe `[<dura√ß√£o>]` ap√≥s um seletor de m√©trica. Por exemplo, `cpu_usage{instance="webserver-1"}[5m]` retorna os √∫ltimos 5 minutos de dados da m√©trica `cpu_usage` para a inst√¢ncia `webserver-1`. As fun√ß√µes como `rate()`, `increase()` e `avg_over_time()` tipicamente esperam um range vector como entrada.

**Exemplos de uso de Instant e Range vectors:**

* Selecionando o valor **atual** (instant√¢neo) da m√©trica `cpu_usage` para a inst√¢ncia `"webserver-1"`:

```promql
cpu_usage{instance="webserver-1"}
```

* Calculando a diferen√ßa instant√¢nea entre duas m√©tricas (Instant Vector resultante):

```promql
http_requests_total - http_requests_failed
```

  Acima, subtra√≠mos, para cada combina√ß√£o de labels correspondente, o valor atual de `http_requests_failed` do valor atual de `http_requests_total`.

* Selecionando uma janela de **5 minutos** de dados da m√©trica `cpu_usage` para cada inst√¢ncia (Range Vector):

```promql
cpu_usage[5m]
```

* Calculando a taxa (por segundo) de `cpu_usage` nos √∫ltimos 5 minutos para cada inst√¢ncia (note que `rate()` retorna um Instant Vector, com a taxa calculada para cada s√©rie):

```promql
rate(cpu_usage[5m])
```

* Obtendo o valor **m√°ximo** da m√©trica `network_traffic` em um intervalo de 30 minutos, separado por inst√¢ncia:

```promql
max_over_time(network_traffic[30m]) by (instance)
```

> Resumindo: um **Instant Vector** √© adequado para consultas que requerem o valor atual (ou de um instante espec√≠fico) de uma m√©trica, enquanto um **Range Vector** √© necess√°rio para consultas que envolvem c√°lculo ao longo do tempo (taxas, m√©dias m√≥veis, etc.). Muitas fun√ß√µes do PromQL, como `rate` e `avg_over_time`, s√≥ funcionam com range vectors porque precisam de v√°rios pontos de dados para produzir um resultado.

### Seguran√ßa do seletor (Seletores seguros vs inseguros)

Ao escrever consultas PromQL, √© importante construir seletores de m√©tricas que capturem exatamente as s√©ries desejadas, evitando resultados imprecisos ou indesejados. Alguns seletores podem ser considerados "inseguros" porque podem abranger s√©ries n√£o pretendidas.

Por exemplo, usar uma correspond√™ncia de prefixo muito gen√©rica em um label pode ser problem√°tico. Considere o seletor de label `job=~"prom.*"`. Ele selecionar√° todas as s√©ries de m√©tricas cujo label `job` come√ßa com "prom".

Isso pode incluir n√£o apenas o job principal "prometheus", mas tamb√©m qualquer outro job cujo nome comece com essas letras (por exemplo, um servi√ßo "promtail" ou "prometheus-exporter"). O resultado pode ser uma consulta retornando s√©ries inesperadas.

Para garantir seletores "seguros", siga algumas pr√°ticas:

* **Seja expl√≠cito nos valores de label:** Prefira usar correspond√™ncia exata (`=` ou `!=`) ou regex precisas. Por exemplo, se voc√™ quer m√©tricas do job Prometheus, use `job="prometheus"` em vez de um regex gen√©rico.
* **Evite padr√µes muito abrangentes:** Como regra, s√≥ use regex se realmente precisar capturar m√∫ltiplos valores similares. Mesmo assim, tente restringir o padr√£o. Regex tendem a ser menos eficientes, pois precisam testar o padr√£o contra todos os valores conhecidos de um label, e podem indicar que talvez a configura√ß√£o dos labels deva ser melhorada.
* **Conhe√ßa seus labels:** Entenda quais labels cada m√©trica possui e quais valores s√£o poss√≠veis. Isso ajuda a criar seletores que n√£o tragam surpresas.

Exemplos comparando seletores seguros vs inseguros:

* **Seguro:** `http_requests_total{job="webserver", status="error"}` ‚Äì seleciona exatamente as s√©ries de requisi√ß√µes HTTP do servi√ßo `webserver` que possuem o status "error".
* **Inseguro:** `http_requests_total{status=~"err.*"}` ‚Äì poderia acidentalmente pegar algo como "erroneous" ou "errata" se esses fossem valores de status, al√©m de "error". Prefira `status="error"` se √© esse o valor exato desejado.
* **Seguro:** `{__name__=~"^http_.*_total$"}` ‚Äì seleciona m√©tricas cujo nome come√ßa com "http\_" e termina com "\_total".
* **Inseguro:** `{__name__=~"http"}` (sem √¢ncoras ou wildcards definidos) ‚Äì esse seletor est√° incompleto e potencialmente inv√°lido. Sempre especifique padr√µes completos, por exemplo `http.*` se a inten√ß√£o √© "come√ßa com http".

Em suma, construa seletores de forma cuidadosa para evitar incluir s√©ries indesejadas. Isso garante que suas consultas retornem dados precisos e tamb√©m evita sobrecarregar o Prometheus com resultados excessivos.

### Obsolesc√™ncia do vetor instant√¢neo (Staleness)

Um detalhe importante ao usar vetores instant√¢neos: o Prometheus possui um mecanismo de *staleness* (obsolesc√™ncia) para lidar com s√©ries temporais que n√£o receberam novos dados em um intervalo de tempo.

Por padr√£o, se uma m√©trica n√£o tiver amostras recentes (normalmente nos √∫ltimos 5 minutos), o PromQL considerar√° essa s√©rie como **ausente** ou retornar√° um valor `NaN` (not a number) em vez de continuar mostrando um valor antigo. Isso evita apresentar dados "velhos" como se fossem atuais.

Por√©m, em algumas consultas, especialmente ao criar alertas, queremos detectar explicitamente quando uma m√©trica parou de ser enviada. Existem maneiras de lidar com isso:

* **Aumentar a janela de consulta**: Em vez de consultar apenas o valor instant√¢neo, podemos consultar em uma janela de tempo para ver se h√° dados recentes. Por exemplo, usar uma subconsulta com intervalo:

```promql
http_requests_total[5m]
```

  garante que estamos inspecionando 5 minutos de dados. Ou ent√£o, usar fun√ß√µes como `max_over_time(metric[5m])` para pegar o √∫ltimo valor nos √∫ltimos 5 minutos.

* **Usar fun√ß√µes de aus√™ncia**: O PromQL oferece a fun√ß√£o `absent()` que retorna 1 se a express√£o dentro dela n√£o retornar nenhum dado. Por exemplo:

```promql
absent(rate(http_requests_total[5m]))
```

  retornar√° 1 (com um label indicando a s√©rie buscada) se **nenhuma** s√©rie `http_requests_total` tiver dados nos √∫ltimos 5 minutos ‚Äì ou seja, indicando que possivelmente a coleta parou. Caso exista qualquer dado, `absent()` retorna uma s√©rie vazia.

Tamb√©m h√° a variante `absent_over_time(metric[dura√ß√£o])`, que verifica se *no intervalo dado* a m√©trica esteve ausente o tempo todo.

* **Combinar com condi√ß√µes booleanas**: Podemos filtrar s√©ries pelo timestamp de sua √∫ltima amostra. A fun√ß√£o `timestamp(metric)` retorna o timestamp da √∫ltima amostra daquela m√©trica. Assim, express√µes como:

```promql
timestamp(cpu_usage) < time() - 30
```

  identificam s√©ries cujo √∫ltimo timestamp √© inferior a 30 segundos atr√°s, ou seja, possivelmente desatualizadas.

Exemplos pr√°ticos:

* **Verificar m√©tricas ausentes**:

```promql
http_requests_total unless absent(rate(http_requests_total[5m]))
```

  Aqui, usamos `unless` (que retorna a s√©rie da esquerda exceto quando a da direita existe) para s√≥ manter `http_requests_total` se ela n√£o estiver ausente nos √∫ltimos 5m. Isso efetivamente filtra fora s√©ries que n√£o receberam dados recentes.

* **Filtrar inst√¢ncias inativas (n√£o reportando)**:

```promql
cpu_usage unless absent_over_time(cpu_usage[2m])
```

  Essa consulta retornaria `cpu_usage` atual apenas para inst√¢ncias que tiveram dados nos √∫ltimos 2 minutos. Se alguma inst√¢ncia parou de reportar (logo, ausente nos √∫ltimos 2m), ela ser√° exclu√≠da do resultado.

* **Combinar timestamp e booleano**:

```promql
cpu_usage * on(instance) group_left() ((time() - timestamp(cpu_usage)) < 30)
```

Esta express√£o resulta no valor de `cpu_usage` apenas para inst√¢ncias cujo √∫ltimo timestamp tem menos de 30 segundos de idade. Estamos multiplicando o valor atual de `cpu_usage` por uma condi√ß√£o booleana que vale 1 apenas para inst√¢ncias atualizadas recentemente (e 0 para inst√¢ncias atrasadas). 

O uso de `* on(instance) group_left()` garante que combinamos corretamente cada inst√¢ncia com sua condi√ß√£o booleana.

Em resumo, devido ao comportamento de *staleness*, um vetor instant√¢neo pode n√£o mostrar valores de m√©tricas atrasadas. Para contornar isso, podemos usar janelas de tempo maiores ou fun√ß√µes especiais como `absent()` para tratar casos de aus√™ncia de dados.

### Fun√ß√µes Matem√°ticas e Clamping

As fun√ß√µes em PromQL permitem manipular e processar m√©tricas de diversas formas. Dentre as mais comuns est√£o as **fun√ß√µes matem√°ticas**, que realizam opera√ß√µes aritm√©ticas sobre as s√©ries de m√©tricas. Temos desde as opera√ß√µes b√°sicas at√© fun√ß√µes matem√°ticas de biblioteca. Alguns exemplos:

* `sqrt(vector)`: retorna a raiz quadrada de cada valor no vetor.
* `exp(vector)`: retorna o exponencial (e^x) de cada valor.
* `ln(vector)`: logaritmo natural.
* `log10(vector)`, `log2(vector)`: logaritmos base 10 e base 2, respectivamente.
* `ceil(vector)`, `floor(vector)`: arredondamento para cima ou baixo.

Al√©m disso, PromQL fornece fun√ß√µes para limitar valores extremos (*clamping*). As fun√ß√µes `clamp_min(vector, scalar)` e `clamp_max(vector, scalar)` limitam os valores de um vetor a um m√≠nimo ou m√°ximo especificado. Por exemplo:

* `clamp_min(metric, 0)`: garante que nenhum valor da s√©rie `metric` seja menor que 0 (valores negativos seriam substitu√≠dos por 0).
* `clamp_max(usage_ratio, 1)`: garante que valores acima de 1 em `usage_ratio` (por exemplo, 100% de uso) sejam reduzidos para 1.

Essas fun√ß√µes de clamping s√£o √∫teis para evitar que ru√≠dos ou anomalias atrapalhem visualiza√ß√µes. Por exemplo, se um c√°lculo produz temporariamente um valor negativo ou um valor absurdamente alto por conta de algum atraso ou jitter, podemos usar clamping para limitar a escala dos gr√°ficos.

**Exemplos de uso de fun√ß√µes matem√°ticas e clamping:**

* Calcular a **m√©dia** dos valores de uma m√©trica nos √∫ltimos 5 minutos:

```promql
avg_over_time(metric_name[5m])
```

* Calcular a **soma** dos valores de uma m√©trica nos √∫ltimos 10 minutos:

```promql
sum_over_time(metric_name[10m])
```

* Calcular o **m√°ximo** valor de uma m√©trica nos √∫ltimos 1 hora, filtrando por um label:

```promql
max_over_time(metric_name{label="value"}[1h])
```

* Limitar o valor de uma m√©trica entre 0 e 100:

```promql
clamp_min(clamp_max(metric_name, 100), 0)
```

  *(Aplica `clamp_max` para limitar a 100 e depois `clamp_min` para garantir m√≠nimo 0.)*

* Converter uma fra√ß√£o em porcentagem e garantir que n√£o passe de 100%:

```promql
clamp_max(success_ratio * 100, 100)
```

Supondo que `success_ratio` seja uma m√©trica ou express√£o que resulta em um valor entre 0 e 1 (por exemplo, propor√ß√£o de sucesso), multiplicamos por 100 para obter porcentagem e usamos `clamp_max` para nunca exibir acima de 100%.

Conhecer e utilizar essas fun√ß√µes permite realizar consultas mais avan√ßadas e obter insights mais precisos a partir dos dados coletados.

### Timestamps e Fun√ß√µes de Tempo e Data

No PromQL, *timestamps* (carimbos de tempo) s√£o representados internamente como n√∫meros de ponto flutuante indicando segundos desde a √©poca Unix (1¬∫ de janeiro de 1970, 00:00:00 UTC).

Embora normalmente n√£o precisemos lidar diretamente com o valor num√©rico do timestamp, h√° fun√ß√µes √∫teis relacionadas ao tempo:

* `time()`: retorna o timestamp Unix do momento atual (momento da avalia√ß√£o da consulta). Pode ser utilizado, por exemplo, para calcular diferen√ßas de tempo.
  *Exemplo:* `time() - 3600` produziria um valor de timestamp correspondente a uma hora atr√°s.

* `timestamp(vetor)`: retorna, para cada s√©rie no vetor dado, o timestamp da √∫ltima amostra daquela s√©rie. √ötil para compara√ß√µes e detec√ß√£o de desatualiza√ß√£o (como visto anteriormente).

Al√©m disso, existem fun√ß√µes para extrair componentes de data/hora do timestamp de cada amostra de uma s√©rie:

* `day_of_week(vetor)`: retorna o dia da semana (0‚Äì6, onde 0 = domingo, 1 = segunda, etc.) de cada amostra no vetor dado.
* `hour(vetor)`: retorna a hora (0‚Äì23) do timestamp de cada amostra.
* `day(vetor)`, `month(vetor)`, `year(vetor)`: retornam respectivamente o dia do m√™s, o m√™s (1‚Äì12) e o ano do timestamp de cada amostra.

Essas fun√ß√µes permitem criar consultas que dependem da hora ou dia. Por exemplo, voc√™ pode querer detectar padr√µes diurnos ou disparar alertas apenas em dias √∫teis.

**Exemplos de uso de fun√ß√µes de tempo e data:**

* Obter o timestamp atual (como escalar):

```promql
time()
```

* Extrair a hora atual do dia como um valor (0‚Äì23):

```promql
hour(vector( time() ))
```

  Aqui, `vector(time())` converte o escalar retornado por `time()` em um vetor (necess√°rio porque `hour()` espera um vetor). O resultado √© um vetor com um √∫nico valor: a hora do dia.

* Calcular a m√©dia de uma m√©trica por hora do dia, nos √∫ltimos 24h (usando subconsulta para separar por hora):

```promql
avg_over_time(my_metric[1h])[24h:1h]
```

Essa express√£o √© uma subconsulta que calcula `avg_over_time(my_metric[1h])` (m√©dia de `my_metric` em cada janela de 1h) para cada hora nas √∫ltimas 24 horas. Isso produz uma s√©rie de 24 pontos, um para cada hora, que pode ser √∫til para observar a varia√ß√£o hor√°ria.

* Selecionar o valor m√©dio da m√©trica `my_metric` no √∫ltimo dia:

```promql
avg_over_time(my_metric[1d])
```

  (Assumindo que h√° dados suficientes para cobrir o √∫ltimo dia inteiro.)

* **Nota:** Para consultar um per√≠odo espec√≠fico (entre timestamps espec√≠ficos), n√£o h√° uma sintaxe direta dentro do PromQL. Em vez disso, usa-se a API de consulta de intervalos do Prometheus (fornecendo `start` e `end` no request) ou ferramentas como Grafana para delimitar visualmente o per√≠odo. Dentro do PromQL, opera√ß√µes de tempo s√£o relativas (como "√∫ltimos 5 minutos", "√∫ltimas 24h", etc.) em rela√ß√£o ao momento de avalia√ß√£o.

### Counter Range Vectors, Agrega√ß√£o Temporal e Subconsultas

**Counter Range Vectors**: Contadores s√£o m√©tricas que apenas aumentam (ou resetam para zero e voltam a aumentar). Exemplos: n√∫mero total de requisi√ß√µes atendidas, bytes transferidos, etc. Quando consultamos diretamente um *counter* como range vector, obteremos uma s√©rie de pontos que s√≥ crescem (com eventuais resets). Para extrair informa√ß√µes √∫teis (como taxa de eventos por segundo ou aumentos em determinado per√≠odo) usamos fun√ß√µes especiais:

* `rate(counter[5m])`: Calcula a **taxa m√©dia por segundo** de incremento do contador nos √∫ltimos 5 minutos. Essa fun√ß√£o j√° lida corretamente com resets do contador (ignorando as quedas abruptas devido a resets e calculando a taxa considerando isso).
* `irate(counter[5m])`: Calcula a **taxa instant√¢nea** (baseada apenas nos dois pontos mais recentes dentro dos 5 minutos). √â mais ruidosa, mas pode reagir mais rapidamente a mudan√ßas repentinas.
* `increase(counter[1h])`: Calcula **quanto o contador aumentou** no √∫ltimo 1 hora. Essencialmente integra a taxa ao longo do per√≠odo.

**Agrega√ß√£o atrav√©s do tempo (Aggregating Across Time)**: √Äs vezes, queremos primeiro agregar os dados e depois analisar a evolu√ß√£o temporal dessa agrega√ß√£o. As **subconsultas** nos permitem isso. Uma *subquery* (subconsulta) √© quando temos uma express√£o do PromQL seguida de um intervalo entre colchetes e possivelmente uma resolu√ß√£o, por exemplo: `expr[dura√ß√£o:passo]`. Isso faz o Prometheus avaliar `expr` repetidamente ao longo do intervalo dado, produzindo um range vector como resultado.

Por exemplo, `avg_over_time(rate(http_requests_total[1m])[24h:1h])` funciona assim:

* Internamente, `rate(http_requests_total[1m])` √© avaliado para cada passo de 1h dentro das √∫ltimas 24h, gerando a taxa m√©dia por minuto calculada a cada hora.
* Em seguida, `avg_over_time(...[24h:1h])` calcula a m√©dia desses 24 valores (um por hora) **no tempo atual**. Na pr√°tica, isso nos daria a m√©dia da taxa hor√°ria de requisi√ß√µes no dia.

Subconsultas s√£o muito poderosas e foram aprimoradas a partir do Prometheus 2.7. Com elas √© poss√≠vel, por exemplo, calcular tend√™ncias, baselines e sazonalidade de forma compacta.

**Exemplos avan√ßados de subconsultas e an√°lise de tend√™ncias:**

* **Tend√™ncia de taxa de erro (janela m√≥vel):** Calcular a m√©dia da taxa de erros em janelas de 1 hora, ao longo das √∫ltimas 24 horas:

```promql
avg_over_time(
  rate(http_requests_total{status=~"5.."}[1m])[24h:1h]
)
```

Essa consulta gera 24 pontos (taxa de erro m√©dia de cada hora nas √∫ltimas 24h) e depois calcula a m√©dia disso tudo (ou seja, a m√©dia di√°ria da taxa de erro). Poder√≠amos tamb√©m omitir a fun√ß√£o externa para simplesmente visualizar a s√©rie das √∫ltimas 24 horas e identificar padr√µes de aumento ou redu√ß√£o de erros ao longo do dia.

* **Baseline de performance (compara√ß√£o com m√©dia hist√≥rica):** Comparar a performance atual com a m√©dia da √∫ltima semana:

```promql
rate(http_requests_total[5m]) 
  / avg_over_time(rate(http_requests_total[5m])[7d])
```

  Essa consulta produz uma raz√£o: valores acima de 1 indicam que a taxa atual de requisi√ß√µes est√° **acima** da m√©dia semanal; valores abaixo de 1, abaixo da m√©dia. Isso pode ser √∫til para identificar desvios significativos de tr√°fego.

* **Detec√ß√£o de anomalia sazonal (padr√£o hor√°rio):** Comparar o tr√°fego atual com o padr√£o do √∫ltimo dia:

```promql
rate(http_requests_total[5m]) 
  / avg_over_time(rate(http_requests_total[5m])[24h:1h])
```

Aqui, o denominador `avg_over_time(...[24h:1h])` produz a m√©dia da taxa em cada hora do dia anterior. Dividindo a taxa atual por esse valor da mesma hora ontem, podemos identificar se o tr√°fego est√° anormalmente alto ou baixo para este hor√°rio do dia.

* **Diferen√ßa di√°ria (subconsulta com offset):** Para calcular a diferen√ßa em uma m√©trica entre hoje e ontem, podemos usar `offset`. Exemplo:

```promql
my_metric - my_metric offset 1d
```

  Isso resulta em quanto `my_metric` variou em compara√ß√£o com exatamente 24 horas atr√°s.

* **Soma acumulada (exemplo de subconsulta):**

```promql
sum(my_counter) - sum(my_counter) offset 1d
```

Este exemplo soma o contador `my_counter` (provavelmente de v√°rias inst√¢ncias) e subtrai o valor de 1 dia atr√°s, mostrando o incremento total em um dia. Essa √© outra forma de calcular algo similar a `increase(my_counter[1d])`.

Em todos esses casos, as subconsultas `[ ... ]` est√£o permitindo observar ou reutilizar resultados ao longo do tempo dentro de uma √∫nica express√£o.

### Histogramas, Mudan√ßa de Tipo, Altera√ß√£o de Labels e Ordena√ß√£o

**Histogramas:** Em Prometheus, histogramas s√£o uma forma de metricar distribui√ß√µes de valores (dura√ß√£o de requisi√ß√µes, tamanho de payloads, etc.). Um histograma cl√°ssico consiste em m√∫ltiplas s√©ries: por conven√ß√£o, se a m√©trica base √© `request_duration_seconds`, as s√©ries ser√£o:

* `request_duration_seconds_bucket{le="0.1", ...}` (um bucket contando quantas observa√ß√µes <= 0.1s)
* v√°rios outros buckets com diferentes limites `le` (le = limite inferior ou igual)
* `request_duration_seconds_count` (contagem total de observa√ß√µes)
* `request_duration_seconds_sum` (soma total dos valores observados)

Para analisar histogramas, geralmente somamos as s√©ries `_bucket` *por limite* para agregar todas as inst√¢ncias ou r√≥tulos de interesse. **√â crucial incluir o label `le` ao agregar buckets.** Por exemplo, a forma correta de agregar um histograma de dura√ß√£o por job seria:

```promql
sum by (job, le) (rate(http_request_duration_seconds_bucket[5m]))
```

Depois de agregado adequadamente, podemos aplicar `histogram_quantile()` para extrair quantis (p50, p90, p99, etc.).

**Trabalhando corretamente com histogramas:**

* *Exemplo can√¥nico (p99 de lat√™ncia HTTP)*:

```promql
histogram_quantile(
  0.99, 
  sum(rate(http_request_duration_seconds_bucket[5m])) by (le)
)
```

  Esse retorna o 99¬∫ percentil da dura√ß√£o das requisi√ß√µes HTTP considerando todos os buckets. Note o uso de `by (le)` dentro do sum.

* *Agregando por labels extras:* Se quisermos o percentil por `job` e `instance`, por exemplo, devemos manter esses labels na agrega√ß√£o, al√©m do `le`:

```promql
histogram_quantile(
  0.95, 
  sum(rate(http_request_duration_seconds_bucket[5m])) by (job, instance, le)
)
```

* *Evitando erro comum:* **Nunca** esque√ßa o `by (le)` ao somar buckets de um histograma cl√°ssico. Por exemplo, isto est√° **errado**:

  ```promql
  # Exemplo INCORRETO - aus√™ncia de by(le)
  histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket[5m])))
  ```

Sem agrupar por `le`, os valores de buckets se somam indevidamente, tornando o resultado do quantil incorreto.

No Prometheus 3.0, foram introduzidos os **histogramas nativos** (ainda experimentais). Eles visam simplificar e tornar mais eficiente o uso de histogramas (evitando lidar com dezenas de s√©ries `_bucket`).

Com histogramas nativos, existem inclusive novas fun√ß√µes como `histogram_count()`, `histogram_sum()` e `histogram_avg()` para extrair diretamente contagem, soma e m√©dia dos histogramas.

Al√©m disso, h√° a fun√ß√£o `histogram_fraction()` para calcular fra√ß√µes entre limites. Embora seja um recurso promissor, a maioria dos usu√°rios ainda trabalha com histogramas cl√°ssicos `_bucket` at√© que os nativos se estabilizem.

**Mudan√ßa de tipo (convers√£o Escalar <-> Vetor):** Em algumas situa√ß√µes avan√ßadas, voc√™ pode precisar converter escalares em vetores ou vice-versa:

* `scalar(vetor)` ‚Äì Converte um vetor de uma √∫nica s√©rie temporal (com um √∫nico valor) em um escalar simples. Isso √© √∫til, por exemplo, quando voc√™ calculou um valor m√≠nimo ou m√°ximo e quer us√°-lo em uma compara√ß√£o global.
  *Exemplo:* `scalar(min(up{job="webserver"}))` ‚Äì isso resultar√° em um escalar 0 ou 1 indicando se **alguma** inst√¢ncia do job "webserver" est√° ca√≠da (0 se o m√≠nimo for 0, ou seja, pelo menos uma inst√¢ncia est√° down; 1 se todas est√£o up).
* `vector(escalar)` ‚Äì O oposto, pega um escalar e o transforma em um vetor (sem labels). √ötil se voc√™ precisa combinar um n√∫mero puro com s√©ries.
  *Exemplo:* `vector(1)` ‚Äì produziria um vetor contendo apenas o valor 1.

**Altera√ß√£o de Labels:** √Äs vezes √© necess√°rio renomear ou copiar labels nas s√©ries. Fun√ß√µes √∫teis:

* `label_replace(vetor, "label_destino", "valor_novo", "label_origem", "regex")` ‚Äì Retorna um vetor a partir de outro, adicionando ou modificando um label. Ele pega o valor do `label_origem` que case com a regex fornecida e o coloca em `label_destino` usando `valor_novo` (onde `'$1'` pode referenciar grupos da regex).
  *Exemplo:*

```promql
label_replace(my_metric, "new_label", "$1", "old_label", "(.*)")
```

  Isso criaria (ou sobrescreveria) `new_label` em cada s√©rie de `my_metric`, copiando exatamente o valor de `old_label` (j√° que `(.*)` captura todo o valor e `$1` insere ele).
* `label_join(vetor, "label_destino", "sep", "label1", "label2", ...)` ‚Äì Concatena m√∫ltiplos labels em um s√≥. Ex: `label_join(my_metric, "instance_job", "-", "instance", "job")` criaria um novo label `instance_job` juntando os valores de `instance` e `job` separados por um `-`.

Essas fun√ß√µes n√£o s√£o usadas com frequ√™ncia em consultas ad-hoc, mas podem ser muito √∫teis ao preparar m√©tricas para certas compara√ß√µes ou ao lidar com diferen√ßas de rotulagem entre m√©tricas.

**Ordena√ß√£o (Sorting):** Para ordenar resultados, podemos usar as fun√ß√µes `sort(vector)` (ordem crescente) e `sort_desc(vector)` (ordem decrescente). Isso pode ser √∫til quando estamos interessados no topo ou no final de uma lista de resultados (embora muitas vezes `topk` e `bottomk` j√° cubram esses casos).

Exemplos r√°pidos:

* Ordenar todas as inst√¢ncias pelo uso de CPU decrescente:

  ```promql
  sort_desc(rate(node_cpu_seconds_total{mode!="idle"}[5m])) by (instance))
  ```

  *(Aqui somamos as CPUs por inst√¢ncia implicitamente ao usar o `by (instance)` na express√£o, e depois ordenamos.)*

* Ordenar alfab√©ticamente por valor de um label (pouco comum, mas poss√≠vel):

  ```promql
  sort(my_metric)
  ```

  *(Se `my_metric` √© um escalar ou tem apenas um valor por s√©rie, `sort()` essencialmente ordenar√° pelos labels j√° que os valores podem ser iguais.)*

### Valores ausentes (Absent / Missing Values)

Valores ausentes podem ocorrer quando uma m√©trica n√£o √© reportada (por exemplo, um servi√ßo caiu ou foi desligado). Em consultas PromQL, um valor ausente simplesmente n√£o aparece no resultado. Entretanto, podemos detectar explicitamente a aus√™ncia de s√©ries usando a fun√ß√£o `absent()` mencionada anteriormente.

Recapitulando o uso de `absent()`:

* `absent(metric)` ‚Äì Retorna uma s√©rie sem labels (ou com labels especificados na consulta) com valor 1 se **nenhuma s√©rie** correspondente a `metric` est√° presente, ou retorna nada (vazio) caso contr√°rio. Isso √© muito √∫til em regras de alerta: um alerta de "TargetDown" pode ser escrito como `absent(up{job="myjob"} == 1)` para disparar quando nenhum alvo daquele job estiver up.

Exemplo:

```promql
absent(up{job="node"} == 1)
```

Acima, a express√£o `up{job="node"} == 1` resultaria em 1 para cada inst√¢ncia de `node` que esteja up, ent√£o `absent(...)` retornaria 1 (sem label) se nenhuma inst√¢ncia de `node` estiver up (ou seja, o resultado dentro foi vazio). Se pelo menos uma inst√¢ncia estiver up, `absent` n√£o retorna nada.

Da mesma forma, `absent_over_time(metric[5m])` verifica se *nenhum* ponto de `metric` apareceu nos √∫ltimos 5 minutos.

**Importante:** Ao visualizar dados no gr√°fico do Prometheus ou Grafana, s√©ries ausentes simplesmente n√£o aparecem. Por isso, ao compor dashboards ou alertas, pode ser √∫til usar consultas que retornem 0 explicitamente quando algo est√° ausente para facilitar a visualiza√ß√£o. Uma t√©cnica √© usar a opera√ß√£o `OR` com `absent()`. Exemplo:

```promql
rate(http_requests_total[5m]) or absent(http_requests_total)
```

Isso retornar√° a taxa de requisi√ß√µes normalmente; se nenhuma s√©rie existir, em vez de nada, retornar√° 1 (ou outro valor constante) indicando aus√™ncia.

### Fun√ß√µes avan√ßadas e menos conhecidas

Algumas fun√ß√µes do PromQL s√£o menos conhecidas, mas podem ser extremamente poderosas em cen√°rios espec√≠ficos:

* **`resets(counter[interval])`:** Conta quantas vezes um contador "resetou" (voltou a zero) no per√≠odo. √ötil para detectar reinicializa√ß√µes de aplicativos ou problemas de coleta.
  *Exemplos:*

  ```promql
  resets(http_requests_total[5m])
  ```

  Contaria quantos resets ocorreram no `http_requests_total` nos √∫ltimos 5 minutos. Se esse n√∫mero for > 0 constantemente, pode indicar que o servi√ßo est√° reiniciando frequentemente (se o contador for interno ao servi√ßo) ou que h√° overflow de contadores.

* **`changes(series[interval])`:** Conta quantas vezes o valor de uma s√©rie mudou durante o intervalo. Isso vale para qualquer m√©trica (n√£o apenas counters). Pode indicar instabilidade ou flapping.
  *Exemplo:*

  ```promql
  changes(process_start_time_seconds[5m]) > 0
  ```

  O exemplo acima retornaria 1 para inst√¢ncias cujo `process_start_time_seconds` (normalmente um timestamp de in√≠cio do processo) tenha mudado nos √∫ltimos 5 minutos ‚Äî ou seja, o processo reiniciou nesse per√≠odo.

* **`predict_linear(series[interval], passos_no_futuro)`:** Realiza uma extrapola√ß√£o linear do valor da s√©rie com base na tend√™ncia nos √∫ltimos intervalos e prev√™ o valor daqui a X segundos (informado em `passos_no_futuro`). √ötil para prever quando algo alcan√ßar√° um certo limite.
  *Exemplo:*

  ```promql
  predict_linear(node_filesystem_free_bytes[1h], 3600) < 0
  ```

  Poderia ser usado para alertar se a tend√™ncia de queda do espa√ßo livre prev√™ que em 1 hora (`3600` segundos) o espa√ßo chegaria a zero.

* **`holt_winters(series[interval], sf, tf)`:** Embora mais comum no Graphite, o PromQL tamb√©m tem uma fun√ß√£o de previs√£o chamada `holt_winters` (Holt-Winters, s√©rie temporal com tend√™ncia e sazonalidade). Aceita uma s√©rie (geralmente resultado de subconsulta) e realiza suaviza√ß√£o exponencial dupla. No entanto, essa fun√ß√£o √© raramente usada diretamente em alertas, servindo mais para visualiza√ß√£o de tend√™ncias suavizadas.

* **Fun√ß√µes para histogramas nativos (Prometheus 3.x):**

  * `histogram_count()` e `histogram_sum()` ‚Äì Retornam, respectivamente, a contagem total e a soma total das observa√ß√µes de histogramas (cl√°ssicos ou nativos). Para histogramas cl√°ssicos, esses usam as s√©ries `_count` e `_sum` internas; para nativos, usam os valores codificados.
  * `histogram_avg()` ‚Äì Computa a m√©dia dos valores observados em cada histograma, equivalente a `histogram_sum/histogram_count`.
  * `histogram_fraction(lower, upper, hist)` ‚Äì Estima a fra√ß√£o de observa√ß√µes dentro do intervalo `[lower, upper]` para cada histograma. √ötil, por exemplo, para calcular *Apdex* (fra√ß√£o de requisi√ß√µes abaixo de um certo limiar de lat√™ncia).

Lembrando que algumas dessas fun√ß√µes mais novas podem requerer flags experimentais, dependendo da vers√£o do Prometheus.

### Operadores Aritm√©ticos e Correspond√™ncia de Vetores Simples

PromQL permite usar operadores bin√°rios entre s√©ries temporais para calcular novas s√©ries. Os operadores aritm√©ticos s√£o: `+`, `-`, `*`, `/`, `%` (m√≥dulo) e `^` (exponencia√ß√£o). Eles podem operar entre:

* Escalar e escalar (ex.: `2 * 3`)
* Vetor e escalar (o escalar aplica-se a todos os valores do vetor; ex.: `metric * 100`)
* Vetor e vetor (aqui entra o conceito de correspond√™ncia de vetores)

Quando aplicamos um operador entre dois vetores (Instant Vectors), o PromQL realiza a opera√ß√£o **par a par** entre s√©ries que "correspondem" umas √†s outras. Essa correspond√™ncia por padr√£o requer que as s√©ries tenham exatamente os mesmos labels (nome da m√©trica pode ser diferente, mas os r√≥tulos-chave e seus valores devem coincidir).

Exemplo simples: se temos as s√©ries `metric_a{host="A", env="prod"}` com valor X e `metric_b{host="A", env="prod"}` com valor Y, ent√£o `metric_a + metric_b` retornar√° `{host="A", env="prod"}` com valor X+Y. Se n√£o houver correspond√™ncia exata de labels entre alguma s√©rie de `metric_a` e alguma de `metric_b`, aquela combina√ß√£o n√£o aparece no resultado.

**Correspond√™ncia simples**: Por padr√£o, todos os labels (exceto o nome da m√©trica) devem casar entre as duas s√©ries para a opera√ß√£o acontecer. √â poss√≠vel ajustar isso com modificadores que veremos adiante (`on` e `ignoring`).

Se quisermos for√ßar a opera√ß√£o em todas as combina√ß√µes (o que raramente faz sentido), h√° o modificador `cross_join` (PromQL >2.9), mas geralmente ele n√£o √© utilizado porque o comportamento padr√£o j√° √© suficiente.

Os operadores tamb√©m podem ser usados com o modificador `bool`, mas isso s√≥ se aplica a operadores de compara√ß√£o, n√£o aos aritm√©ticos.

Exemplos pr√°ticos de operadores aritm√©ticos:

* **Soma de m√©tricas**:

  ```promql
  http_requests_total{status="200"} + http_requests_total{status="500"}
  ```

  Aqui, somamos as s√©ries de requisi√ß√µes com status 200 e as com status 500, casando por quaisquer outros labels (por exemplo, inst√¢ncia). O resultado √© o total combinado de requisi√ß√µes de sucesso e erro.

* **Diferen√ßa de m√©tricas**:

  ```promql
  node_memory_MemTotal_bytes - node_memory_MemFree_bytes
  ```

  Calcula a mem√≥ria em uso (diferen√ßa entre total e livre) para cada inst√¢ncia, assumindo que ambas as m√©tricas compartilham os labels de inst√¢ncia.

* **Multiplica√ß√£o por escalar**:

  ```promql
  cpu_usage * 100
  ```

  Converte a m√©trica `cpu_usage` (talvez como fra√ß√£o 0‚Äì1) em porcentagem.

* **Combina√ß√£o de dois vetores diferentes**:

  ```promql
  errors_total / requests_total
  ```

  Pode calcular a taxa de erro (assumindo que `errors_total` e `requests_total` compartilham labels como servi√ßo/endpoint). Isso exige correspond√™ncia exata de labels.

No caso acima, se `errors_total` existir para um determinado label e `requests_total` n√£o, essa combina√ß√£o n√£o retorna resultado. Podemos usar *vector matching* avan√ßado (pr√≥xima se√ß√£o) para ajustar essas situa√ß√µes.

### Correspond√™ncia de S√©ries Temporais: `on()`, `ignoring()`, `group_left`, `group_right`

Quando combinamos m√©tricas diferentes (vetor-vetor), muitas vezes precisamos controlar quais labels s√£o usados para fazer o *join* (uni√£o) entre as s√©ries de cada lado da opera√ß√£o. √â aqui que entram os modificadores `on` e `ignoring`, e os operadores de jun√ß√£o externa `group_left` e `group_right`:

* **`on(lista_de_labels)`**: Especifica explicitamente quais labels devem ser usados para casar as s√©ries ao aplicar o operador. Todos os demais labels s√£o ignorados no matching (exceto os do `on` listados).
  *Exemplo:*

  ```promql
  errors_total / on(instance) requests_total
  ```

  Aqui dizemos: combine s√©ries de `errors_total` e `requests_total` que tenham o mesmo valor de `instance`. Labels diferentes de `instance` ser√£o ignorados na compara√ß√£o. Isso √© √∫til se, por exemplo, `errors_total` tem um label `status="5xx"` enquanto `requests_total` n√£o tem o label `status`. Sem o `on(instance)`, essas s√©ries n√£o casariam por terem conjuntos de labels distintos.

* **`ignoring(lista_de_labels)`**: O inverso do `on`. Use todos os labels *exceto* os listados para fazer o matching. Ou seja, finge que os labels mencionados n√£o existem nos vetores ao procurar pares correspondentes.
  *Exemplo:*

  ```promql
  cpu_usage{cpu="total"} / ignoring(cpu) cpu_quota
  ```

  Suponha que `cpu_usage` tenha um label `cpu` (n√∫cleo) e valor `"total"` para indicar uso total da CPU, enquanto `cpu_quota` n√£o tem esse label (aplica a todo CPU). O `ignoring(cpu)` permite desconsiderar essa diferen√ßa, casando as s√©ries somente pelos outros labels (por exemplo, pod ou cont√™iner, se for o caso).

* **Jun√ß√µes um-para-muitos (many-to-one)**: Por padr√£o, se houver m√∫ltiplas s√©ries de um lado que poderiam casar com uma s√©rie do outro, a opera√ß√£o n√£o ocorre e o resultado √© vazio para evitar ambiguidades. No entanto, √†s vezes desejamos permitir isso ‚Äî por exemplo, dividir uma m√©trica total por n√∫mero de CPUs, onde a m√©trica total n√£o tem o label `cpu` mas a de contagem de CPU tem (m√∫ltiplas s√©ries, uma por core).
  Para isso, usamos `group_left` ou `group_right` em conjunto com `on`/`ignoring`:

  * **`group_left(label1, label2, ...)`**: Indica que as s√©ries do lado esquerdo do operador devem permanecer separadas (muitas) enquanto as do lado direito ser√£o "espalhadas" para casar. Em outras palavras, permite que uma √∫nica s√©rie do lado direito seja usada para m√∫ltiplas do lado esquerdo. Opcionalmente, podemos listar labels que ser√£o **copiados** do lado direito para o resultado final.
  * **`group_right(label1, label2, ...)`**: O contr√°rio, mant√©m o lado direito com muitas s√©ries e espalha o lado esquerdo.

  *Exemplo (adicionando labels com group\_left):*

  ```promql
  rate(http_requests_total[5m]) 
    * on(instance) 
    group_left(job, environment) 
    up
  ```

  Nesse exemplo, `rate(http_requests_total[5m])` produz s√©ries talvez com labels `instance` e outros, mas digamos que n√£o tenha `job` nem `environment` explicitamente (ou queremos copiar do `up`). A s√©rie `up` (m√©trica de sa√∫de do alvo) tem `job`, `instance`, e `environment`. Estamos multiplicando as duas m√©tricas apenas casando por `instance` (`on(instance)`). Como do lado direito (`up`) h√° possivelmente apenas uma s√©rie por instance (valor 0 ou 1), e do lado esquerdo pode haver m√∫ltiplas (por caminho de requisi√ß√£o, status, etc.), usamos `group_left(job, environment)` para dizer: permite que a mesma s√©rie de `up` case com m√∫ltiplas s√©ries de requests do lado esquerdo, e traga os labels `job` e `environment` dessa s√©rie de `up` para o resultado final. Assim, o resultado ter√° a taxa de requests por `instance` mas agora enriquecido com os labels de job e environment.

  *Exemplo (many-to-one sem copiar labels):*

  ```promql
  cpu_usage 
    / on(instance) 
    group_right 
    cpu_count
  ```

  Suponha que `cpu_usage{instance="A"}` representa o uso total de CPU (consolidado) em determinada m√°quina, e `cpu_count{instance="A", cpu="0"}` e `cpu_count{instance="A", cpu="1"}` etc. representam 1 para cada CPU f√≠sica (cada core). Se somarmos `cpu_count by (instance)` obter√≠amos o n√∫mero de CPUs por inst√¢ncia, mas podemos diretamente dividir usando o truque do `group_right`. Aqui, cada s√©rie de `cpu_usage` (uma por instancia) ser√° comparada com m√∫ltiplas s√©ries de `cpu_count` (uma por CPU). Sem `group_right`, n√£o casaria por haver m√∫ltiplas s√©ries do lado direito para o mesmo instance. Com `group_right`, permitimos isso e, por n√£o especificar labels a copiar, o resultado herda os labels do lado esquerdo (`cpu_usage`), e a opera√ß√£o divis√£o √© feita para cada combina√ß√£o (na pr√°tica repetindo o mesmo valor de `cpu_usage` para cada CPU e dividindo por o respectivo `cpu_count` ‚Äì o que acaba resultando no mesmo valor para cada CPU). Talvez nesse caso espec√≠fico fosse melhor j√° agrupar `cpu_count` antes de dividir, mas esse exemplo ilustra a sintaxe.

* **Operador de conjunto `union`:** PromQL n√£o possui um operador expl√≠cito "UNION" nomeado, mas podemos realizar uni√£o de resultados simplesmente listando express√µes separadas por v√≠rgula em uma consulta. Por exemplo:

  ```promql
  metric_a, metric_b
  ```

  Isso retorna todas as s√©ries de `metric_a` e todas as de `metric_b`. N√£o √© muito comum em consultas manuais, mas pode ser √∫til para jun√ß√£o visual.

Resumindo, os modificadores `on` e `ignoring` controlam **quais** labels considerar ao casar s√©ries de m√©tricas diferentes, e `group_left`/`group_right` controlam **como lidar** quando h√° cardinalidades diferentes (um-para-muitos). Combin√°-los corretamente √© fundamental para escrever consultas que envolvam m√∫ltiplas m√©tricas.

### Operadores L√≥gicos: `and`, `or`, `unless`

Al√©m dos operadores aritm√©ticos e de compara√ß√£o, PromQL tamb√©m suporta operadores l√≥gicos para vetores. Esses operadores n√£o criam valores num√©ricos novos, mas sim filtram ou combinam s√©ries com base em condi√ß√µes booleanas.

* **`and`:** Ret√©m apenas as s√©ries que aparecem em **ambos** os operandos. Em outras palavras, √© uma interse√ß√£o: uma s√©rie do lado esquerdo s√≥ passa se existe uma s√©rie exatamente igual do lado direito (considerando labels) e vice-versa. O valor resultante de cada s√©rie ser√° o valor do lado esquerdo (padr√£o) ou, se usado como comparador, segue regras de comparador bool.
  Uso t√≠pico: aplicar uma condi√ß√£o a um resultado. Por exemplo:

  ```promql
  (vector1 comparacao const) and vector1
  ```

  Isso retornaria apenas as s√©ries de `vector1` que atendem √† compara√ß√£o (pois o comparador produzir√° 1 para as s√©ries que satisfazem, e ent√£o `and` manter√° apenas essas).

* **`or`:** Uni√£o de s√©ries. Retorna s√©ries que est√£o em **pelo menos um** dos lados. Se a mesma s√©rie (mesmos labels) aparece em ambos, o valor resultante ser√° o do lado esquerdo (padr√£o) ou pode ser modificado com bool se estivermos combinando booleanos. √â √∫til para combinar resultados diferentes.
  Por exemplo:

  ```promql
  vector_a or vector_b
  ```

  Isso d√° todas as s√©ries de `vector_a` e `vector_b`. Se alguma s√©rie estiver presente nos dois, aparece uma vez s√≥ (com valor de `vector_a`).

* **`unless`:** Ret√©m as s√©ries do lado esquerdo **a menos que** elas tamb√©m apare√ßam no lado direito. Equivale a diferen√ßa de conjuntos: resultado = esquerda \ direita. (Obs: O lado direito s√≥ importa pelos labels, seus valores s√£o ignorados).
  Por exemplo:

  ```promql
  up{job="api"} unless up{job="api", region="us-east"}
  ```

  Isso retornaria as s√©ries `up` do job "api" **que n√£o t√™m** region="us-east", ou seja, efetivamente filtra fora todas as inst√¢ncias da regi√£o us-east.

Os operadores l√≥gicos s√£o avaliados ap√≥s todos os c√°lculos num√©ricos serem feitos. Isso significa que podemos us√°-los tanto em m√©tricas brutas quanto em resultados de express√µes.

**Exemplos pr√°ticos combinando compara√ß√µes e operadores l√≥gicos:**

* **Contar inst√¢ncias ativas em dois grupos diferentes:**

  ```promql
  sum(up{job="node"} == 1) or sum(up{job="db"} == 1)
  ```

  Esse exemplo usa `== 1` para converter as s√©ries `up` em booleanas (1 para up, 0 para down) e soma para contar quantas est√£o up em cada job. O `or` aqui faz a uni√£o, retornando duas s√©ries (uma para node e outra para db) com o valor de quantas inst√¢ncias est√£o up em cada.

* **Filtrar top 5 de um conjunto e combinar com outro crit√©rio:**

  ```promql
  topk(5, rate(http_requests_total[5m])) and ignoring(instance) (rate(errors_total[5m]) > 0)
  ```

  Esse exemplo hipot√©tico pegaria as 5 maiores taxas de requisi√ß√£o (independente de inst√¢ncia) e ent√£o, atrav√©s do `and` com `ignoring(instance)` e a condi√ß√£o de erros, manteria somente aquelas cujo servi√ßo (ignorando inst√¢ncias) est√° apresentando erros. Bastante espec√≠fico, mas demonstra o uso combinado: `topk` produz s√©ries; a outra parte produz 1/0 para servi√ßos com erro; o `and ignoring(instance)` casa por servi√ßo e filtra.

Lembrando que, se quisermos comparar valores de uma s√©rie com um n√∫mero e obter diretamente 1 ou 0, podemos usar o modificador `bool`. Exemplo: `vector1 > bool 10` retornaria um vetor com valor 1 para s√©ries onde `vector1` > 10 e 0 caso contr√°rio (mantendo os labels). Sem `bool`, ele retornaria as pr√≥prias s√©ries (com seus valores originais) por√©m filtradas pelas que atendem √† condi√ß√£o.

### Resumo de operadores de conjunto (conjuntos de s√©ries)

J√° falamos sobre `on`, `ignoring`, `group_left`, `group_right` e os operadores l√≥gicos. Vale refor√ßar:

* `on` / `ignoring`: controlam quais labels fazem parte da compara√ß√£o entre s√©ries ao aplicar um operador bin√°rio.
* `group_left` / `group_right`: permitem matching many-to-one e definem de que lado as s√©ries duplicadas ficam.
* `and`, `or`, `unless`: operam em n√≠vel de conjunto de s√©ries (interse√ß√£o, uni√£o, diferen√ßa).

Al√©m disso, quando usamos agregadores (como `sum`, `avg` etc.), usamos `by` ou `without` para controlar quais labels ser√£o preservados ou removidos. Isso √†s vezes √© referido como agrupar por labels, mas √© diferente de `on/ignoring` (que √© para matching de operadores).

**Recapitulando agrega√ß√£o com `by` e `without`:**

* `sum by(label1, label2) (expr)` ‚Äì Soma os valores de `expr` agrupando s√©ries que compartilham os mesmos valores de `label1` e `label2`. Os labels `label1` e `label2` ser√£o mantidos no resultado, e todos os outros ser√£o descartados (exceto aqueles usados no by).
* `avg without(labelX) (expr)` ‚Äì Calcula a m√©dia removendo `labelX` da distin√ß√£o. Isso significa agrupar por todas as outras labels, ou seja, fundir s√©ries que diferem apenas em `labelX`.

Exemplo: `sum by(job) (up == 0)` ‚Äì contaria quantas inst√¢ncias est√£o down por job. Aqui `up == 0` produz 1 para inst√¢ncias down. Agrupando por job e somando, obtemos a contagem de inst√¢ncias n√£o ativas de cada job.

## Fun√ß√µes Essenciais do PromQL

As fun√ß√µes essenciais do PromQL s√£o aquelas mais utilizadas no dia a dia para monitoramento e an√°lise de m√©tricas. Elas permitem transformar dados brutos em informa√ß√µes acion√°veis, calculando taxas, agrega√ß√µes e estat√≠sticas importantes.

### Fun√ß√µes de Taxa e Incremento

As fun√ß√µes mais fundamentais para trabalhar com contadores s√£o `rate()` e `increase()`:

**`rate(counter[interval])`**: Calcula a taxa m√©dia por segundo de incremento do contador no intervalo especificado. Esta fun√ß√£o lida automaticamente com resets do contador.

```promql
rate(http_requests_total[5m])
```

**`increase(counter[interval])`**: Calcula quanto o contador aumentou no intervalo especificado.

```promql
increase(http_requests_total[1h])
```

**`irate(counter[interval])`**: Calcula a taxa instant√¢nea baseada apenas nos dois pontos mais recentes. √â mais ruidosa, mas reage mais rapidamente a mudan√ßas.

```promql
irate(http_requests_total[5m])
```

### Fun√ß√µes de Agrega√ß√£o

As fun√ß√µes de agrega√ß√£o permitem resumir dados de m√∫ltiplas s√©ries:

**`sum(expr) by (label1, label2)`**: Soma os valores agrupando por labels espec√≠ficos.

```promql
sum(rate(http_requests_total[5m])) by (job)
```

**`avg(expr) by (label1, label2)`**: Calcula a m√©dia agrupando por labels espec√≠ficos.

```promql
avg(rate(node_cpu_seconds_total{mode="user"}[5m])) by (instance)
```

**`count(expr) by (label1, label2)`**: Conta o n√∫mero de s√©ries agrupando por labels.

```promql
count(up) by (job)
```

**`max(expr) by (label1, label2)`**: Retorna o valor m√°ximo agrupando por labels.

```promql
max(rate(http_requests_total[5m])) by (endpoint)
```

**`min(expr) by (label1, label2)`**: Retorna o valor m√≠nimo agrupando por labels.

```promql
min(rate(http_requests_total[5m])) by (endpoint)
```

### Fun√ß√µes de Percentil e Histograma

**`histogram_quantile(quantile, histogram)`**: Calcula um quantil espec√≠fico a partir de um histograma.

```promql
histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket[5m])) by (le))
```

**`quantile(quantile, expr)`**: Calcula um quantil espec√≠fico de uma express√£o.

```promql
quantile(0.95, rate(http_requests_total[5m]))
```

### Fun√ß√µes de Filtro e Sele√ß√£o

**`topk(k, expr)`**: Retorna as k s√©ries com os maiores valores.

```promql
topk(5, rate(http_requests_total[5m]))
```

**`bottomk(k, expr)`**: Retorna as k s√©ries com os menores valores.

```promql
bottomk(5, rate(http_requests_total[5m]))
```

### Fun√ß√µes de Tempo

**`avg_over_time(expr[interval])`**: Calcula a m√©dia dos valores no intervalo especificado.

```promql
avg_over_time(http_requests_total[5m])
```

**`sum_over_time(expr[interval])`**: Calcula a soma dos valores no intervalo especificado.

```promql
sum_over_time(http_requests_total[5m])
```

**`max_over_time(expr[interval])`**: Retorna o valor m√°ximo no intervalo especificado.

```promql
max_over_time(cpu_usage[1h])
```

**`min_over_time(expr[interval])`**: Retorna o valor m√≠nimo no intervalo especificado.

```promql
min_over_time(memory_usage[1h])
```

### Fun√ß√µes de Detec√ß√£o de Aus√™ncia

**`absent(expr)`**: Retorna 1 se a express√£o n√£o retornar nenhum dado, caso contr√°rio retorna nada.

```promql
absent(up{job="webserver"})
```

**`absent_over_time(expr[interval])`**: Verifica se a m√©trica esteve ausente durante todo o intervalo.

```promql
absent_over_time(up{job="webserver"}[5m])
```

## PromQL Avan√ßado

O PromQL oferece recursos avan√ßados para consultas complexas e an√°lises sofisticadas. Esta se√ß√£o aborda t√≥picos mais avan√ßados como correspond√™ncia de vetores, subconsultas, operadores l√≥gicos e fun√ß√µes especializadas.

### Correspond√™ncia de S√©ries Temporais: `on()`, `ignoring()`, `group_left`, `group_right`

Quando combinamos m√©tricas diferentes (vetor-vetor), muitas vezes precisamos controlar quais labels s√£o usados para fazer o *join* (uni√£o) entre as s√©ries de cada lado da opera√ß√£o. √â aqui que entram os modificadores `on` e `ignoring`, e os operadores de jun√ß√£o externa `group_left` e `group_right`:

* **`on(lista_de_labels)`**: Especifica explicitamente quais labels devem ser usados para casar as s√©ries ao aplicar o operador. Todos os demais labels s√£o ignorados no matching (exceto os do `on` listados).
  *Exemplo:*

  ```promql
  errors_total / on(instance) requests_total
  ```

  Aqui dizemos: combine s√©ries de `errors_total` e `requests_total` que tenham o mesmo valor de `instance`. Labels diferentes de `instance` ser√£o ignorados na compara√ß√£o. Isso √© √∫til se, por exemplo, `errors_total` tem um label `status="5xx"` enquanto `requests_total` n√£o tem o label `status`. Sem o `on(instance)`, essas s√©ries n√£o casariam por terem conjuntos de labels distintos.

* **`ignoring(lista_de_labels)`**: O inverso do `on`. Use todos os labels *exceto* os listados para fazer o matching. Ou seja, finge que os labels mencionados n√£o existem nos vetores ao procurar pares correspondentes.
  *Exemplo:*

  ```promql
  cpu_usage{cpu="total"} / ignoring(cpu) cpu_quota
  ```

  Suponha que `cpu_usage` tenha um label `cpu` (n√∫cleo) e valor `"total"` para indicar uso total da CPU, enquanto `cpu_quota` n√£o tem esse label (aplica a todo CPU). O `ignoring(cpu)` permite desconsiderar essa diferen√ßa, casando as s√©ries somente pelos outros labels (por exemplo, pod ou cont√™iner, se for o caso).

* **Jun√ß√µes um-para-muitos (many-to-one)**: Por padr√£o, se houver m√∫ltiplas s√©ries de um lado que poderiam casar com uma s√©rie do outro, a opera√ß√£o n√£o ocorre e o resultado √© vazio para evitar ambiguidades. No entanto, √†s vezes desejamos permitir isso ‚Äî por exemplo, dividir uma m√©trica total por n√∫mero de CPUs, onde a m√©trica total n√£o tem o label `cpu` mas a de contagem de CPU tem (m√∫ltiplas s√©ries, uma por core).
  Para isso, usamos `group_left` ou `group_right` em conjunto com `on`/`ignoring`:

  * **`group_left(label1, label2, ...)`**: Indica que as s√©ries do lado esquerdo do operador devem permanecer separadas (muitas) enquanto as do lado direito ser√£o "espalhadas" para casar. Em outras palavras, permite que uma √∫nica s√©rie do lado direito seja usada para m√∫ltiplas do lado esquerdo. Opcionalmente, podemos listar labels que ser√£o **copiados** do lado direito para o resultado final.
  * **`group_right(label1, label2, ...)`**: O contr√°rio, mant√©m o lado direito com muitas s√©ries e espalha o lado esquerdo.

  *Exemplo (adicionando labels com group\_left):*

  ```promql
  rate(http_requests_total[5m]) 
    * on(instance) 
    group_left(job, environment) 
    up
  ```

  Nesse exemplo, `rate(http_requests_total[5m])` produz s√©ries talvez com labels `instance` e outros, mas digamos que n√£o tenha `job` nem `environment` explicitamente (ou queremos copiar do `up`). A s√©rie `up` (m√©trica de sa√∫de do alvo) tem `job`, `instance`, e `environment`. Estamos multiplicando as duas m√©tricas apenas casando por `instance` (`on(instance)`). Como do lado direito (`up`) h√° possivelmente apenas uma s√©rie por instance (valor 0 ou 1), e do lado esquerdo pode haver m√∫ltiplas (por caminho de requisi√ß√£o, status, etc.), usamos `group_left(job, environment)` para dizer: permite que a mesma s√©rie de `up` case com m√∫ltiplas s√©ries de requests do lado esquerdo, e traga os labels `job` e `environment` dessa s√©rie de `up` para o resultado final. Assim, o resultado ter√° a taxa de requests por `instance` mas agora enriquecido com os labels de job e environment.

  *Exemplo (many-to-one sem copiar labels):*

  ```promql
  cpu_usage 
    / on(instance) 
    group_right 
    cpu_count
  ```

  Suponha que `cpu_usage{instance="A"}` representa o uso total de CPU (consolidado) em determinada m√°quina, e `cpu_count{instance="A", cpu="0"}` e `cpu_count{instance="A", cpu="1"}` etc. representam 1 para cada CPU f√≠sica (cada core). Se somarmos `cpu_count by (instance)` obter√≠amos o n√∫mero de CPUs por inst√¢ncia, mas podemos diretamente dividir usando o truque do `group_right`. Aqui, cada s√©rie de `cpu_usage` (uma por instancia) ser√° comparada com m√∫ltiplas s√©ries de `cpu_count` (uma por CPU). Sem `group_right`, n√£o casaria por haver m√∫ltiplas s√©ries do lado direito para o mesmo instance. Com `group_right`, permitimos isso e, por n√£o especificar labels a copiar, o resultado herda os labels do lado esquerdo (`cpu_usage`), e a opera√ß√£o divis√£o √© feita para cada combina√ß√£o (na pr√°tica repetindo o mesmo valor de `cpu_usage` para cada CPU e dividindo por o respectivo `cpu_count` ‚Äì o que acaba resultando no mesmo valor para cada CPU). Talvez nesse caso espec√≠fico fosse melhor j√° agrupar `cpu_count` antes de dividir, mas esse exemplo ilustra a sintaxe.

* **Operador de conjunto `union`:** PromQL n√£o possui um operador expl√≠cito "UNION" nomeado, mas podemos realizar uni√£o de resultados simplesmente listando express√µes separadas por v√≠rgula em uma consulta. Por exemplo:

  ```promql
  metric_a, metric_b
  ```

  Isso retorna todas as s√©ries de `metric_a` e todas as de `metric_b`. N√£o √© muito comum em consultas manuais, mas pode ser √∫til para jun√ß√£o visual.

Resumindo, os modificadores `on` e `ignoring` controlam **quais** labels considerar ao casar s√©ries de m√©tricas diferentes, e `group_left`/`group_right` controlam **como lidar** quando h√° cardinalidades diferentes (um-para-muitos). Combin√°-los corretamente √© fundamental para escrever consultas que envolvam m√∫ltiplas m√©tricas.

### Operadores L√≥gicos: `and`, `or`, `unless`

Al√©m dos operadores aritm√©ticos e de compara√ß√£o, PromQL tamb√©m suporta operadores l√≥gicos para vetores. Esses operadores n√£o criam valores num√©ricos novos, mas sim filtram ou combinam s√©ries com base em condi√ß√µes booleanas.

* **`and`:** Ret√©m apenas as s√©ries que aparecem em **ambos** os operandos. Em outras palavras, √© uma interse√ß√£o: uma s√©rie do lado esquerdo s√≥ passa se existe uma s√©rie exatamente igual do lado direito (considerando labels) e vice-versa. O valor resultante de cada s√©rie ser√° o valor do lado esquerdo (padr√£o) ou, se usado como comparador, segue regras de comparador bool.
  Uso t√≠pico: aplicar uma condi√ß√£o a um resultado. Por exemplo:

  ```promql
  (vector1 comparacao const) and vector1
  ```

  Isso retornaria apenas as s√©ries de `vector1` que atendem √† compara√ß√£o (pois o comparador produzir√° 1 para as s√©ries que satisfazem, e ent√£o `and` manter√° apenas essas).

* **`or`:** Uni√£o de s√©ries. Retorna s√©ries que est√£o em **pelo menos um** dos lados. Se a mesma s√©rie (mesmos labels) aparece em ambos, o valor resultante ser√° o do lado esquerdo (padr√£o) ou pode ser modificado com bool se estivermos combinando booleanos. √â √∫til para combinar resultados diferentes.
  Por exemplo:

  ```promql
  vector_a or vector_b
  ```

  Isso d√° todas as s√©ries de `vector_a` e `vector_b`. Se alguma s√©rie estiver presente nos dois, aparece uma vez s√≥ (com valor de `vector_a`).

* **`unless`:** Ret√©m as s√©ries do lado esquerdo **a menos que** elas tamb√©m apare√ßam no lado direito. Equivale a diferen√ßa de conjuntos: resultado = esquerda \ direita. (Obs: O lado direito s√≥ importa pelos labels, seus valores s√£o ignorados).
  Por exemplo:

  ```promql
  up{job="api"} unless up{job="api", region="us-east"}
  ```

  Isso retornaria as s√©ries `up` do job "api" **que n√£o t√™m** region="us-east", ou seja, efetivamente filtra fora todas as inst√¢ncias da regi√£o us-east.

Os operadores l√≥gicos s√£o avaliados ap√≥s todos os c√°lculos num√©ricos serem feitos. Isso significa que podemos us√°-los tanto em m√©tricas brutas quanto em resultados de express√µes.

**Exemplos pr√°ticos combinando compara√ß√µes e operadores l√≥gicos:**

* **Contar inst√¢ncias ativas em dois grupos diferentes:**

  ```promql
  sum(up{job="node"} == 1) or sum(up{job="db"} == 1)
  ```

  Esse exemplo usa `== 1` para converter as s√©ries `up` em booleanas (1 para up, 0 para down) e soma para contar quantas est√£o up em cada job. O `or` aqui faz a uni√£o, retornando duas s√©ries (uma para node e outra para db) com o valor de quantas inst√¢ncias est√£o up em cada.

* **Filtrar top 5 de um conjunto e combinar com outro crit√©rio:**

  ```promql
  topk(5, rate(http_requests_total[5m])) and ignoring(instance) (rate(errors_total[5m]) > 0)
  ```

  Esse exemplo hipot√©tico pegaria as 5 maiores taxas de requisi√ß√£o (independente de inst√¢ncia) e ent√£o, atrav√©s do `and` com `ignoring(instance)` e a condi√ß√£o de erros, manteria somente aquelas cujo servi√ßo (ignorando inst√¢ncias) est√° apresentando erros. Bastante espec√≠fico, mas demonstra o uso combinado: `topk` produz s√©ries; a outra parte produz 1/0 para servi√ßos com erro; o `and ignoring(instance)` casa por servi√ßo e filtra.

Lembrando que, se quisermos comparar valores de uma s√©rie com um n√∫mero e obter diretamente 1 ou 0, podemos usar o modificador `bool`. Exemplo: `vector1 > bool 10` retornaria um vetor com valor 1 para s√©ries onde `vector1` > 10 e 0 caso contr√°rio (mantendo os labels). Sem `bool`, ele retornaria as pr√≥prias s√©ries (com seus valores originais) por√©m filtradas pelas que atendem √† condi√ß√£o.

### Subconsultas e An√°lise Temporal Avan√ßada

**Counter Range Vectors**: Contadores s√£o m√©tricas que apenas aumentam (ou resetam para zero e voltam a aumentar). Exemplos: n√∫mero total de requisi√ß√µes atendidas, bytes transferidos, etc. Quando consultamos diretamente um *counter* como range vector, obteremos uma s√©rie de pontos que s√≥ crescem (com eventuais resets). Para extrair informa√ß√µes √∫teis (como taxa de eventos por segundo ou aumentos em determinado per√≠odo) usamos fun√ß√µes especiais:

* `rate(counter[5m])`: Calcula a **taxa m√©dia por segundo** de incremento do contador nos √∫ltimos 5 minutos. Essa fun√ß√£o j√° lida corretamente com resets do contador (ignorando as quedas abruptas devido a resets e calculando a taxa considerando isso).
* `irate(counter[5m])`: Calcula a **taxa instant√¢nea** (baseada apenas nos dois pontos mais recentes dentro dos 5 minutos). √â mais ruidosa, mas pode reagir mais rapidamente a mudan√ßas repentinas.
* `increase(counter[1h])`: Calcula **quanto o contador aumentou** no √∫ltimo 1 hora. Essencialmente integra a taxa ao longo do per√≠odo.

**Agrega√ß√£o atrav√©s do tempo (Aggregating Across Time)**: √Äs vezes, queremos primeiro agregar os dados e depois analisar a evolu√ß√£o temporal dessa agrega√ß√£o. As **subconsultas** nos permitem isso. Uma *subquery* (subconsulta) √© quando temos uma express√£o do PromQL seguida de um intervalo entre colchetes e possivelmente uma resolu√ß√£o, por exemplo: `expr[dura√ß√£o:passo]`. Isso faz o Prometheus avaliar `expr` repetidamente ao longo do intervalo dado, produzindo um range vector como resultado.

Por exemplo, `avg_over_time(rate(http_requests_total[1m])[24h:1h])` funciona assim:

* Internamente, `rate(http_requests_total[1m])` √© avaliado para cada passo de 1h dentro das √∫ltimas 24h, gerando a taxa m√©dia por minuto calculada a cada hora.
* Em seguida, `avg_over_time(...[24h:1h])` calcula a m√©dia desses 24 valores (um por hora) **no tempo atual**. Na pr√°tica, isso nos daria a m√©dia da taxa hor√°ria de requisi√ß√µes no dia.

Subconsultas s√£o muito poderosas e foram aprimoradas a partir do Prometheus 2.7. Com elas √© poss√≠vel, por exemplo, calcular tend√™ncias, baselines e sazonalidade de forma compacta.

**Exemplos avan√ßados de subconsultas e an√°lise de tend√™ncias:**

* **Tend√™ncia de taxa de erro (janela m√≥vel):** Calcular a m√©dia da taxa de erros em janelas de 1 hora, ao longo das √∫ltimas 24 horas:

  ```promql
  avg_over_time(
    rate(http_requests_total{status=~"5.."}[1m])[24h:1h]
  )
  ```

  Essa consulta gera 24 pontos (taxa de erro m√©dia de cada hora nas √∫ltimas 24h) e depois calcula a m√©dia disso tudo (ou seja, a m√©dia di√°ria da taxa de erro). Poder√≠amos tamb√©m omitir a fun√ß√£o externa para simplesmente visualizar a s√©rie das √∫ltimas 24 horas e identificar padr√µes de aumento ou redu√ß√£o de erros ao longo do dia.

* **Baseline de performance (compara√ß√£o com m√©dia hist√≥rica):** Comparar a performance atual com a m√©dia da √∫ltima semana:

  ```promql
  rate(http_requests_total[5m]) 
    / avg_over_time(rate(http_requests_total[5m])[7d])
  ```

  Essa consulta produz uma raz√£o: valores acima de 1 indicam que a taxa atual de requisi√ß√µes est√° **acima** da m√©dia semanal; valores abaixo de 1, abaixo da m√©dia. Isso pode ser √∫til para identificar desvios significativos de tr√°fego.

* **Detec√ß√£o de anomalia sazonal (padr√£o hor√°rio):** Comparar o tr√°fego atual com o padr√£o do √∫ltimo dia:

  ```promql
  rate(http_requests_total[5m]) 
    / avg_over_time(rate(http_requests_total[5m])[24h:1h])
  ```

  Aqui, o denominador `avg_over_time(...[24h:1h])` produz a m√©dia da taxa em cada hora do dia anterior. Dividindo a taxa atual por esse valor da mesma hora ontem, podemos identificar se o tr√°fego est√° anormalmente alto ou baixo para este hor√°rio do dia.

* **Diferen√ßa di√°ria (subconsulta com offset):** Para calcular a diferen√ßa em uma m√©trica entre hoje e ontem, podemos usar `offset`. Exemplo:

  ```promql
  my_metric - my_metric offset 1d
  ```

  Isso resulta em quanto `my_metric` variou em compara√ß√£o com exatamente 24 horas atr√°s.

* **Soma acumulada (exemplo de subconsulta):**

  ```promql
  sum(my_counter) - sum(my_counter) offset 1d
  ```

  Este exemplo soma o contador `my_counter` (provavelmente de v√°rias inst√¢ncias) e subtrai o valor de 1 dia atr√°s, mostrando o incremento total em um dia. Essa √© outra forma de calcular algo similar a `increase(my_counter[1d])`.

Em todos esses casos, as subconsultas `[ ... ]` est√£o permitindo observar ou reutilizar resultados ao longo do tempo dentro de uma √∫nica express√£o.

### Fun√ß√µes Avan√ßadas e Especializadas

Algumas fun√ß√µes do PromQL s√£o menos conhecidas, mas podem ser extremamente poderosas em cen√°rios espec√≠ficos:

* **`resets(counter[interval])`:** Conta quantas vezes um contador "resetou" (voltou a zero) no per√≠odo. √ötil para detectar reinicializa√ß√µes de aplicativos ou problemas de coleta.
  *Exemplos:*

  ```promql
  resets(http_requests_total[5m])
  ```

  Contaria quantos resets ocorreram no `http_requests_total` nos √∫ltimos 5 minutos. Se esse n√∫mero for > 0 constantemente, pode indicar que o servi√ßo est√° reiniciando frequentemente (se o contador for interno ao servi√ßo) ou que h√° overflow de contadores.

* **`changes(series[interval])`:** Conta quantas vezes o valor de uma s√©rie mudou durante o intervalo. Isso vale para qualquer m√©trica (n√£o apenas counters). Pode indicar instabilidade ou flapping.
  *Exemplo:*

  ```promql
  changes(process_start_time_seconds[5m]) > 0
  ```

  O exemplo acima retornaria 1 para inst√¢ncias cujo `process_start_time_seconds` (normalmente um timestamp de in√≠cio do processo) tenha mudado nos √∫ltimos 5 minutos ‚Äî ou seja, o processo reiniciou nesse per√≠odo.

* **`predict_linear(series[interval], passos_no_futuro)`:** Realiza uma extrapola√ß√£o linear do valor da s√©rie com base na tend√™ncia nos √∫ltimos intervalos e prev√™ o valor daqui a X segundos (informado em `passos_no_futuro`). √ötil para prever quando algo alcan√ßar√° um certo limite.
  *Exemplo:*

  ```promql
  predict_linear(node_filesystem_free_bytes[1h], 3600) < 0
  ```

  Poderia ser usado para alertar se a tend√™ncia de queda do espa√ßo livre prev√™ que em 1 hora (`3600` segundos) o espa√ßo chegaria a zero.

* **`holt_winters(series[interval], sf, tf)`:** Embora mais comum no Graphite, o PromQL tamb√©m tem uma fun√ß√£o de previs√£o chamada `holt_winters` (Holt-Winters, s√©rie temporal com tend√™ncia e sazonalidade). Aceita uma s√©rie (geralmente resultado de subconsulta) e realiza suaviza√ß√£o exponencial dupla. No entanto, essa fun√ß√£o √© raramente usada diretamente em alertas, servindo mais para visualiza√ß√£o de tend√™ncias suavizadas.

* **Fun√ß√µes para histogramas nativos (Prometheus 3.x):**

  * `histogram_count()` e `histogram_sum()` ‚Äì Retornam, respectivamente, a contagem total e a soma total das observa√ß√µes de histogramas (cl√°ssicos ou nativos). Para histogramas cl√°ssicos, esses usam as s√©ries `_count` e `_sum` internas; para nativos, usam os valores codificados.
  * `histogram_avg()` ‚Äì Computa a m√©dia dos valores observados em cada histograma, equivalente a `histogram_sum/histogram_count`.
  * `histogram_fraction(lower, upper, hist)` ‚Äì Estima a fra√ß√£o de observa√ß√µes dentro do intervalo `[lower, upper]` para cada histograma. √ötil, por exemplo, para calcular *Apdex* (fra√ß√£o de requisi√ß√µes abaixo de um certo limiar de lat√™ncia).

Lembrando que algumas dessas fun√ß√µes mais novas podem requerer flags experimentais, dependendo da vers√£o do Prometheus.

## PromQL na Pr√°tica

O PromQL √© a linguagem de consulta do Prometheus que permite extrair insights valiosos das m√©tricas coletadas. Vamos explorar exemplos pr√°ticos de consultas comuns para uso di√°rio em monitoramento.

### Consultas B√°sicas de Disponibilidade

**Verificar se todos os targets est√£o up:**
```promql
up == 1
```

**Contar quantos targets est√£o down:**
```promql
count(up == 0)
```

**Taxa de disponibilidade por job:**
```promql
avg(up) by (job)
```

### M√©tricas de Sistema (Node Exporter)

**CPU m√©dio por inst√¢ncia:**
```promql
avg(rate(node_cpu_seconds_total{mode="user"}[5m])) by (instance)
```

**Uso de mem√≥ria em porcentagem:**
```promql
(node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes * 100
```

**Uso de disco por filesystem:**
```promql
(node_filesystem_size_bytes - node_filesystem_free_bytes) / node_filesystem_size_bytes * 100
```

**Taxa de I/O de disco:**
```promql
rate(node_disk_io_time_seconds_total[5m])
```

### M√©tricas de Aplica√ß√£o Web

**Taxa de requisi√ß√µes por segundo (QPS):**
```promql
rate(http_requests_total[5m])
```

**Taxa de erro por endpoint:**
```promql
rate(http_requests_total{status=~"5.."}[5m])
```

**Lat√™ncia p95 (percentil 95):**
```promql
histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket[5m])) by (le))
```

**Lat√™ncia p99 (percentil 99):**
```promql
histogram_quantile(0.99, sum(rate(http_request_duration_seconds_bucket[5m])) by (le))
```

**Tempo de resposta m√©dio:**
```promql
rate(http_request_duration_seconds_sum[5m]) / rate(http_request_duration_seconds_count[5m])
```

### M√©tricas de Banco de Dados

**Conex√µes ativas do PostgreSQL:**
```promql
pg_stat_database_numbackends
```

**Taxa de transa√ß√µes por segundo:**
```promql
rate(pg_stat_database_xact_commit[5m]) + rate(pg_stat_database_xact_rollback[5m])
```

**Tamanho de tabelas (PostgreSQL):**
```promql
pg_stat_user_tables_size_bytes
```

### M√©tricas de Container/Kubernetes

**CPU por pod:**
```promql
sum(rate(container_cpu_usage_seconds_total{container!=""}[5m])) by (pod)
```

**Mem√≥ria por pod:**
```promql
sum(container_memory_usage_bytes{container!=""}) by (pod)
```

**Pods por namespace:**
```promql
count(kube_pod_info) by (namespace)
```

### Alertas Comuns

**Alerta de CPU alta:**
```promql
100 - (avg(irate(node_cpu_seconds_total{mode="idle"}[5m])) by (instance) * 100) > 80
```

**Alerta de mem√≥ria alta:**
```promql
(node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes * 100 > 85
```

**Alerta de disco cheio:**
```promql
(node_filesystem_size_bytes - node_filesystem_free_bytes) / node_filesystem_size_bytes * 100 > 90
```

**Alerta de lat√™ncia alta:**
```promql
histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket[5m])) by (le)) > 1
```

**Alerta de taxa de erro alta:**
```promql
rate(http_requests_total{status=~"5.."}[5m]) / rate(http_requests_total[5m]) > 0.05
```

### Consultas Avan√ßadas

**Top 5 inst√¢ncias com maior CPU:**
```promql
topk(5, 100 - (avg(irate(node_cpu_seconds_total{mode="idle"}[5m])) by (instance) * 100))
```

**Soma de m√©tricas por regi√£o:**
```promql
sum(rate(http_requests_total[5m])) by (region)
```

**Diferen√ßa de m√©tricas entre per√≠odos:**
```promql
increase(http_requests_total[1h]) - increase(http_requests_total[1h] offset 1h)
```

**M√©trica com label din√¢mico:**
```promql
rate(http_requests_total{endpoint=~"/api/.*"}[5m])
```

### Dicas de Performance

**Use intervalos apropriados:**
* Para alertas: `[5m]` ou `[1m]`
* Para dashboards: `[1h]` para tend√™ncias
* Evite `[24h]` em consultas frequentes

**Prefira `rate()` sobre `irate()` para alertas:**
```promql
# Bom para alertas (mais est√°vel)
rate(http_requests_total[5m])

# Melhor para dashboards (mais responsivo)
irate(http_requests_total[5m])
```

**Agregue quando poss√≠vel:**
```promql
# Em vez de somar muitas s√©ries
sum(rate(http_requests_total[5m])) by (job)

# Evite isso em m√©tricas com alta cardinalidade
sum(rate(http_requests_total[5m]))
```

### Exemplos de Recording Rules

**Regra para QPS agregado:**
```yaml
groups:
- name: recording_rules
  rules:
    - record: job:http_requests:rate5m
      expr: sum(rate(http_requests_total[5m])) by (job)
```

**Regra para lat√™ncia p95:**
```yaml
    - record: job:http_request_duration_seconds:p95
      expr: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket[5m])) by (le, job))
```

> **Dica**: Use recording rules para pr√©-calcular consultas complexas e frequentes. Isso melhora a performance e reduz a carga no Prometheus.

### Instrumenta√ß√£o direta: exemplos por linguagem

Agora vejamos como instrumentar aplica√ß√µes escritas em algumas linguagens populares. A ideia geral em qualquer linguagem √©: instalar a biblioteca cliente do Prometheus, criar m√©tricas ([counters](https://prometheus.io/docs/concepts/metric_types/#counter), [gauges](https://prometheus.io/docs/concepts/metric_types/#gauge), etc.) em pontos estrat√©gicos do c√≥digo, e expor um endpoint HTTP `/metrics` onde essas m√©tricas s√£o servidas (em formato de texto). O Prometheus ent√£o coleta nesse endpoint.

#### Java (Micrometer / Cliente Java do Prometheus)

Em Java, uma abordagem comum √© usar o **[Micrometer](https://micrometer.io/)** ‚Äì uma biblioteca de instrumenta√ß√£o que suporta m√∫ltiplos backends (Prometheus, Graphite, etc.). O Micrometer foi adotado pelo Spring Boot, por exemplo, facilitando a exposi√ß√£o de m√©tricas. Passos b√°sicos:

1. **Depend√™ncias:** Adicione ao seu projeto (pom.xml ou build.gradle) a depend√™ncia do Micrometer e do registry Prometheus. Exemplo (Maven):

   ```xml
   <dependency>
       <groupId>io.micrometer</groupId>
       <artifactId>micrometer-core</artifactId>
       <version>1.10.4</version>
   </dependency>
   <dependency>
       <groupId>io.micrometer</groupId>
       <artifactId>micrometer-registry-prometheus</artifactId>
       <version>1.10.4</version>
   </dependency>
   ```

2. **Registrar m√©tricas:** Em sua aplica√ß√£o, configure um `MeterRegistry` do Prometheus e registre m√©tricas. Por exemplo, em uma classe de configura√ß√£o Spring:

   ```java
   @Bean
   PrometheusMeterRegistry prometheusRegistry() {
       return new PrometheusMeterRegistry(PrometheusConfig.DEFAULT);
   }
   ```

   Voc√™ pode ent√£o criar contadores, gauges, etc. usando esse registry:

   ```java
   Counter requestCount = Counter.builder("myapp_requests_total")
                                 .description("Total de requisi√ß√µes")
                                 .register(prometheusRegistry());
   // Usar requestCount.inc(); em pontos apropriados do c√≥digo
   ```

   Ou usar anota√ß√µes/filtros prontos do Spring Boot Actuator que medem tempos de resposta automaticamente.

3. **Expor endpoint /metrics:** Se estiver usando Spring Boot Actuator, habilite a endpoint Prometheus. No application.properties:

   ```
   management.endpoints.web.exposure.include=prometheus
   management.endpoint.prometheus.enabled=true
   ```

   Isso far√° o Actuator expor `/actuator/prometheus` com as m√©tricas no formato Prometheus. O Prometheus pode ent√£o fazer scrape nessa URL. (Alternativamente, sem Spring, voc√™ poderia iniciar um HTTP server manualmente que responda com `prometheusRegistry.scrape()` output).

4. **Verificar m√©tricas:** Ao rodar a aplica√ß√£o, acesse [http://localhost:8080/actuator/prometheus](http://localhost:8080/actuator/prometheus) (por exemplo) e voc√™ ver√° todas as m√©tricas registradas, inclusive padr√µes do JVM (o Micrometer j√° fornece m√©tricas de mem√≥ria, CPU, GC, etc. por padr√£o) e as personalizadas que voc√™ adicionou.

> Em resumo, no Java/Spring o processo pode ser muito simples aproveitando frameworks existentes. Para outras aplica√ß√µes Java sem Spring, existe tamb√©m o cliente Java do Prometheus (simpleclient) onde voc√™ manualmente gerencia as m√©tricas e HTTP endpoint.

#### JavaScript/Node.js

No Node.js podemos usar o pacote **prom-client** para instrumenta√ß√£o:

1. **Instalar pacote:** `npm install prom-client`.

2. **Criar m√©tricas no c√≥digo:** Por exemplo, vamos medir o tempo de resposta de uma rota Express:

   ```js
   const express = require('express');
   const promClient = require('prom-client');
   const app = express();

   // Cria um histogram para tempos de resposta em segundos
   const httpResponseHist = new promClient.Histogram({
     name: 'myapp_http_response_duration_seconds',
     help: 'Tempo de resposta das requisi√ß√µes HTTP (segundos)',
     labelNames: ['route', 'method']
   });
   ```

   Aqui usamos um Histogram (poderia ser Summary tamb√©m). Antes de enviar a resposta na rota, registramos a observa√ß√£o:

   ```js
   app.get('/example', (req, res) => {
     const end = httpResponseHist.startTimer({ route: '/example', method: 'GET' });
     // ... l√≥gica da rota ...
     res.send("Hello World");
     end(); // marca o fim do timer e observa a dura√ß√£o no histogram
   });
   ```

   O *prom-client* possui m√©todos convenientes para medir dura√ß√£o com `Histogram.startTimer()` que retorna uma fun√ß√£o para encerrar e registrar.

3. **Expor as m√©tricas:** Precisamos servir as m√©tricas via HTTP para o Prometheus. Podemos criar um endpoint `/metrics`:

   ```js
   app.get('/metrics', async (req, res) => {
     res.set('Content-Type', promClient.register.contentType);
     res.end(await promClient.register.metrics());
   });
   ```

   Isso coleta todas as m√©tricas registradas e retorna no formato de texto padr√£o.

4. **Iniciar server:** Por fim, inicie seu servidor Node (por ex, `app.listen(3000)`). Ent√£o a URL [http://localhost:3000/metrics](http://localhost:3000/metrics) mostrar√° as m√©tricas.

5. **Configurar Prometheus:** Adicione no `prometheus.yml` um job apontando para o servi√ßo Node, porta 3000 (ou a porta usada) e path `/metrics`. Exemplo:

   ```yaml
   scrape_configs:
     - job_name: 'my-nodeapp'
       static_configs:
         - targets: ['my-node-host:3000']
   ```

   (Se o Node est√° no mesmo Docker Compose do Prometheus, pode usar o nome de servi√ßo do container e porta.)

A partir da√≠, o Prometheus coletar√° as m√©tricas do seu app Node. Voc√™ poder√° consultar coisas como `rate(myapp_http_response_duration_seconds_count[5m])` ou `histogram_quantile(0.9, rate(myapp_http_response_duration_seconds_bucket[5m]))` para ver percentis de lat√™ncia.

#### Python (Flask, etc.)

Em Python, h√° o pacote **prometheus\_client**. Exemplo integrando com Flask:

1. **Instala√ß√£o:** `pip install prometheus_client`.

2. **Cria√ß√£o de m√©tricas:** Digamos que queremos contar requisi√ß√µes e medir dura√ß√£o. Podemos usar um Histogram ou Summary. Aqui um Summary:

   ```python
   from flask import Flask, request
   from prometheus_client import Summary, Counter, start_http_server

   app = Flask(__name__)
   REQUEST_TIME = Summary('myapp_request_processing_seconds', 'Tempo de processamento por rota', ['endpoint'])
   REQUEST_COUNT = Counter('myapp_requests_total', 'Total de requisi√ß√µes', ['endpoint', 'http_status'])
   ```

   Decoramos a rota para coletar m√©tricas:

   ```python
   @app.route("/example")
   def example():
       with REQUEST_TIME.labels(endpoint="/example").time():  # inicia timer autom√°tico
           # ... l√≥gica do endpoint ...
           response = "Hello World"
       REQUEST_COUNT.labels(endpoint="/example", http_status=200).inc()
       return response
   ```

   O `Summary.time()` funciona como context manager medindo o tempo dentro do bloco. Tamb√©m incrementamos um counter de requests totais por endpoint e status.

3. **Expor m√©tricas:** Podemos fazer de duas formas ‚Äì ou usamos o servidor HTTP interno do prometheus\_client ou integramos com Flask. Uma maneira simples: iniciar um *thread* do servidor metrics separado:

   ```python
   if __name__ == "__main__":
       start_http_server(8000)  # inicia servidor em porta 8000
       app.run(host="0.0.0.0", port=5000)
   ```

O `start_http_server(8000)` far√° com que em [http://localhost:8000/metrics](http://localhost:8000/metrics) tenhamos as m√©tricas (note: ele por default exp√µe em /metrics automaticamente). Nesse caso, o Prometheus deve apontar para porta 8000 do app.

Alternativamente, h√° integra√ß√£o para Flask (via middleware) que poderia expor /metrics no pr√≥prio Flask app.

4. **Prometheus config:** Similar aos anteriores, adicionar job apontando para o endpoint do metrics (host e porta usados).

Ap√≥s esses passos, seu app Python estar√° fornecendo m√©tricas. Voc√™ pode conferir acessando [http://localhost:8000/metrics](http://localhost:8000/metrics) e vendo as s√©ries nomeadas `myapp_request_processing_seconds_*` e `myapp_requests_total` entre outras (o client lib Python tamb√©m exp√µe m√©tricas padr√£o do processo Python como uso de mem√≥ria do processo, CPU, etc.).

### Ferramentas legadas e fechadas

Uma dificuldade comum √© monitorar sistemas legados ou softwares propriet√°rios que n√£o oferecem m√©tricas no formato Prometheus. Nesses casos, h√° alguns padr√µes de solu√ß√£o:

* **[Exporters externos](https://prometheus.io/docs/instrumenting/exporters/)**: Como j√° mencionado, se existir um exporter compat√≠vel (oficial ou da comunidade) para aquela ferramenta, ele √© o caminho mais f√°cil ‚Äì rodar o exporter e configur√°-lo como alvo. Por exemplo, para monitorar um servidor Oracle propriet√°rio, pode haver um exporter que conecta no Oracle e extrai estat√≠sticas via queries.

* **[Bridges personalizadas](https://prometheus.io/docs/instrumenting/writing_exporters/#writing-a-bridge-exporter):** Caso n√£o exista um exporter pronto, podemos criar um processo intermedi√°rio (*bridge*) que consulta a ferramenta legada de alguma forma (API REST, CLI, leitura de arquivos de log) e exp√µe resultados em /metrics. Essencialmente, isso √© escrever um pequeno exporter sob medida. Ferramentas de script como Python facilitam isso ‚Äì voc√™ coleta os dados e usa `prometheus_client` para expor.

* **[Integra√ß√µes via gateway ou plugins](https://prometheus.io/docs/instrumenting/writing_exporters/#writing-a-bridge-exporter):** Alguns ambientes possuem hooks para m√©tricas. Por exemplo, aplica√ß√µes .NET legadas podem exportar contadores no Windows Performance Counters ‚Äì a√≠ usar o Windows Exporter para peg√°-los. Em casos extremos, voc√™ pode usar o Pushgateway como ponte: o sistema legado faz push de alguma m√©trica b√°sica para o gateway (n√£o ideal, mas poss√≠vel).

> Em resumo, **sempre** √© poss√≠vel integrar algo ao Prometheus, ainda que indiretamente. A comunidade j√° produziu exporters para muitos sistemas fechados (WebLogic, SAP, etc.). E como √∫ltimo recurso, extrair dados e expor manualmente n√£o √© t√£o complexo gra√ßas √†s bibliotecas cliente dispon√≠veis.

## Alertmanager

O **[Alertmanager](https://prometheus.io/docs/alerting/latest/alertmanager/)** complementa o Prometheus no tratamento de alertas. Enquanto o Prometheus detecta condi√ß√µes de alerta (com base nas m√©tricas e regras definidas), ele delega ao Alertmanager a fun√ß√£o de envio de notifica√ß√µes e gerenciamento desses alertas. Isso inclui agregar alertas similares, evitar duplica√ß√µes, silenciar alertas durante manuten√ß√£o, e encaminh√°-los para canais apropriados (e-mail, sistemas de chat, PagerDuty, etc.).

**Alta Disponibilidade:** O Alertmanager suporta configura√ß√£o em cluster para alta disponibilidade. Quando m√∫ltiplas inst√¢ncias do Alertmanager est√£o ativas, elas se comunicam entre si para deduplicar alertas vindos de dois Prometheus id√™nticos, garantindo que apenas uma notifica√ß√£o seja enviada mesmo quando m√∫ltiplas fontes detectam o mesmo problema.

> Como funciona: voc√™ define no Prometheus regras de alerta (no arquivo de configura√ß√£o ou separado) com express√µes PromQL que identificam situa√ß√µes problem√°ticas. Por exemplo: "se a m√©trica `up` de um servidor for 0 por 5 minutos, dispare alerta".

Quando a condi√ß√£o √© verdadeira, o Prometheus gera um evento de alerta e o envia para o Alertmanager (que est√° configurado na se√ß√£o `alerting` do prometheus.yml). 

> O Alertmanager ent√£o aplica suas pr√≥prias regras de roteamento: por exemplo, enviar alertas de severidade cr√≠tica para um webhook do Slack e para email da equipe X, alertas menos graves s√≥ para email, etc...

**Exemplo pr√°tico:** Vamos configurar um alerta de servidor fora do ar com notifica√ß√£o no Slack.

1. **Definir regra de alerta (Prometheus):** Crie um arquivo `alert.rules.yml`:

```yaml
groups:
- name: instance_down
  rules:
    - alert: InstanceDown
      expr: up == 0
      for: 1m
      labels:
        severity: critical
      annotations:
        summary: "Inst√¢ncia {{ $labels.instance }} fora do ar"
        description: "O alvo {{ $labels.instance }} n√£o respondeu √†s coletas por mais de 1 minuto."
```

Essa regra verifica a m√©trica `up` de todos os alvos; se qualquer um estiver com valor 0 (significa alvo inacess√≠vel) por 1 minuto cont√≠nuo, aciona o alerta **InstanceDown** com severidade **critical**. As anota√ß√µes fornecem um resumo e descri√ß√£o usando templating (inserindo o label instance do alvo problem√°tico).

2. **Incluir regra e Alertmanager na config do Prometheus:** No `prometheus.yml`, adicionar:

```yaml
rule_files:
  - "alert.rules.yml"

alerting:
  alertmanagers:
    - static_configs:
        - targets: ['alertmanager:9093']
```

Aqui presumimos que o Alertmanager est√° rodando e acess√≠vel no endere√ßo `alertmanager:9093` (no Docker Compose, por ex.). O Prometheus agora carrega as regras de alerta e sabe para onde enviar notifica√ß√µes.

3. **Configurar o Alertmanager (alertmanager.yml):** Exemplo m√≠nimo para Slack:

```yaml
route:
  group_by: ['alertname']
  receiver: 'time-slack'
receivers:
  - name: 'time-slack'
    slack_configs:
      - api_url: 'https://hooks.slack.com/services/T000/B000/XXXXX'  # Webhook do Slack
        channel: '#alerts'
        send_resolved: true
        title: "{{ range .Alerts }}{{ .Annotations.summary }}{{ end }}"
        text: "{{ range .Alerts }}{{ .Annotations.description }}{{ end }}"
```

Esse config muito b√°sico diz: todos alertas (n√£o importa o grupo\_by, etc.) ir√£o para o receptor nomeado 'time-slack', que tem um slack\_config apontando para um webhook do Slack no canal **#alerts**. O `title` e `text` da mensagem aproveitam as anota√ß√µes definidas na regra (summary e description). 

O valor `send_resolved: true` indica para notificar tamb√©m quando o alerta for resolvido.

Em produ√ß√£o, o Alertmanager pode ter rotas mais elaboradas ‚Äì por exemplo, roteando com base em labels de alerta (team=A vai para equipe A, severidade critical pode mandar SMS, etc.), escalonamento, agrupamento por determinados campos (como agrupar todos alertas do mesmo datacenter numa s√≥ notifica√ß√£o), etc.

4. **Executar e testar:** Rode o Alertmanager com esse config (no Docker ou bin√°rio). Quando um alerta InstanceDown ocorrer, o Prometheus vai enviar para o Alertmanager, que em seguida usar√° a integra√ß√£o [Slack](https://prometheus.io/docs/alerting/latest/configuration/#slack-receiver) para postar no canal configurado uma mensagem com t√≠tulo "Inst√¢ncia X fora do ar" e descri√ß√£o com detalhes.

Esse foi um exemplo focado em Slack, mas o Alertmanager suporta muitos outros **receivers**: e-mail (SMTP), PagerDuty, OpsGenie, VictorOps, Webhooks gen√©ricos, entre outros. Com ele, voc√™ ganha flexibilidade para gerenciar o "barulho" de alertas: por exemplo, suprimir alertas filhos quando um pai j√° ocorreu ([inhibition](https://prometheus.io/docs/alerting/latest/configuration/#inhibition)), ou silenciar certos alertas durante janelas de manuten√ß√£o planejada.

> **Observa√ß√£o:** O Alertmanager n√£o √© obrigat√≥rio ‚Äì voc√™ pode rodar o Prometheus sem ele se n√£o precisar de notifica√ß√µes externas. Por√©m, para qualquer ambiente de produ√ß√£o, √© altamente recomendado configur√°-lo para n√£o depender de ficar olhando a p√°gina /alerts manualmente. Em outro artigo abordaremos em detalhes boas pr√°ticas de configura√ß√£o do Alertmanager.

### Alertmanager Avan√ßado: Silencing e Inhibition

Em ambientes de produ√ß√£o com muitos alertas, o **"alert fatigue"** (fadiga de alertas) pode ser um problema s√©rio. O Alertmanager oferece funcionalidades avan√ßadas para gerenciar esse cen√°rio: **silencing** (silenciamento) e **inhibition** (inibi√ß√£o).

#### Silencing

O **silencing** permite suprimir temporariamente alertas espec√≠ficos, geralmente durante janelas de manuten√ß√£o planejada. Isso evita spam desnecess√°rio quando voc√™ j√° sabe que um servi√ßo estar√° indispon√≠vel.

**Exemplo de configura√ß√£o de silence:**

```yaml
# Via API do Alertmanager (POST /api/v1/silences)
{
  "matchers": [
    {
      "name": "alertname",
      "value": "InstanceDown",
      "isRegex": false
    },
    {
      "name": "instance",
      "value": "web-server-01:9100",
      "isRegex": false
    }
  ],
  "startsAt": "2023-12-01T10:00:00Z",
  "endsAt": "2023-12-01T12:00:00Z",
  "createdBy": "admin",
  "comment": "Manuten√ß√£o programada do servidor web-01"
}
```

**Silencing via interface web:**
O Alertmanager oferece uma interface web em `/silences` onde voc√™ pode criar silences interativamente, especificando:
* **Matchers**: Labels que identificam os alertas a silenciar
* **Dura√ß√£o**: Per√≠odo de silenciamento (in√≠cio e fim)
* **Coment√°rio**: Justificativa para o silence

#### Inhibition

A **inhibition** permite suprimir alertas secund√°rios quando um alerta prim√°rio j√° est√° ativo. Por exemplo, se um servidor caiu (alerta cr√≠tico), n√£o faz sentido alertar sobre "disco quase cheio" ou "alta lat√™ncia" na mesma inst√¢ncia.

**Exemplo de configura√ß√£o de inhibition:**

```yaml
inhibit_rules:
  # Se um alerta critical estiver ativo, suprimir warnings da mesma inst√¢ncia
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['instance', 'job']
  
  # Se um datacenter estiver down, suprimir alertas de servi√ßos internos
  - source_match:
      alertname: 'DatacenterDown'
    target_match:
      severity: 'warning'
    equal: ['datacenter']
  
  # Se CPU estiver 100%, suprimir alertas de alta lat√™ncia
  - source_match:
      alertname: 'HighCPUUsage'
      severity: 'critical'
    target_match:
      alertname: 'HighLatency'
    equal: ['instance']
```

**Casos de uso comuns:**

* **Alertas de infraestrutura**: Se um rack/datacenter caiu, suprimir alertas de servi√ßos que dependem dele
* **Alertas de aplica√ß√£o**: Se um servi√ßo cr√≠tico est√° down, n√£o alertar sobre m√©tricas secund√°rias
* **Alertas de depend√™ncia**: Se um banco de dados est√° inacess√≠vel, suprimir alertas de aplica√ß√µes que dependem dele

#### Routing Avan√ßado

O Alertmanager permite roteamento sofisticado baseado em labels de alerta:

```yaml
route:
  group_by: ['alertname', 'cluster', 'service']
  group_wait: 30s
  group_interval: 5m
  repeat_interval: 4h
  
  routes:
    # Alertas cr√≠ticos v√£o para PagerDuty + Slack
    - match:
        severity: critical
      receiver: 'pager-duty-critical'
      continue: true  # Continua para o pr√≥ximo receiver
    
    # Alertas cr√≠ticos tamb√©m v√£o para Slack
    - match:
        severity: critical
      receiver: 'slack-critical'
    
    # Alertas de infraestrutura v√£o para equipe de infra
    - match:
        job: node
      receiver: 'infra-team'
    
    # Alertas de aplica√ß√£o v√£o para equipe de dev
    - match:
        job: app
      receiver: 'dev-team'
    
    # Default: todos os outros alertas v√£o para Slack geral
    - receiver: 'slack-general'

receivers:
  - name: 'pager-duty-critical'
    pagerduty_configs:
      - service_key: 'your-pagerduty-key'
  
  - name: 'slack-critical'
    slack_configs:
      - api_url: 'https://hooks.slack.com/services/...'
        channel: '#alerts-critical'
  
  - name: 'infra-team'
    slack_configs:
      - api_url: 'https://hooks.slack.com/services/...'
        channel: '#infra-alerts'
  
  - name: 'dev-team'
    slack_configs:
      - api_url: 'https://hooks.slack.com/services/...'
        channel: '#dev-alerts'
  
  - name: 'slack-general'
    slack_configs:
      - api_url: 'https://hooks.slack.com/services/...'
        channel: '#monitoring'
```

**Recursos avan√ßados:**

* **Agrupamento inteligente**: `group_by` agrupa alertas similares em uma notifica√ß√£o
* **Tempo de espera**: `group_wait` aguarda antes de enviar o primeiro alerta do grupo
* **Intervalo de repeti√ß√£o**: `repeat_interval` define quando reenviar alertas n√£o resolvidos
* **Roteamento condicional**: `continue: true` permite m√∫ltiplos receivers para o mesmo alerta

## PushGateway

O **[Pushgateway](https://prometheus.io/docs/instrumenting/pushing/)** √© um componente auxiliar do ecossistema Prometheus que permite coletar m√©tricas via modelo *push* em situa√ß√µes espec√≠ficas. A ideia √© que certos jobs ou aplicativos ef√™meros, que n√£o t√™m como serem raspados diretamente (por exemplo, um script cron que executa e termina rapidamente), possam empurrar suas m√©tricas para um gateway intermedi√°rio. O Prometheus ent√£o coleta essas m√©tricas do Pushgateway posteriormente.

Funciona assim: o job de curta dura√ß√£o (ou qualquer processo que n√£o viva tempo suficiente para ser raspado) envia um HTTP POST para o Pushgateway com suas m√©tricas no formato Prometheus. O Pushgateway armazena essas m√©tricas em mem√≥ria e as exp√µe em seu pr√≥prio `/metrics`. O Prometheus configura um scrape no Pushgateway, coletando tudo que estiver l√°.

**Por√©m,** √© importante entender que o Pushgateway deve ser usado com modera√ß√£o e prop√≥sito claro. Ele n√£o √© um agente gen√©rico para substituir o modelo pull. Alguns pontos de aten√ß√£o destacados pela documenta√ß√£o oficial:

* Se m√∫ltiplas inst√¢ncias usam um mesmo Pushgateway, ele vira um ponto central de falha e potencial gargalo.
* Voc√™ perde a detec√ß√£o autom√°tica de *down* (j√° que as m√©tricas s√£o push, o Prometheus n√£o sabe se um job n√£o est√° rodando ou s√≥ n√£o teve m√©tricas recentes).
* O Pushgateway **n√£o expira** automaticamente s√©ries que foram enviadas. Uma vez que uma m√©trica √© empurrada, ela ficar√° l√° at√© ser sobrescrita ou manualmente apagada via API do Pushgateway. Isso significa que m√©tricas de jobs antigos podem ficar persistindo como "fantasmas", exigindo que voc√™ gerencie remo√ß√£o ou inclus√£o de algum label de *instance* para distingui-las.

Devido a esses aspectos, o uso recomendado do Pushgateway √© **capturar resultados de jobs batch de n√≠vel de servi√ßo** ‚Äì isto √©, trabalhos que n√£o pertencem a uma √∫nica m√°quina ou inst√¢ncia espec√≠fica, mas sim algo como "um script de limpeza de banco que roda uma vez por dia".

Nesse caso, o job emite (push) uma m√©trica do tipo "usuarios\_deletados\_total{job="cleanup"} 123" e termina. O Pushgateway guarda esse valor.

O Prometheus, ao raspar, ter√° essa informa√ß√£o agregada do job. Como esse tipo de job n√£o tem um "endpoint" pr√≥prio para scrap, o Pushgateway serve como cache.

Para outros cen√°rios, onde o push √© considerado porque h√° firewall/NAT impedindo scrapes, a documenta√ß√£o sugere alternativas melhores ‚Äì como rodar Prometheus perto dos alvos (dentro da rede) ou usar algo como o **[PushProx](https://github.com/prometheus/pushprox)** para atravessar firewalls mantendo o modelo pull. E para jobs cron por m√°quina, que t√™m contexto de host, recomenda-se usar o **[Node Exporter Textfile Collector](https://github.com/prometheus/node_exporter#textfile-collector)** (escrever m√©tricas em um arquivo que o Node Exporter l√™), ao inv√©s do Pushgateway.

> Resumindo: o Pushgateway √© √∫til, mas **somente** em casos espec√≠ficos. Evite us√°-lo para coletar m√©tricas de servi√ßos normais (isso seria ‚Äúusar push por pregui√ßa‚Äù, e acarretaria problemas de dados stale e falta de detec√ß√£o de falha). Use-o para jobs batch pontuais, e mesmo assim, sem abusar ‚Äì lembre-se de limpar m√©tricas antigas se necess√°rio, ou projetar os labels de modo que cada job substitua seu pr√≥prio valor sem acumular lixo.

## Federa√ß√£o

A **federa√ß√£o** no Prometheus permite que uma inst√¢ncia do Prometheus (geralmente chamada de **federadora** ou **global**) fa√ßa scrape em endpoints de outras inst√¢ncias do Prometheus (**federadas**) para obter um subconjunto de suas m√©tricas.

Em outras palavras, √© uma forma de **hierarquizar** o monitoramento: por exemplo, voc√™ pode ter um Prometheus por data center coletando tudo localmente, e um Prometheus global que apenas busca m√©tricas j√° agregadas de cada data center para ter uma vis√£o geral corporativa.

Existem dois casos de uso principais para federa√ß√£o:

1. **[Agrega√ß√£o hier√°rquica](https://prometheus.io/docs/prometheus/latest/federation/)**: como no exemplo acima, onde cada Prometheus local faz o trabalho pesado e calcula agregados (soma de CPU por datacenter, lat√™ncia m√©dia de servi√ßo X por datacenter, etc.), e o Prometheus global s√≥ extrai essas s√©ries agregadas prontas. Isso d√° uma vis√£o do todo sem sobrecarregar a inst√¢ncia global com todas as s√©ries detalhadas.

2. **[Checagens cruzadas ou seletivas](https://prometheus.io/docs/prometheus/latest/federation/)**: Puxar algumas poucas m√©tricas de outra inst√¢ncia para compara√ß√µes. Exemplo: voc√™ tem um Prometheus dedicado a HAProxy e outro para um app front-end, pode federar a m√©trica de QPS do HAProxy no Prometheus do front-end para checar se ambos observam o mesmo tr√°fego. Normalmente, isso √© usado at√© mesmo apenas para alertas (voc√™ pode configurar alertas usando essas poucas m√©tricas federadas).

**[Quando N√ÉO usar federa√ß√£o](https://prometheus.io/docs/prometheus/latest/federation/#when-not-to-use-federation):** a tenta√ß√£o de federar tudo de todos os Prometheus em um ‚Äúsuper Prometheus‚Äù central deve ser evitada. Pegar todas as s√©ries de inst√¢ncias filhas e centralizar em uma s√≥ inst√¢ncia global traz v√°rios problemas:

* **Escalabilidade limitada:** O desempenho do Prometheus √© limitado pelos recursos de um √∫nico n√≥ (n√£o escala horizontalmente). Se voc√™ puxa tudo para um s√≥ servidor global, no fim do dia voc√™ est√° limitado ao throughput e mem√≥ria de uma m√°quina. Isso anula a distribui√ß√£o de carga que m√∫ltiplas inst√¢ncias proporcionam.
* **Performance e carga duplicada:** Al√©m de sobrecarregar a inst√¢ncia global ao ter que armazenar e consultar tudo, a pr√≥pria opera√ß√£o de federa√ß√£o (expor /federate e responder a scraping) gera carga nas inst√¢ncias filhas. Se a consulta federada n√£o for focada (usar express√µes match\[] gen√©ricas demais), pode consumir muitos recursos para as inst√¢ncias fonte servirem esses dados.
* **Confiabilidade reduzida:** Voc√™ adiciona um ponto extra de falha. Se o link entre uma inst√¢ncia local e a global cair, a inst√¢ncia global ‚Äúfica cega‚Äù √†quele segmento. E pior, se voc√™ centralizou a avalia√ß√£o de certos alertas s√≥ no global, pode ficar sem alertas (falso negativo) caso o global perca conex√£o com os locais. A recomenda√ß√£o de especialistas √© sempre que poss√≠vel avaliar alertas o mais localmente poss√≠vel ‚Äì por exemplo, um alerta ‚Äúservi√ßo X caiu‚Äù deve ser definido no Prometheus que coleta servi√ßo X, n√£o em um global distante, exatamente para n√£o depender de rede.
* **Delay e poss√≠veis inconsist√™ncias:** A federa√ß√£o n√£o √© instant√¢nea; h√° lat√™ncia entre um dado ser coletado no Prometheus filho e ser federado pelo pai. Al√©m disso, condi√ß√µes de corrida podem fazer o global perder algumas amostras ou ver valores ligeiramente diferentes (por exemplo, contadores que resetaram podem parecer estranhos). Para uns poucos agregados isso √© toler√°vel, mas se voc√™ federar tudo e depender disso para alertar, pode ter sutilezas indesejadas.
* **Complexidade de configura√ß√£o e seguran√ßa:** √â mais complexo gerenciar dois n√≠veis de Prometheus, com configura√ß√µes de match\[], externas labels √∫nicas por inst√¢ncia, etc. Tamb√©m √© necess√°rio expor o endpoint /federate das inst√¢ncias filhas ‚Äì o que pode ampliar a superf√≠cie de ataque ou requerer configura√ß√µes TLS, autentica√ß√£o, caso atravesse redes n√£o confi√°veis.

Em raz√£o desses fatores, a federa√ß√£o deve ser usada **apenas** para casos de uso bem planejados (tipicamente agrega√ß√µes de baixo volume ou m√©tricas espec√≠ficas). N√£o √© a solu√ß√£o adequada para reten√ß√£o de longo prazo nem para alta disponibilidade.

> **NOTA:** Para necessidades de **escalabilidade horizontal** e **armazenamento de longo prazo**, surgiram outros projetos que complementam o Prometheus, como **Thanos**, **Cortex** e **Mimir** (Grafana Labs). Essas solu√ß√µes armazenam as s√©ries em storage distribu√≠do (objeto, bigtable, etc.) e permitem ‚Äújuntar‚Äù m√∫ltiplas inst√¢ncias como se fossem uma s√≥, suportando consultas globais e reten√ß√£o virtualmente infinita. Exploraremos essas alternativas em outro artigo, mas adianta-se que elas resolvem muitos dos problemas de tentar usar federa√ß√£o pura para esses fins.

## Remote Write e Remote Read

O Prometheus pode ser configurado para enviar suas m√©tricas em tempo real para bancos externos (**remote write**) e buscar dados hist√≥ricos de outros sistemas (**remote read**). Essa funcionalidade √© fundamental para integra√ß√£o com solu√ß√µes de armazenamento de longo prazo, compliance e an√°lise de dados.

### Remote Write

O **remote write** permite que o Prometheus envie amostras coletadas para sistemas externos em tempo real, mantendo uma c√≥pia local. Isso √© √∫til para:

* **Reten√ß√£o de longo prazo**: Enviar dados para sistemas como InfluxDB, TimescaleDB, ou solu√ß√µes cloud
* **Compliance e auditoria**: Manter m√©tricas por meses/anos para requisitos regulat√≥rios
* **Machine Learning**: Integrar com plataformas de ML para an√°lise preditiva
* **Correla√ß√£o de dados**: Combinar m√©tricas com logs e traces em sistemas unificados

**Exemplo de configura√ß√£o:**

```yaml
remote_write:
  - url: "https://longterm.example.com/api/v1/write"
    basic_auth:
      username: "prometheus"
      password: "password"
    write_relabel_configs:
      - source_labels: [__name__]
        regex: 'node_.*'
        action: keep
    queue_config:
      max_samples_per_send: 1000
      max_shards: 30
      capacity: 2500
```

**Configura√ß√µes importantes:**

* **`url`**: Endpoint do sistema de destino
* **`basic_auth`**: Autentica√ß√£o b√°sica (tamb√©m suporta TLS)
* **`write_relabel_configs`**: Filtros para enviar apenas m√©tricas espec√≠ficas
* **`queue_config`**: Configura√ß√µes de buffer e performance

### Remote Read

O **remote read** permite que o Prometheus busque dados hist√≥ricos de sistemas externos, como se fossem parte do seu TSDB local. Isso √© √∫til para:

* **Consultas hist√≥ricas**: Acessar dados antigos sem manter tudo localmente
* **Migra√ß√£o de dados**: Transi√ß√£o gradual entre sistemas de armazenamento
* **An√°lise retrospectiva**: Investigar incidentes passados com dados completos

**Exemplo de configura√ß√£o:**

```yaml
remote_read:
  - url: "https://longterm.example.com/api/v1/read"
    basic_auth:
      username: "prometheus"
      password: "password"
    read_recent: true
    required_matchers:
      - label: "job"
        value: "node"
```

### Casos de Uso T√≠picos

**1. Integra√ß√£o com Grafana Cloud:**
```yaml
remote_write:
  - url: "https://prometheus-prod-XX-XXX.grafana.net/api/prom/push"
    basic_auth:
      username: "12345"
      password: "glc_eyJvIjoiOTk5OTkiLCJuIjoiYWRtaW4iLCJpIjoiMTIzNDU2Nzg5MCJ9"
```

**2. Envio para InfluxDB:**
```yaml
remote_write:
  - url: "http://influxdb:8086/api/v2/prom/write?org=myorg&bucket=prometheus"
    basic_auth:
      username: "admin"
      password: "password"
```

**3. M√∫ltiplos destinos:**
```yaml
remote_write:
  - url: "https://backup-storage.example.com/write"
    write_relabel_configs:
      - source_labels: [__name__]
        regex: '.*'
        action: keep
  - url: "https://ml-platform.example.com/metrics"
    write_relabel_configs:
      - source_labels: [__name__]
        regex: 'app_.*'
        action: keep
```

> **Importante**: Remote write/read n√£o substitui o armazenamento local do Prometheus. O TSDB local continua sendo usado para consultas recentes e alertas. O remote write √© **aditivo** - voc√™ mant√©m os dados locais e envia uma c√≥pia para sistemas externos.

## Under the Hood

Nesta se√ß√£o, vamos dissecar o funcionamento interno do armazenamento de dados do Prometheus ‚Äì o **[Time Series Database](https://prometheus.io/docs/introduction/architecture/#time-series-database)** (TSDB) local ‚Äì e entender por que ele consome recursos como consome.

Quando instalamos o Prometheus, uma pasta de dados (por padr√£o chamada `data/`) √© usada para persistir as s√©ries temporais coletadas. Dentro dela, os dados s√£o organizados em blocos de tempo fixo. Por padr√£o, cada **bloco** cobre 2 horas de m√©tricas. Ap√≥s duas horas de coleta, o Prometheus fecha aquele bloco e inicia outro.

Periodicamente, v√°rios blocos menores podem ser compactados em blocos maiores (por exemplo, 5 blocos de 2h podem ser mesclados num bloco de 10h de dados, e assim por diante). A estrutura de arquivos t√≠pica em `data/` √© assim (exemplo simplificado):

```
data/
‚îú‚îÄ‚îÄ 01GZY5ABCD.../       # pasta de um bloco de dados
‚îÇ   ‚îú‚îÄ‚îÄ meta.json        # metadados do bloco
‚îÇ   ‚îú‚îÄ‚îÄ index            # √≠ndice para busca das s√©ries no bloco
‚îÇ   ‚îú‚îÄ‚îÄ chunks/          # peda√ßos contendo os samples comprimidos
‚îÇ   ‚îî‚îÄ‚îÄ tombstones       # (pode estar vazio) marca√ß√µes de dele√ß√£o
‚îú‚îÄ‚îÄ 01GZY1WXYZ.../       # outro bloco (mais antigo, por ex)
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ chunks_head/         # chunks do bloco "head" atual (em uso)
‚îî‚îÄ‚îÄ wal/                 # Write-Ahead Log (log de escrita recente)
    ‚îú‚îÄ‚îÄ 00000000
    ‚îú‚îÄ‚îÄ 00000001
    ‚îî‚îÄ‚îÄ checkpoint.000001/ ...
```

Cada bloco de 2h √© identificado por um **[ULID](https://github.com/prometheus/prometheus/blob/main/tsdb/encoding/ulid.go)** (ID √∫nico lexicograficamente orden√°vel) que comp√µe o nome da pasta. Dentro de um bloco, temos:

* **meta.json:** arquivo JSON com metadados do bloco (faixa de tempo coberta, stats de quantas s√©ries/amostras cont√©m, hist√≥rico de compacta√ß√£o, etc.).
* **index:** arquivo de √≠ndice invertido para permitir procurar s√©ries rapidamente pelo nome e labels, e localizar em quais chunks est√£o seus dados.
* **chunks/**: diret√≥rio contendo os arquivos bin√°rios de chunks de dados. Os *chunks* s√£o os blocos comprimidos de amostras das s√©ries. Cada arquivo (nomeado como 000001, 000002, ...) cont√©m muitos chunks. O tamanho m√°ximo de cada arquivo √© \~512MB para facilitar gerenciamento.
* **tombstones:** arquivo que registra intervalos de dados deletados manualmente (via API de delete), se houver.

Al√©m dos blocos fechados, existe o **[Head block](https://prometheus.io/docs/introduction/architecture/#head-block)** (bloco atual em mem√≥ria) que armazena as m√©tricas em curso. Os dados mais recentes (√∫ltimas \~2h) residem em mem√≥ria para escrita r√°pida e consultas de curt√≠ssimo prazo.

A cada 2h, o Prometheus ‚Äúdissolve‚Äù parte do Head em um bloco persistente e libera daquela mem√≥ria. Vamos inspecionar um exemplo de **meta.json** para entender seus campos:

```json
{
    "ulid": "01BKGTZQ1SYQJTR4PB43C8PD98",
    "minTime": 1602237600000,
    "maxTime": 1602244800000,
    "stats": {
        "numSamples": 553673232,
        "numSeries": 1346066,
        "numChunks": 4440437
    },
    "compaction": {
        "level": 1,
        "sources": [
            "01EM65SHSX4VARXBBHBF0M0FDS",
            "01EM6GAJSYWSQQRDY782EA5ZPN"
        ]
    },
    "version": 1
}
```

Explicando os campos principais:

* **ulid:** Identificador √∫nico do bloco (um c√≥digo 128-bit parecido com [UUID](https://en.wikipedia.org/wiki/Universally_unique_identifier)). Ele √© tamb√©m o nome da pasta do bloco.
* **minTime e maxTime:** Timestamp inicial e final (epoch em milissegundos) cobertos pelos samples deste bloco. No exemplo, corresponde a um intervalo de 2h.
* **stats:** Estat√≠sticas do bloco ‚Äì quantas amostras ([numSamples](https://prometheus.io/docs/introduction/architecture/#head-block)), s√©ries ([numSeries](https://prometheus.io/docs/introduction/architecture/#head-block)) e chunks ([numChunks](https://prometheus.io/docs/introduction/architecture/#head-block)) est√£o armazenados nele. No exemplo real acima, temos \~1,34 milh√£o de s√©ries distintas, totalizando 553 milh√µes de amostras em \~4,44 milh√µes de chunks dentro desse bloco de 2h. Esses n√∫meros d√£o uma no√ß√£o do volume de dados.
* **compaction:** Informa o hist√≥rico de compacta√ß√£o. **[level](https://prometheus.io/docs/introduction/architecture/#head-block)** indica quantas vezes j√° foi compactado (1 significa um bloco resultante da jun√ß√£o de outros menores). **[sources](https://prometheus.io/docs/introduction/architecture/#head-block)** lista os IDs dos blocos que foram combinados para formar este (no caso, dois blocos anteriores). Se o bloco foi gerado direto do Head (dados ‚Äúoriginais‚Äù), √†s vezes sources cont√©m ele pr√≥prio.
* **version:** Vers√£o do formato do bloco/arquivo (para compatibilidade futura).

Com isso, entendemos que cada bloco √© imut√°vel depois de escrito. Se novos dados chegam daquele intervalo, seria criado um bloco novo via compaction. Isso facilita a confiabilidade ‚Äì dados hist√≥ricos n√£o mudam.

O **arquivo de √≠ndice (index)** serve para mapear as s√©ries e labels aos chunks dentro do bloco. Ele funciona como um √≠ndice invertido: dado um nome de m√©trica e um conjunto de labels, encontra os IDs das s√©ries correspondentes e, ent√£o, aponta para os chunks onde est√£o os dados daquela s√©rie.

Assim, ao fazer uma consulta, o Prometheus carrega o √≠ndice do bloco relevante e consegue buscar rapidamente somente os chunks necess√°rios (por exemplo, pula chunks inteiros que est√£o fora do range de tempo consultado, usando informa√ß√µes de minTime/maxtime dos chunks). 

O √≠ndice √© altamente otimizado e comprimido ‚Äì usa conceitos de [posting lists](https://prometheus.io/docs/introduction/architecture/#posting-lists) (listas de IDs de s√©ries para cada label-valor) e [tabelas de s√≠mbolos](https://prometheus.io/docs/introduction/architecture/#symbol-table) para strings √∫nicas. Esses detalhes avan√ßados fogem do escopo aqui, mas o importante √©: o √≠ndice permite que mesmo com milh√µes de s√©ries por bloco, o Prometheus consiga localizar dados sem varrer tudo linearmente.

Finalmente, o **[WAL (Write-Ahead Log)](https://prometheus.io/docs/introduction/architecture/#write-ahead-log)** √© um log de transa√ß√µes recente onde cada amostra coletada √© gravada imediatamente no disco antes de ser inserida na mem√≥ria do Head. Isso garante que, se o Prometheus cair inesperadamente, ao voltar ele pode reprocessar o WAL e recuperar as amostras que ainda n√£o tinham sido compactadas em blocos.

O WAL consiste em arquivos sequenciais (`00000000`, `00000001`, etc.) que v√£o acumulando as escritas. Periodicamente, o Prometheus faz um checkpoint (snapshot do head) e limpa parte do WAL j√° aplicado.

Em caso de crash, ele l√™ desde o √∫ltimo checkpoint para restaurar o estado do Head.

### Gerenciamento de mem√≥ria pelo Prometheus

O Prometheus armazena as s√©ries temporais em mem√≥ria para r√°pido acesso √†s m√©tricas recentes, enquanto grava continuamente os novos dados no disco (WAL) para durabilidade. Isso pode levar a alto uso de RAM e espa√ßo em disco.

![](https://raw.githubusercontent.com/scovl/scovl.github.io/main/post/images/tsdb/prom-mem02.png)

Como mencionado, o Prometheus mant√©m em RAM todas as s√©ries ativas do bloco atual (tipicamente √∫ltimas 2 horas de dados por s√©rie). Essa decis√£o arquitetural visa desempenho: consultas sobre dados recentes (que s√£o as mais comuns, e.g. alertas e dashboards de curto prazo) n√£o precisam esperar leitura de disco ‚Äì os valores j√° est√£o na mem√≥ria. 

Al√©m disso, novas amostras sendo inseridas a cada segundo/minuto s√£o agregadas a estruturas em mem√≥ria (evitando I/O de disco a cada opera√ß√£o, que seria invi√°vel em alta escala). O resultado √© que o **consumo de RAM** do Prometheus cresce com o n√∫mero de s√©ries ativas e com a frequ√™ncia de coleta.

Estima-se, por experi√™ncias reportadas, que cada s√©rie ativa consome em torno de **\~3 KB de RAM** (depende de labels, comprimento do nome, etc.). Portanto, 1 milh√£o de s√©ries pode usar na ordem de 3‚Äì4 GB de RAM apenas para manter o head da TSDB.

Em paralelo, o Prometheus escreve todas as amostras no WAL (em disco) para n√£o perd√™-las em caso de crash. A cada 2 horas, ele ent√£o compacta esses dados quentes em um bloco de 2h comprimido e libera a mem√≥ria correspondente. Ou seja, h√° um ciclo onde a mem√≥ria vai sendo ocupada pelas amostras recentes, e de hora em hora (na verdade 2h) h√° um flush para disco que esvazia um pouco a mem√≥ria (mas novas s√©ries podem surgir e ocupar de novo).

O *design* de manter dados recentes em mem√≥ria traz a consequ√™ncia de que **o uso de RAM aumenta com a carga de m√©tricas e n√£o √© liberado at√© que os blocos sejam fechados ou as s√©ries cessem**. Em per√≠odos de pico (muitas s√©ries novas aparecendo rapidamente), o Prometheus pode chegar a consumir muita mem√≥ria para acompanhar.

Se faltar RAM, o processo corre risco de OOM (matar por falta de mem√≥ria) ou, no melhor caso, o sistema operacional vai come√ßar a usar swap ‚Äì o que degrada muito a performance. Na imagem acima, vemos que tanto a RAM quanto o armazenamento em disco podem crescer substancialmente √† medida que aumentamos o volume de dados monitorados.

> **Quanto mais dias de reten√ß√£o mantidos no Prometheus, mais recursos s√£o usados e maior o esfor√ßo para consultas longas. Manter dados hist√≥ricos demais pode sobrecarregar a mem√≥ria e o disco, al√©m de dificultar encontrar informa√ß√µes recentes relevantes.**

Embora possamos configurar reten√ß√µes longas (30, 60 dias), isso n√£o significa que o Prometheus foi otimizado para operar eficientemente com esse hist√≥rico todo localmente. Lembre-se: ele n√£o indexa por data de forma distribu√≠da ‚Äì consultas que abrangem muitos dias ter√£o que ler v√°rios blocos do disco e processar um grande volume de amostras.

Na pr√°tica, reter al√©m de algumas semanas come√ßa a tornar as consultas bem lentas e o uso de disco muito alto (sem falar nos backups dessa quantidade de data). Consultas extensas acabam exigindo leitura de m√∫ltiplos blocos e processamento de grandes volumes de dados, o que impacta diretamente a performance do sistema.

A imagem acima ilustra que, √† medida que guardamos mais dias, o custo de recursos cresce e pode inclusive ofuscar tend√™ncias atuais no meio de tanto dado antigo.

![](https://raw.githubusercontent.com/scovl/scovl.github.io/main/post/images/tsdb/prom-mem03.png)

A filosofia do Prometheus √© ser a ferramenta de **monitoramento em tempo real** e de curto/m√©dio prazo.

Para an√°lises hist√≥ricas longas ou compliance (guardar m√©tricas por 1 ano, por exemplo), a solu√ß√£o comum √© integrar um back-end de longo prazo (Thanos, Cortex, databases remotas) que arquivem esses dados, enquanto o Prometheus local mant√©m s√≥ o necess√°rio para opera√ß√£o/alertas recentes.

Assim voc√™ tem o melhor dos dois mundos: rapidez no real-time e hist√≥rico completo dispon√≠vel quando precisar, sem sobrecarregar o Prometheus diariamente.

> Todas as amostras recentes residem na mem√≥ria principal (Head), com flush peri√≥dico para disco a cada 2 horas. O WAL no disco captura as escritas para garantir durabilidade. Em situa√ß√£o de carga extrema, o OS pode usar swap, mas isso deve ser evitado pois degrada o desempenho.

Vamos recapitular o ciclo de vida dos dados no Prometheus e seu impacto em mem√≥ria/disco:

* **Head Block (mem√≥ria):** Novas s√©ries e amostras entram aqui. As s√©ries ativas ocupam estruturas na heap da aplica√ß√£o Go do Prometheus. A cada amostra recebida, ela tamb√©m √© anexada no **[WAL](https://prometheus.io/docs/introduction/architecture/#write-ahead-log)** (no SSD/disco) para registro permanente. Durante at√© \~2h, os dados ficam dispon√≠veis no Head para consultas instant√¢neas. Por isso, consultas e alertas em dados "frescos" s√£o muito r√°pidas.

* **Flush para bloco persistente:** Quando o intervalo de 2h se completa, o Prometheus corta o bloco (na verdade ele espera 2h ou 1h30 dependendo de certas condi√ß√µes) e escreve um **[novo bloco](https://prometheus.io/docs/introduction/architecture/#head-block)** no diret√≥rio data (contendo aqueles 2h de amostras agora imut√°veis, j√° comprimidas). Em seguida, libera da mem√≥ria boa parte das estruturas referentes √†quele intervalo. O head ent√£o mant√©m somente as s√©ries ainda ativas que extrapolem o pr√≥ximo bloco.

* **Compaction:** Ap√≥s algumas rota√ß√µes de bloco, o Prometheus agrupa blocos menores em blocos maiores (por exemplo, une 5 blocos de 2h em 1 bloco de 10h, e assim por diante). Isso ocorre em segundo plano e ajuda a reduzir o n√∫mero de arquivos e melhorar compress√£o geral. Compaction consome CPU/disk I/O, mas √© intercalado para n√£o interferir muito.

* **Reten√ß√£o e cleanup:** Quando um bloco excede a reten√ß√£o configurada (ex: ficou mais velho que 15 dias), ele √© marcado para dele√ß√£o. A limpeza ocorre periodicamente e remove blocos expirados. Importante: a remo√ß√£o n√£o √© imediata ao passar do prazo ‚Äì o processo de cleanup roda em intervalos (at√© 2h de delay). Durante a limpeza, o Prometheus deleta os diret√≥rios daqueles blocos antigos, liberando espa√ßo em disco.

* **Rein√≠cio e recupera√ß√£o:** Se o Prometheus reiniciar ou cair, na inicializa√ß√£o ele precisa recarregar o estado. Ele vai abrir todos os blocos persistentes (apenas meta e √≠ndice, sem carregar todos os dados) e principalmente processar o WAL para recriar o Head com as amostras que ainda n√£o estavam em bloco. Esse processo de recupera√ß√£o do WAL pode demorar dependendo do tamanho (por isso h√° checkpoint para otimizar). Ao final, o sistema retorna ao estado como se nunca tivesse parado (exceto pelos minutos offline onde dados podem ter se perdido se os alvos n√£o suportam retroativa).

Tudo isso explica por que o Prometheus consome **bastante mem√≥ria**: ele aposta em manter as s√©ries recentes acess√≠veis e indexadas para respostas r√°pidas.

Num Prometheus com muitos alvos ou alta cardinalidade (muitas combina√ß√µes de labels), o consumo de RAM pode facilmente ser o principal limitador. Conforme mencionado anteriormente, 1 milh√£o de s√©ries ativas pode exigir v√°rios GB de RAM, portanto planeje a capacidade de acordo com o volume de m√©tricas esperado.

Infelizmente, n√£o h√° muito **tunings** manuais a fazer na mem√≥ria al√©m de reduzir a quantidade de dados: **menos s√©ries ou menor frequ√™ncia de coleta** = menos uso de RAM. O Prometheus n√£o tem um mecanismo interno de shard autom√°tico ou flush mais frequente (o flush √© fixo \~2h por design).

Ent√£o, as solu√ß√µes se resumem a **escalar verticalmente** (m√°quinas com mais mem√≥ria, CPU, disco r√°pido) ou **escalar horizontalmente** (dividir a carga entre v√°rios Prometheus, cada um monitorando uma parte das targets). Nas melhores pr√°ticas a seguir, daremos dicas para mitigar esses desafios de desempenho e dimensionamento.

### Native Histograms (Recurso Experimental)

O Prometheus introduziu **Native Histograms** como um recurso experimental nas vers√µes mais recentes (2.40+). Essa funcionalidade representa uma evolu√ß√£o significativa na forma como histogramas s√£o armazenados e consultados.

#### Diferen√ßas dos Histogramas Tradicionais

**Histogramas tradicionais:**
* Usam buckets predefinidos (ex: 0.1, 0.5, 1.0, 2.5, 5.0, 10.0)
* Cada bucket gera uma s√©rie separada (`_bucket`)
* Requerem m√∫ltiplas s√©ries para representar uma distribui√ß√£o
* Limitados pela granularidade dos buckets

**Native Histograms:**
* Usam buckets din√¢micos e adaptativos
* Armazenam a distribui√ß√£o completa em uma √∫nica s√©rie
* Permitem maior precis√£o nos percentis
* Reduzem significativamente o n√∫mero de s√©ries

#### Configura√ß√£o

Para habilitar native histograms, adicione a flag experimental:

```bash
prometheus --enable-feature=native-histograms
```

Ou no Docker:

```yaml
command:
  - '--enable-feature=native-histograms'
```

#### Exemplo de Uso

**Instrumenta√ß√£o com native histograms (Go):**
```go
import (
    "github.com/prometheus/client_golang/prometheus"
    "github.com/prometheus/client_golang/prometheus/promauto"
)

var (
    requestDuration = promauto.NewHistogram(prometheus.HistogramOpts{
        Name: "http_request_duration_seconds",
        Help: "Duration of HTTP requests",
        NativeHistogramBucketFactor: 1.1,  // Fator de crescimento dos buckets
        NativeHistogramMaxBucketNumber: 100, // M√°ximo de buckets
    })
)
```

**Consulta de percentis:**
```promql
# Percentil 95 usando native histogram
histogram_quantile(0.95, rate(http_request_duration_seconds[5m]))

# Percentil 99
histogram_quantile(0.99, rate(http_request_duration_seconds[5m]))
```

#### Vantagens

* **Menos s√©ries**: Uma m√©trica de lat√™ncia que antes gerava 10+ s√©ries agora gera apenas 1
* **Maior precis√£o**: Buckets adaptativos capturam melhor a distribui√ß√£o real
* **Melhor performance**: Menos overhead de armazenamento e consulta
* **Compatibilidade**: Funciona com todas as fun√ß√µes PromQL existentes

#### Considera√ß√µes

* **Experimental**: Ainda em desenvolvimento, pode ter mudan√ßas na API
* **Migra√ß√£o**: Requer atualiza√ß√£o das bibliotecas cliente
* **Compatibilidade**: Funciona apenas com vers√µes recentes do Prometheus

> **Nota**: Native histograms s√£o especialmente √∫teis para m√©tricas de lat√™ncia em aplica√ß√µes de alta performance, onde a precis√£o dos percentis √© cr√≠tica.

## Melhores Pr√°ticas

Depois de entender a mec√¢nica interna do Prometheus, √© v√°lido reunir algumas recomenda√ß√µes para tirar o melhor proveito da ferramenta de forma escal√°vel e confi√°vel.

### Planejamento de Capacidade

* **Estime volume de m√©tricas e reten√ß√£o:** Antes de implantar, fa√ßa uma estimativa do n√∫mero de s√©ries que voc√™ vai coletar e defina uma reten√ß√£o condizente. Lembre que por padr√£o s√£o 15 dias. Se n√£o precisar de tudo isso para monitoramento di√°rio, reten√ß√µes menores aliviam recursos. Ao contr√°rio, se precisar de mais tempo hist√≥rico, esteja ciente do aumento de disco e possivelmente avalie armazenamento remoto.

* **Monitore o Prometheus em si:** "Quis custodiet ipsos custodes?" ‚Äì o Prometheus exp√µe suas pr√≥prias m√©tricas (no endpoint /metrics dele). Use um outro Prometheus ou a mesma inst√¢ncia para monitorar m√©tricas como `prometheus_tsdb_head_series` (n√∫mero de s√©ries no head), `prometheus_tsdb_head_samples_appended_total` (samples inseridos por segundo), `prometheus_engine_query_duration_seconds` (lat√™ncia das consultas), etc. Isso alerta para crescimento de cardinalidade inesperado ou consultas muito pesadas rodando.

* **Dimensione hardware adequadamente:** Regra emp√≠rica: 1 CPU core pode processar aproximadamente at√© 200k amostras por segundo (varia, mas √© uma ideia). Mem√≥ria, calcule \~3kB por s√©rie ativa. Disco: \~1-2 bytes por amostra armazenada comprimida (15 dias, 200 milh√µes de amostras \~ 200-300MB). Use SSDs r√°pidos ‚Äì opera√ß√µes de WAL e blocos beneficiam de I/O r√°pido.

### Organiza√ß√£o de M√©tricas e Labels

* **Consist√™ncia na nomea√ß√£o:** Siga conven√ß√µes de nomenclatura para facilitar a vida. Use nomes descritivos e padronizados (letras min√∫sculas, separadas por underscores, unidade no sufixo se aplic√°vel: `_seconds`, `_bytes`, `_total` para contadores acumulativos). Por exemplo, prefira `app_memory_usage_bytes` a algo como `MemUsed` ou outras varia√ß√µes inconsistentes. Isso ajuda todo mundo a entender do que se trata sem ambiguidade.

* **Labels estrat√©gicos:** Anexe labels que fa√ßam sentido de consulta, mas evite rotular com informa√ß√µes que tenham alta cardinalidade ou unicidade. Um bom label √© algo como `region`, `datacenter`, `instance` (desde que este n√£o seja √∫nico por m√©trica ‚Äì use instance s√≥ onde faz sentido). Maus labels incluem: ID de requisi√ß√£o, nome de usu√°rio, URL completa (em vez de caminho gen√©rico), timestamp, IP din√¢mico de cliente. Esses valores criam um n√∫mero enorme de s√©ries distintas. Lembre-se: cada combina√ß√£o diferente de labels vira **uma s√©rie separada** no TSDB. Se voc√™ tiver 1000 usu√°rios e rotular m√©tricas por usu√°rio, virou 1000 s√©ries onde antes podia ser 1 ou algumas. Leve isso em conta.

* **Explos√£o de cardinalidade:** √â um dos problemas mais comuns. Por exemplo, adicionar um label `product_id` a uma m√©trica de pedidos, onde product\_id pode assumir dezenas de milhares de valores, multiplicar√° as s√©ries. Isso pode levar o Prometheus a consumir toda mem√≥ria e travar. Portanto, s√≥ use labels cujo conjunto de valores poss√≠vel seja **limitado e relativamente pequeno**. (Regra de bolso: algumas dezenas ou poucas centenas de valores diferentes por label no m√°ximo. Mais que isso, pense duas vezes se √© necess√°rio.) Caso precise monitorar algo muito cardinal (ex: m√©tricas por usu√°rio √∫nico), talvez o Prometheus n√£o seja a ferramenta adequada ou voc√™ precisa agreg√°-las antes de expor.

#### O Inimigo n¬∫ 1: Explos√£o de Cardinalidade

**A cardinalidade √© o maior desafio do Prometheus.** Cada combina√ß√£o √∫nica de labels cria uma s√©rie temporal separada no TSDB. Quando voc√™ adiciona labels com valores altamente vari√°veis (como IDs de usu√°rio, timestamps, URLs completas, ou IPs din√¢micos), voc√™ est√° multiplicando exponencialmente o n√∫mero de s√©ries armazenadas.

**Por que √© t√£o perigoso:**
- **Consumo de mem√≥ria:** Cada s√©rie ativa consome ~3kB de RAM. Milhares de s√©ries = gigabytes de mem√≥ria
- **Performance de consultas:** Mais s√©ries = consultas mais lentas e maior uso de CPU
- **Instabilidade:** Cardinalidade excessiva pode fazer o Prometheus travar ou reiniciar constantemente
- **Custos de armazenamento:** Mais s√©ries = mais dados para armazenar e processar

**Exemplos de labels perigosos:**
- `user_id` (pode ter milh√µes de valores √∫nicos)
- `request_id` (√∫nico por requisi√ß√£o)
- `timestamp` (muda a cada scrape)
- `ip_address` (muito vari√°vel)
- `full_url` (em vez de usar `endpoint` ou `path`)

**Solu√ß√µes pr√°ticas:**
- **Agrega√ß√£o pr√©via:** Agregue m√©tricas antes de exp√¥-las ao Prometheus
- **Labels limitados:** Use apenas labels com valores limitados e previs√≠veis
- **M√©tricas de resumo:** Em vez de m√©tricas por item individual, use m√©tricas de contagem/total
- **Filtros inteligentes:** Use relabeling para remover labels problem√°ticos
- **Monitoramento ativo:** Monitore `prometheus_tsdb_head_series` para detectar crescimento anormal

**Regra de ouro:** Se voc√™ n√£o consegue prever quantos valores diferentes um label pode ter, provavelmente n√£o deveria us√°-lo no Prometheus.

* **M√©tricas altas vs baixas cardinalidades:** Prefira m√©tricas mais agregadas. Por exemplo, em vez de registrar uma m√©trica separada para cada item em fila (que n√£o faz sentido), registre o tamanho da fila como um gauge. Em vez de m√©tricas por sess√£o de usu√°rio, exponha total global ou por categoria de usu√°rio. Enfim, modele os dados de forma a minimizar detalhes desnecess√°rios.

### Consultas (PromQL) Eficientes

* **Cuidado com fun√ß√µes custosas:** Algumas fun√ß√µes PromQL podem ser muito √∫teis, por√©m custosas. `topk()` e `bottomk()`, por exemplo, obrigam o engine a ordenar muitas s√©ries para achar o top N ‚Äì pode ser caro se aplicado numa m√©trica com milhares de s√©ries. Use-as com modera√ß√£o (talvez em queries de background para dashboard, mas evite em alertas cr√≠ticos se poss√≠vel). Similar para agrega√ß√µes sem restri√ß√£o: `sum by (label)` onde label tem muitos valores, o Prometheus ter√° que materializar todas combina√ß√µes.

* **Use intervalos de tempo adequados:** Querys do tipo *\[5m]*, *\[1h]* etc. definem quanto tempo de dados v√£o considerar. Evite pedir mais do que precisa. Por exemplo, se um alerta precisa saber a taxa nos √∫ltimos 5 minutos, n√£o use 1h. Intervalos maiores = mais dados lidos e processados. Num gr√°fico, tamb√©m n√£o exagere no zoom out se n√£o for necess√°rio ‚Äì muitos dados tornam a renderiza√ß√£o e transmiss√£o pesadas.

* **Prefira `rate()` ou `increase()` para contadores ao inv√©s de `irate()` para alertas cont√≠nuos:** A fun√ß√£o `irate()` calcula instantaneamente a derivada entre os dois √∫ltimos pontos ‚Äì isso √© √∫til √†s vezes, mas tende a ser muito "barulhento" (varia√ß√£o instante a instante). Em dashboards e alertas gerais, `rate()` numa janela de pelo menos 1m ou 5m √© mais est√°vel e representativo da taxa m√©dia. Use `irate` somente quando quer realmente capturar spikes moment√¢neos e tem alta frequ√™ncia de scrape.

* **Agregue no scraping quando poss√≠vel:** Se voc√™ j√° sabe que nunca vai olhar cada inst√¢ncia individual de certa m√©trica, poderia agreg√°-la antes mesmo de enviar. Exemplo: se voc√™ tem 10 threads fazendo trabalho id√™ntico e s√≥ quer saber o total combinado, exponha uma √∫nica m√©trica total e n√£o 10 separadas. Claro que isso depende do caso de uso ‚Äì muitas vezes queremos o detalhe ‚Äì mas √© algo a pensar.

* **Limite consultas no UI:** O Prometheus permite rodar qualquer PromQL ad-hoc no UI ou via API. Em ambientes compartilhados, controle o acesso ou conscientize os usu√°rios para n√£o rodarem consultas insanas (tipo um sum sem nenhum label em milh√µes de s√©ries por 365d) que possam afetar a performance. Voc√™ pode habilitar autentica√ß√£o/TLS e at√© colocar um proxy com quotas se for necess√°rio proteger a API de uso indevido.

### Arquitetura e Escalabilidade

* **Sharding (divis√£o de carga):** Se chegar ao ponto de um √∫nico Prometheus n√£o dar conta (seja por limite de CPU/RAM ou por quest√µes organizacionais), considere dividir os alvos entre m√∫ltiplas inst√¢ncias. Por exemplo, rodar um Prometheus por cluster Kubernetes, ou por ambiente (dev/prod), ou por regi√£o geogr√°fica. Cada um monitora s√≥ seu √¢mbito. Voc√™ pode replicar as regras de alertas em todos (assim cada local alerta independentemente). Para m√©tricas globais, use federa√ß√£o ou uma camada agregadora (como Thanos) para unificar se necess√°rio.

* **Alta disponibilidade:** O Prometheus em si n√£o √© HA ‚Äì ele √© stand-alone. Se cair, fica um buraco de coleta enquanto estiver fora. Uma pr√°tica comum em produ√ß√£o √© rodar **dois Prometheus em paralelo coletando os mesmos alvos** (nas mesmas configura√ß√µes) ‚Äì assim, se um falhar, o outro continua e nenhuma m√©trica se perde. O Alertmanager pode receber alertas duplicados de ambos, mas ele deduplica automaticamente (precisa configurar ambos Prometheus com o mesmo external\_label cluster). Essa abordagem gasta mais recursos (coleta em dobro), mas √© simples e efetiva para HA de alertas.

* **Longo prazo e agrega√ß√£o global:** Conforme citado, se precisar *escalar horizontalmente* de verdade ou guardar m√©tricas por longos per√≠odos, vale integrar solu√ß√µes como **Thanos, Cortex ou Grafana Mimir**. Essas ferramentas armazenam dados em base de dados distribu√≠da (por exemplo, S3 ou BigTable no caso do Thanos/Cortex) e permitem rodar consultas PromQL que abrangem m√∫ltiplos Prometheus "como se fosse um s√≥". 

> O Thanos, por exemplo, atua como um *sidecar* pegando os dados de cada Prometheus e enviando para o objeto storage, depois uma camada de *querier* unifica as consultas. O Grafana Mimir segue arquitetura semelhante, nascida da experi√™ncia do Cortex, permitindo **escala praticamente ilimitada (bilh√µes de s√©ries) e alta disponibilidade**, com compatibilidade total com PromQL e remote write. Claro, adicionam complexidade ‚Äì mas s√£o solu√ß√µes maduras mantidas pela CNCF/Grafana Labs.

* **Federa√ß√£o bem aplicada:** Caso use federa√ß√£o, siga a orienta√ß√£o de federar apenas m√©tricas j√° agregadas e necess√°rias globalmente. Por exemplo, federar s√≥ m√©tricas come√ßando com `job:` (indicando que s√£o resultados de recording rules j√° agregadas). N√£o federar todas as m√©tricas crus. E realize alertas localmente, deixando o global s√≥ para visualiza√ß√£o.

### Seguran√ßa

* **N√£o exponha sem prote√ß√£o em redes inseguras:** O Prometheus, por padr√£o, n√£o tem autentica√ß√£o nem TLS habilitados. Se voc√™ for disponibilizar a interface ou API em rede p√∫blica ou multi-tenant, coloque-o atr√°s de um proxy reverso que implemente TLS e autentica√ß√£o (b√°sica, OAuth, o que for). Alternativamente, rode em rede interna/VPN somente. H√° flags experimentais para TLS direto e auth no Prometheus, mas a abordagem recomendada ainda √© usar um proxy (por exemplo, Nginx, Traefik, etc).

* **Controle acesso √† API:** Considere habilitar autoriza√ß√£o se for um ambiente com v√°rios usu√°rios ou multi-time. Infelizmente, o Prometheus n√£o suporta m√∫ltiplos n√≠veis de usu√°rio nativamente. A solu√ß√£o costuma ser segregar inst√¢ncias ou novamente um proxy que filtre rotas. Por exemplo, impedir acesso direto ao `/api/v1/admin` (que possui comandos de dele√ß√£o de dados).

* **Atualiza√ß√µes e patches:** Mantenha o Prometheus atualizado ‚Äì a cada vers√£o h√° otimiza√ß√µes e corre√ß√µes, inclusive de seguran√ßa. E.g., compress√£o de WAL veio ativada por padr√£o na 2.20, reduzindo disco pela metade. Vers√µes mais novas introduziram *native histograms* (experimental) e melhorias de desempenho. Ent√£o acompanhe o changelog oficial e planeje upgrade regularmente (Prometheus √© bem compat√≠vel retroativamente em dados e configs, upgrades diretos costumam ser tranquilos).

* **Isolamento de rede para exporters:** Exporters muitas vezes exp√µem m√©tricas sens√≠veis (por exemplo, o Node Exporter exp√µe informa√ß√µes de hardware, usu√°rios logados etc.). √â boa pr√°tica deixar esses endpoints acess√≠veis s√≥ pelo Prometheus, n√£o abertos ao mundo. Use firewalls/regras de seguran√ßa nos hosts ou config de container network para limitar.

* **Naming anti-collision:** Se voc√™ usa r√≥tulos *externos* (external\_labels) para identificar inst√¢ncias em um contexto federado ou HA, garanta que cada Prometheus tenha um label √∫nico (e.g., `cluster="eu-west-1"`). Isso evita confus√£o de m√©tricas vindas de origens diferentes no caso de jun√ß√£o (Thanos, federa√ß√£o) e ajuda a filtrar.

### Backup, Recovery e Upgrade

Em ambientes de produ√ß√£o, √© fundamental ter estrat√©gias robustas para backup, recupera√ß√£o de falhas e upgrades do Prometheus. Esses aspectos s√£o frequentemente negligenciados, mas s√£o cr√≠ticos para manter a continuidade do monitoramento.

#### Backup de Dados

O Prometheus armazena dados no diret√≥rio `data/` que cont√©m os blocos de s√©ries temporais. Para fazer backup consistente:

**Backup a quente (recomendado):**
```bash
# Parar o Prometheus para garantir consist√™ncia
sudo systemctl stop prometheus

# Fazer backup do diret√≥rio data
tar -czf prometheus-backup-$(date +%Y%m%d).tar.gz /opt/prometheus/data/

# Reiniciar o Prometheus
sudo systemctl start prometheus
```

**Backup a frio (alternativa):**
```bash
# Usar promtool para verificar integridade antes do backup
promtool tsdb check /opt/prometheus/data/

# Fazer backup apenas dos blocos fechados (mais seguro)
find /opt/prometheus/data/ -name "*.json" -exec tar -czf prometheus-blocks-$(date +%Y%m%d).tar.gz {} \;
```

**Backup de configura√ß√£o:**
```bash
# Backup dos arquivos de configura√ß√£o
cp /etc/prometheus/prometheus.yml /backup/prometheus.yml.$(date +%Y%m%d)
cp /etc/prometheus/alert.rules.yml /backup/alert.rules.yml.$(date +%Y%m%d)
```

#### Recupera√ß√£o de Falhas

**Restaura√ß√£o de dados:**
```bash
# Parar o Prometheus
sudo systemctl stop prometheus

# Restaurar backup
tar -xzf prometheus-backup-20231201.tar.gz -C /

# Verificar integridade dos dados
promtool tsdb check /opt/prometheus/data/

# Reiniciar
sudo systemctl start prometheus
```

**Recupera√ß√£o de WAL corrompido:**
```bash
# Se o WAL estiver corrompido, pode ser necess√°rio recriar
rm -rf /opt/prometheus/data/wal/
rm -rf /opt/prometheus/data/chunks_head/

# Reiniciar - o Prometheus recriar√° o WAL
sudo systemctl start prometheus
```

#### Estrat√©gias de Upgrade

**Upgrade direto (mais comum):**
```bash
# Fazer backup antes do upgrade
sudo systemctl stop prometheus
tar -czf prometheus-backup-pre-upgrade.tar.gz /opt/prometheus/data/

# Baixar nova vers√£o
wget https://github.com/prometheus/prometheus/releases/download/v2.45.0/prometheus-2.45.0.linux-amd64.tar.gz
tar -xzf prometheus-2.45.0.linux-amd64.tar.gz

# Substituir bin√°rio
cp prometheus-2.45.0.linux-amd64/prometheus /opt/prometheus/
cp prometheus-2.45.0.linux-amd64/promtool /opt/prometheus/

# Verificar configura√ß√£o
/opt/prometheus/promtool check config /etc/prometheus/prometheus.yml

# Reiniciar
sudo systemctl start prometheus
```

**Upgrade com rollback:**
```bash
# Manter vers√£o anterior
cp /opt/prometheus/prometheus /opt/prometheus/prometheus.backup

# Fazer upgrade
# ... (mesmo processo acima)

# Se houver problemas, rollback
sudo systemctl stop prometheus
cp /opt/prometheus/prometheus.backup /opt/prometheus/prometheus
sudo systemctl start prometheus
```

#### Considera√ß√µes Importantes

**Compatibilidade de dados:**
* O Prometheus mant√©m compatibilidade retroativa de dados entre vers√µes menores
* Upgrades major (ex: 2.x para 3.x) podem requerer migra√ß√£o de dados
* Sempre verifique o changelog oficial antes de upgrades

**Tempo de recupera√ß√£o:**
* O Prometheus pode demorar para processar o WAL ap√≥s reinicializa√ß√£o
* Em ambientes com muitas s√©ries, a recupera√ß√£o pode levar minutos
* Monitore `prometheus_tsdb_wal_replay_duration_seconds` durante recupera√ß√£o

**Backup automatizado:**
```bash
#!/bin/bash
# Script de backup automatizado
DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_DIR="/backup/prometheus"

# Criar backup
sudo systemctl stop prometheus
tar -czf $BACKUP_DIR/prometheus-$DATE.tar.gz /opt/prometheus/data/
sudo systemctl start prometheus

# Manter apenas √∫ltimos 7 backups
find $BACKUP_DIR -name "prometheus-*.tar.gz" -mtime +7 -delete
```

**Monitoramento de integridade:**
```yaml
# Alertas para problemas de backup/recupera√ß√£o
groups:
- name: prometheus_backup
  rules:
    - alert: PrometheusBackupFailed
      expr: time() - prometheus_build_info > 86400  # Mais de 1 dia sem restart
      for: 1h
      labels:
        severity: warning
      annotations:
        summary: "Prometheus n√£o foi reiniciado recentemente (poss√≠vel problema de backup)"
```

> **Importante**: Sempre teste backups e procedimentos de recupera√ß√£o em ambiente de desenvolvimento antes de aplicar em produ√ß√£o. A integridade dos dados de monitoramento √© t√£o cr√≠tica quanto os dados da aplica√ß√£o.

Seguindo essas pr√°ticas, voc√™ dever√° manter seu ambiente Prometheus funcionando de forma mais suave, evitando as armadilhas comuns de desempenho e garantindo que as m√©tricas coletadas realmente agreguem valor (e alertas disparem quando devem, sem falso positivos ou negativos).

## Opera√ß√£o e Manuten√ß√£o

### Promtool

O **promtool** √© uma ferramenta de linha de comando que acompanha o Prometheus, fornecendo utilit√°rios para verificar configura√ß√µes e depurar dados. Algumas utiliza√ß√µes comuns do promtool:

* **Checar sintaxe de configura√ß√£o:** Antes de subir uma altera√ß√£o no `prometheus.yml`, rode `promtool check config prometheus.yml`. Ele apontar√° erros de sintaxe ou campos desconhecidos, ajudando a evitar falhas no start do servidor.
* **Validar regras de alerta ou grava√ß√£o:** Se voc√™ definiu arquivos externos de regras (YAML de alertas ou recording rules), use `promtool check rules minhas_regras.yml`. Ele analisar√° as express√µes PromQL e a formata√ß√£o.
* **Testar express√£o de alerta:** O promtool permite avaliar manualmente express√µes em um dado instant√¢neo ou s√©rie de tempo para ver se disparariam alerta. √ötil em CI ou para garantir que a l√≥gica est√° correta.
* **Checar integridade do TSDB:** Com o comando `promtool tsdb check /path/para/dados` √© poss√≠vel inspecionar o banco local de s√©ries temporais em busca de inconsist√™ncias ou corrup√ß√£o.
* **Converter formatos de dados de m√©trica:** H√° como transformar arquivos de m√©tricas entre formatos (por exemplo, de texto para JSON e vice-versa) usando `promtool convert metrics --from=txt --to=json arquivo.txt`.

Essas s√£o apenas algumas fun√ß√µes. Em suma, o promtool √© seu amigo para garantir que o ambiente Prometheus est√° consistente e saud√°vel ‚Äì use-o sempre que fizer mudan√ßas significativas na configura√ß√£o.

## Conclus√£o

Neste artigo, exploramos em detalhes o Prometheus ‚Äì desde conceitos fundamentais at√© seu funcionamento interno e implica√ß√µes pr√°ticas de opera√ß√£o. Vimos como ele implementa um banco de dados de s√©ries temporais altamente eficiente, mantendo dados recentes em mem√≥ria para rapidez e usando compress√£o e segmenta√ß√£o em blocos para hist√≥rico em disco.

Tamb√©m analisamos aspectos como modelo de coleta pull, linguagem de consulta poderosa, uso intensivo de recursos proporcionais ao volume de m√©tricas, e formas de contornar limita√ß√µes (sejam arquiteturais ou de escala) com boas pr√°ticas e ferramentas auxiliares.

Esses pontos mostram como o Prometheus alia efici√™ncia t√©cnica a flexibilidade operacional, permitindo que equipes monitorem ambientes complexos e em constante evolu√ß√£o, ao mesmo tempo em que enfrentam desafios de escala e desempenho com solu√ß√µes pr√°ticas e acess√≠veis.

O Prometheus se destaca no ecossistema de monitoramento por sua simplicidade de implanta√ß√£o e por ter sido projetado desde o in√≠cio para ambientes de microsservi√ßos e infraestrutura din√¢mica. Seu modelo multidimensional de m√©tricas com labels e o PromQL possibilitam an√°lises ricas e alertas robustos com relativamente pouco esfor√ßo de configura√ß√£o.

√â not√°vel como em poucos anos ele se tornou um dos pilares da observabilidade moderna, ao lado de ferramentas complementares para logs (ELK stack) e *tracing* (Jaeger, etc.).

Por outro lado, entendemos que o Prometheus n√£o resolve tudo sozinho: reten√ß√£o de longo prazo, alta disponibilidade nativa e escalabilidade horizontal s√£o pontos fora do escopo do core do Prometheus.

Em vez de tentar ser distribu√≠do, o projeto optou por interfaces (remote write/read) e pela filosofia de componibilidade ‚Äì cabendo a outras pe√ßas (como Thanos ou Mimir) suprir essas demandas quando necess√°rias.

Essa decis√£o de design mant√©m o Prometheus "enxuto" e confi√°vel, mas significa que para crescer al√©m de certo limite, precisamos arquitetar bem a solu√ß√£o de monitoramento abrangendo outros componentes.

Recapitulando alguns aprendizados chave:

* Organize bem suas m√©tricas e labels para evitar sobrecarga de cardinalidade.
* Monitore o pr√≥prio Prometheus e ajuste a capacidade conforme crescimento.
* Use Alertmanager e outras integra√ß√µes para ter um uso completo (coleta, armazenamento, alerta, visualiza√ß√£o).
* Em caso de grandes escalas, parta para sharding ou ferramentas de escala distribu√≠da ‚Äì n√£o force um Prometheus √∫nico a fazer trabalho demais.
* Leve em conta seguran√ßa e isolamento, pois monitoramento tamb√©m lida com informa√ß√µes sens√≠veis do ambiente.

Esperamos que este guia tenha fornecido insights valiosos, tanto para iniciantes entenderem os conceitos do Prometheus quanto para usu√°rios experientes refinarem sua utiliza√ß√£o. Compreender o "under the hood" do Prometheus ajuda a antecipar comportamentos, otimizar configura√ß√µes e evitar armadilhas comuns na opera√ß√£o di√°ria.

O Prometheus continua em r√°pida evolu√ß√£o (com melhorias na TSDB, novos recursos como Exemplos Exemplares e Native Histograms em teste, etc.), e o ecossistema ao seu redor tamb√©m. Fique atento a atualiza√ß√µes e boas pr√°ticas emergentes ‚Äì a comunidade CNCF e blogs como o *Robust Perception* regularmente publicam conte√∫dos de alto n√≠vel a respeito.

No mais, boas m√©tricas e bons alertas!

---

## Refer√™ncias

* **Documenta√ß√£o Oficial do Prometheus** ‚Äì especialmente a [Overview](https://prometheus.io/docs/introduction/overview/) , [Metric Types](https://prometheus.io/docs/concepts/metric_types/) , [Best Practices](https://prometheus.io/docs/practices/naming/) e se√ß√£o de [Storage](https://prometheus.io/docs/prometheus/latest/storage/) .
* **Blog Robust Perception (Brian Brazil)** ‚Äì v√°rias postagens aprofundadas, por exemplo: ["Federation, what is it good for?"](https://www.robustperception.io/federation-what-is-it-good-for/) , ["How much RAM does Prometheus 2.x need..."](https://www.robustperception.io/how-much-ram-does-prometheus-2-x-need-for-cardinality-and-ingestion/) , ["Using JSON file service discovery"](https://www.robustperception.io/using-json-file-service-discovery-with-prometheus) .
* **Ganesh Vernekar ‚Äì S√©rie de artigos "Prometheus TSDB"** ‚Äì *Parts 1-7* no blog do Ganesh (engenheiro Grafana Labs) detalhando a fundo a arquitetura do TSDB. Em especial, [Parte 4: Blocos persistentes e √çndice](https://ganeshvernekar.com/blog/prometheus-tsdb-persistent-block-and-its-index/) .
* **Livro "Prometheus Up & Running" (O'Reilly, 2019)** ‚Äì de Brian Brazil, √≥tima introdu√ß√£o abrangendo do b√°sico a casos avan√ßados.
* **Livro "The Prometheus Book" de James Turnbull** ‚Äì guia pr√°tico cobrindo instala√ß√£o, instrumenta√ß√£o e alertas (dispon√≠vel online).
* **Hands-On Infrastructure Monitoring with Prometheus** (Packt) ‚Äì livro focado em exemplos pr√°ticos de uso do Prometheus em cen√°rios reais.
* **Monitoring Microservices and Containerized Applications** (Apress) ‚Äì aborda Prometheus em contexto de microsservi√ßos/Kubernetes.
* **Comparativos Prometheus vs. outras ferramentas:** Artigos como *"Prometheus vs. ELK"*, *"Prometheus vs. Grafana Mimir (Cortex)"*, e posts do blog da BetterStack sobre melhores pr√°ticas.
* **Grafana Mimir** ‚Äì [P√°gina oficial](https://grafana.com/oss/mimir/)  e an√∫ncio do lan√ßamento em 2022, mostrando como escalar Prometheus para 1 bilh√£o de s√©ries.
* **Datadog e New Relic** ‚Äì documenta√ß√µes e sites oficiais para entender ofertas de monitoramento propriet√°rias integradas (APM, Logs, etc.), √∫til para ver diferen√ßas de escopo.
* **Nagios/Core e Zabbix** ‚Äì documenta√ß√£o e comunidade, para contexto hist√≥rico de monitoramento (foco em disponibilidade, sem TSDB nativo).
* **ELK Stack** ‚Äì docs Elastic e blogs de terceiros comparando com Prometheus (focando que ELK √© logs e Prometheus m√©tricas).
* **CNCF Observability Landscape** ‚Äì projetos e ferramentas relacionadas, para quem quiser explorar al√©m (OpenTelemetry, Fluentd, etc.).