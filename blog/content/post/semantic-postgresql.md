+++
title = "Busca Sem√¢ntica com Ollama e PostgreSQL"
description = "Implementando busca sem√¢ntica com PostgreSQL e Ollama"
date = 2025-03-25T12:00:00-00:00
tags = ["RAG", "PostgreSQL", "pgvector", "pgai", "Ollama", "Semantic Search"]
draft = false
weight = 2
author = "Vitor Lobo Ramos"
+++

Ol√°, pessoal! üëã

No [artigo anterior](/post/rag/), exploramos como construir um sistema RAG (Retrieval-Augmented Generation) usando [Clojure](https://clojure.org/) e [Ollama](https://ollama.com/) com uma implementa√ß√£o simples de [TF-IDF](/post/tf-idf/). Embora essa abordagem seja excelente para aprender os fundamentos, quando pensamos em solu√ß√µes de produ√ß√£o, precisamos de algo mais robusto e escal√°vel.

Neste artigo, vamos descobrir como construir um sistema de busca sem√¢ntica poderoso usando [Ollama](https://ollama.com/), [PostgreSQL](https://www.postgresql.org/) e suas extens√µes para manipula√ß√£o de vetores. Esta solu√ß√£o √© perfeitamente adequada para aplica√ß√µes de produ√ß√£o e pode servir como base para sistemas RAG, agentes de IA, assistentes em geral. Diferentemente do artigo anterior, vamos usar o [Ollama](https://ollama.com/) via Docker assim como o [PostgreSQL](https://www.postgresql.org/) e as extens√µes [pgvector](https://github.com/pgvector/pgvector) e [pgai](https://github.com/timescale/pgai).

A combina√ß√£o do [PostgreSQL](https://www.postgresql.org/) com extens√µes como [pgvector](https://github.com/pgvector/pgvector) e [pgai](https://github.com/timescale/pgai), junto com o [Ollama](https://ollama.com/) (que permite executar modelos de linguagem localmente), cria uma solu√ß√£o completa e de alto desempenho para [processamento sem√¢ntico de dados](https://en.wikipedia.org/wiki/Semantic_search).

## Entendendo a Arquitetura

A busca sem√¢ntica vai al√©m da simples correspond√™ncia de palavras-chave, capturando o significado e o contexto da sua consulta. Em vez de depender apenas de correspond√™ncias exatas, ela utiliza [embeddings vetoriais](https://en.wikipedia.org/wiki/Embedding_(machine_learning)) para representar o conte√∫do sem√¢ntico do texto (ou qualquer dado n√£o estruturado). Essa abordagem permite que seu sistema recupere resultados contextualmente relevantes, mesmo quando as palavras-chave exatas n√£o est√£o presentes.

Por exemplo, se voc√™ pesquisar por "melhores lugares para comer", um [sistema de busca sem√¢ntica](https://en.wikipedia.org/wiki/Semantic_search) pode recuperar documentos sobre "restaurantes bem avaliados nas proximidades" ou "experi√™ncias gastron√¥micas altamente recomendadas", efetivamente capturando sua inten√ß√£o em vez da formula√ß√£o exata. A arquitetura para busca sem√¢ntica com PostgreSQL envolve quatro componentes principais:

```mermaid
flowchart LR
    A[Ollama] --> B[pgai]
    B --> C[pgvector]
    C --> D[PostgreSQL]
    
    style A fill:#f9f,stroke:#333,stroke-width:2px
    style D fill:#9ff,stroke:#333,stroke-width:2px
```

- [**Ollama**](https://ollama.com/): Ferramenta open-source que permite executar e gerenciar modelos de linguagem de grande escala (LLMs) e modelos de vis√£o (VLMs) localmente no seu computador ou em um servidor cloud, proporcionando maior privacidade e controle sobre os dados.
- [**pgai**](https://github.com/timescale/pgai): Extens√£o do PostgreSQL que simplifica o armazenamento e recupera√ß√£o de dados para RAG e outras aplica√ß√µes de IA, automatizando a cria√ß√£o e gest√£o de embeddings, facilitando a busca sem√¢ntica e permitindo a execu√ß√£o de fun√ß√µes de LLM diretamente dentro de consultas SQL.
- [**pgvector**](https://github.com/pgvector/pgvector): Extens√£o do PostgreSQL que adiciona suporte para armazenar, indexar e consultar embeddings vetoriais de alta dimensionalidade.
- [**PostgreSQL**](https://www.postgresql.org/): O sistema de banco de dados relacional que serve como funda√ß√£o robusta e escal√°vel para todo o sistema.

---

## Pr√©-requisitos

Antes de come√ßar, precisamos garantir que voc√™ tenha:

1. **Docker e Docker Compose**: Para configurar o ambiente facilmente
2. **PostgreSQL com pgvector e pgai**: Para armazenar e consultar embeddings

> **NOTA**: No artigo anterior sobre [RAG em Clojure](/post/rag/), usamos o [Ollama](https://ollama.com/) com [DeepSeek R1](https://ollama.com/models/deepseek-r1) baixando o projeto ollama diretamente na m√°quina. Nesta abordagem, vamos usar o Ollama via Docker. Portanto, recomendo que voc√™ feche o Ollama para usar-mos ele inteiramente via Docker aqui nesta abordagem (√© necess√°rio fechar para n√£o conflitar com o endpoint do Ollama que vamos usar no Docker Compose).

Vamos configurar tudo isso rapidamente usando Docker Compose:

```bash
name: pgai
services:
  db:
    image: timescale/timescaledb-ha:pg17
    environment:
      POSTGRES_PASSWORD: postgres
      # Definir vari√°veis de ambiente para o host do Ollama
      OLLAMA_HOST: http://ollama:11434
    ports:
      - "5432:5432"
    volumes:
      - data:/home/postgres/pgdata/data
    # N√£o use a extens√£o ai at√© garantir que est√° instalada corretamente
    command: "-c search_path=public"
    depends_on:
      - ollama
    # Adicionar links expl√≠citos para o servi√ßo Ollama
    links:
      - ollama

  vectorizer-worker:
    image: timescale/pgai-vectorizer-worker:latest
    environment:
      PGAI_VECTORIZER_WORKER_DB_URL: postgres://postgres:postgres@db:5432/postgres
      OLLAMA_HOST: http://ollama:11434
    command: [ "--poll-interval", "5s", "--log-level", "DEBUG" ]
    depends_on:
      - db
      - ollama
    links:
      - ollama

  ollama:
    image: ollama/ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    # Comando direto para iniciar o Ollama
    command: serve

volumes:
  data:
  ollama_data: 
```

O arquivo `docker-compose.yml` acima configura uma infraestrutura para busca sem√¢ntica com tr√™s servi√ßos interconectados. O servi√ßo `db` utiliza o [TimescaleDB](https://www.timescale.com/) (que nada mais √© que uma vers√£o do [PostgreSQL](https://www.postgresql.org/) especializada para otimiza√ß√£o de desempenho para dados de s√©ries temporais) com a vers√£o 17, configurando credenciais, mapeamento de portas e um volume persistente para armazenar os dados. Este servi√ßo √© configurado para se comunicar com o Ollama atrav√©s de vari√°veis de ambiente e links expl√≠citos, garantindo que a comunica√ß√£o entre os cont√™ineres funcione corretamente.

```mermaid
flowchart TD
    subgraph db ["TimescaleDB (pg17)"]
        db_info["Ports: 5432:5432<br>Volumes: data:/home/postgres/pgdata/data<br>Environment:<br>POSTGRES_PASSWORD=postgres<br>OLLAMA_HOST=http://ollama:11434"]
    end

    subgraph vectorizer_worker ["pgai-vectorizer-worker"]
        vw_info["Environment:<br>PGAI_VECTORIZER_WORKER_DB_URL=postgres://postgres:postgres@db:5432/postgres<br>OLLAMA_HOST=http://ollama:11434<br>Command: --poll-interval 5s --log-level DEBUG"]
    end

    subgraph ollama ["Ollama"]
        o_info["Ports: 11434:11434<br>Volumes: ollama_data:/root/.ollama<br>Command: serve"]
    end

    data["Data Volume"]
    ollama_data["Ollama Data Volume"]

    db --- data
    ollama --- ollama_data
    vectorizer_worker --- db
    vectorizer_worker --- ollama
    db --- ollama

    style db fill:#f9f,stroke:#333,stroke-width:2px
    style vectorizer_worker fill:#ccf,stroke:#333,stroke-width:2px
    style ollama fill:#ffc,stroke:#333,stroke-width:2px
    style data fill:#eee,stroke:#333,stroke-width:2px
    style ollama_data fill:#eee,stroke:#333,stroke-width:2px
```

O diagrama acima ilustra a arquitetura do sistema de busca sem√¢ntica com PostgreSQL. No centro, temos tr√™s componentes principais: o TimescaleDB (uma vers√£o especializada do PostgreSQL), o pgai-vectorizer-worker (respons√°vel por processar e vetorizar os textos) e o Ollama (que fornece os modelos de IA). As conex√µes entre os servi√ßos mostram como eles se comunicam: o vectorizer-worker se conecta tanto ao banco de dados quanto ao Ollama para realizar seu trabalho de transforma√ß√£o de textos em vetores. 

Os volumes persistentes (representados em cinza) garantem que tanto os dados do PostgreSQL quanto os modelos do Ollama sejam preservados entre reinicializa√ß√µes. Esta arquitetura modular permite escalar cada componente independentemente conforme necess√°rio, enquanto mant√©m um fluxo de dados eficiente para opera√ß√µes de busca sem√¢ntica.


O servi√ßo `vectorizer-worker` √© um componente especializado do [pgai](https://github.com/timescale/pgai) que monitora o banco de dados a cada 5 segundos, processando automaticamente textos para transform√°-los em embeddings vetoriais. Ele se conecta ao banco [PostgreSQL](https://www.postgresql.org/) e ao servi√ßo [Ollama](https://ollama.com/) para realizar a vetoriza√ß√£o dos textos, funcionando como uma ponte entre o armazenamento de dados e o modelo de IA, com logs detalhados para facilitar a depura√ß√£o durante o desenvolvimento.

Por fim, o servi√ßo `ollama` fornece a infraestrutura para executar modelos de IA localmente, expondo uma API REST na porta 11434 e armazenando os modelos baixados em um volume persistente. Este design de tr√™s camadas (banco de dados, processador de vetores e motor de IA) cria um sistema completo para busca sem√¢ntica que pode ser iniciado com um simples `docker compose up -d`, seguido pelo download do modelo de [embeddings](https://en.wikipedia.org/wiki/Embedding_(machine_learning)) que transformar√° os textos em vetores.

```bash	
docker compose exec ollama ollama pull nomic-embed-text
```

Este setup configura um banco de dados PostgreSQL com as extens√µes [pgai](https://github.com/timescale/pgai), [pgvector](https://github.com/pgvector/pgvector) e [pgvectorscale](https://github.com/timescale/pgvectorscale). Tamb√©m configura o Ollama, que voc√™ pode usar para implantar LLMs e modelos de embedding.

---

## Passos para Construir a Busca Sem√¢ntica

Os passos para implementar a busca sem√¢ntica no PostgreSQL s√£o relativamente simples. Primeiro, vamos habilitar as extens√µes necess√°rias, criar uma tabela para armazenar nossos documentos, configurar o [vectorizer](https://github.com/timescale/pgai/tree/main/vectorizer) para gerar [embeddings](https://en.wikipedia.org/wiki/Embedding_(machine_learning)) automaticamente e, finalmente, realizar consultas sem√¢nticas.

### 1. Habilitando as Extens√µes

Primeiro, precisamos habilitar as extens√µes necess√°rias no PostgreSQL:

```sql
CREATE EXTENSION IF NOT EXISTS vector CASCADE; 
CREATE EXTENSION IF NOT EXISTS ai CASCADE;
```

### 2. Criando a Tabela de Documentos

Agora, vamos criar uma tabela para armazenar os documentos que queremos pesquisar:

```sql
CREATE TABLE IF NOT EXISTS documentos (
   id SERIAL PRIMARY KEY,
   titulo TEXT NOT NULL,
   conteudo TEXT,
   categoria TEXT,
   data_criacao TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

Neste exemplo, criamos uma tabela chamada `documentos` com quatro colunas: `id`, `titulo`, `conteudo` e `categoria`. √â importante notar que a coluna `id` √© a chave prim√°ria da tabela. Outro ponto importante √© que a coluna `data_criacao` √© uma coluna de metadados que √© gerada automaticamente pelo PostgreSQL.

### 3. Inserindo Documentos

Podemos inserir documentos manualmente ou usar a fun√ß√£o `ai.load_dataset` do [pgai](https://github.com/timescale/pgai) para carregar dados diretamente do [Hugging Face](https://huggingface.co/):

```sql
SELECT ai.load_dataset(
   name => 'Cohere/movies',
   table_name => 'documentos',
   if_table_exists => 'append',
   field_types => '{"title": "titulo", "overview": "conteudo", "genres": "categoria"}'::jsonb
);
```

Alternativamente, podemos inserir registros manualmente:

```sql
INSERT INTO documentos (titulo, conteudo, categoria) VALUES 
('Guia Clojure', 'Clojure √© uma linguagem funcional moderna...', 'Programa√ß√£o'),
('Tutorial RAG', 'Sistemas RAG combinam busca e gera√ß√£o...', 'IA'),
('PostgreSQL Avan√ßado', 'T√©cnicas de otimiza√ß√£o para PostgreSQL...', 'Banco de Dados');
```

> **NOTA**: O [Hugging Face](https://huggingface.co/) √© uma plataforma de dados e modelos de IA.

Agora vamos configurar o vectorizer para gerar embeddings automaticamente.

### 4. Configurando o Vectorizer

O [pgai](https://github.com/timescale/pgai) inclui uma ferramenta chamada [vectorizer](https://github.com/timescale/pgai/tree/main/vectorizer) que automatiza a cria√ß√£o e sincroniza√ß√£o de embeddings. Esta √© uma das funcionalidades mais poderosas desta solu√ß√£o, pois elimina a necessidade de ferramentas externas para criar [embeddings](https://en.wikipedia.org/wiki/Embedding_(machine_learning)). Vamos configur√°-la:

```sql
SELECT ai.create_vectorizer(
   'public.documentos'::regclass,
   destination => 'documentos_embeddings',
   embedding => ai.embedding_ollama('nomic-embed-text', 768),
   chunking => ai.chunking_recursive_character_text_splitter('conteudo')
);
```

Basicamente, o comando acima faz o seguinte:

1. Cria uma tabela `documentos_embeddings` para armazenar os vetores
2. Configura o modelo `nomic-embed-text` via Ollama para gerar embeddings
3. Define uma estrat√©gia de chunking para dividir textos longos
4. Cria automaticamente uma view `documentos_embeddings_vectorized` que junta os documentos com seus embeddings

O [vectorizer](https://github.com/timescale/pgai/tree/main/vectorizer) tamb√©m cuida da sincroniza√ß√£o autom√°tica dos embeddings quando documentos s√£o inseridos, atualizados ou removidos - sem necessidade de c√≥digo adicional! Isto simplifica enormemente a manuten√ß√£o do sistema.

### 5. Realizando Busca Sem√¢ntica

Agora estamos prontos para realizar buscas sem√¢nticas. Usaremos a fun√ß√£o `ai.ollama_embed` para gerar embeddings para nossa consulta e o operador de dist√¢ncia de cosseno (`<=>`) para encontrar documentos similares:

```sql
WITH query_embedding AS (
    -- Gerar embedding para a consulta
    SELECT ai.ollama_embed('nomic-embed-text', 'Como implementar RAG em sistemas modernos', 
                          host => 'http://ollama:11434') AS embedding
)
SELECT
    d.titulo,
    d.conteudo,
    d.categoria,
    t.embedding <=> (SELECT embedding FROM query_embedding) AS distancia
FROM documentos_embeddings t
LEFT JOIN documentos d ON t.id = d.id
ORDER BY distancia
LIMIT 5;
```

Este c√≥digo SQL realiza uma [busca sem√¢ntica](https://en.wikipedia.org/wiki/Semantic_search) em nossa base de documentos utilizando [embeddings](https://en.wikipedia.org/wiki/Embedding_(machine_learning)) gerados pelo modelo `nomic-embed-text` atrav√©s do [Ollama](https://ollama.com/). Primeiro, criamos uma CTE (Common Table Expression) chamada `query_embedding` que gera o embedding para nossa consulta "Como implementar RAG em sistemas modernos". Em seguida, selecionamos os documentos mais relevantes comparando este embedding de consulta com os embeddings armazenados na tabela `documentos_embeddings` usando o operador de dist√¢ncia de cosseno (`<=>`).

O resultado √© uma lista ordenada dos documentos mais semanticamente similares √† nossa consulta, independentemente de compartilharem as mesmas palavras exatas. Esta √© a ess√™ncia da busca sem√¢ntica - encontrar conte√∫do conceitualmente relacionado, n√£o apenas correspond√™ncias de palavras-chave. A coluna `distancia` nos mostra qu√£o pr√≥ximo cada documento est√° da nossa consulta, com valores menores indicando maior similaridade. Limitamos os resultados aos 5 documentos mais relevantes, mas este n√∫mero pode ser ajustado conforme necess√°rio. O PostgreSQL oferece tr√™s operadores para c√°lculo de similaridade:

- `<->`: [Dist√¢ncia L2 (Euclidiana)](https://en.wikipedia.org/wiki/Euclidean_distance)
- `<#>`: [Produto interno](https://en.wikipedia.org/wiki/Dot_product)
- `<=>`: [Dist√¢ncia de cosseno](https://en.wikipedia.org/wiki/Cosine_distance) (geralmente a melhor op√ß√£o)

E pronto! Com apenas esses poucos passos, temos um sistema de busca sem√¢ntica totalmente funcional, diretamente no PostgreSQL. **[Para quem acompanhou o artigo anterior sobre a implementa√ß√£o de RAG em Clojure](/post/rag/)**, vale a pena comparar as duas abordagens:

A diferen√ßa entre as duas abordagens √© bem clara quando olhamos lado a lado. [No artigo anterior sobre RAG em Clojure](/post/rag/), usamos uma t√©cnica mais simples [(TF-IDF)](/post/tf-idf/) que funciona bem para projetos pequenos e did√°ticos. √â como usar uma bicicleta para se locomover para dist√¢ncias curtas. O c√≥digo em Clojure mant√©m tudo em mem√≥ria, o que √© √≥timo para aprender os conceitos, mas come√ßa a dar problema quando a quantidade de documentos cresce.

J√° a abordagem com PostgreSQL + pgai √© como trocar a bicicleta por um carro esportivo! Estamos usando embeddings densos gerados por LLMs, que capturam muito melhor o significado sem√¢ntico dos textos. O PostgreSQL cuida de toda a parte chata de persist√™ncia e indexa√ß√£o, permitindo que voc√™ escale para milh√µes de documentos sem suar. Os √≠ndices especializados para vetores (como HNSW) fazem buscas em bilh√µes de embeddings parecerem instant√¢neas, algo que nossa implementa√ß√£o anterior jamais conseguiria.

O mais legal √© que a manuten√ß√£o fica muito mais simples. Com o [vectorizer do pgai](https://github.com/timescale/pgai/tree/main/vectorizer), voc√™ s√≥ precisa inserir documentos no banco normalmente, e ele cuida automaticamente de gerar e atualizar os embeddings. 


---

## Integra√ß√£o com Clojure

O objetivo deste artigo √© mostrar como √© f√°cil construir um sistema de busca sem√¢ntica usando PostgreSQL e pgai. No entanto, √© mostrar tamb√©m como podemos evoluir √† proposta anterior e construir um sistema de busca sem√¢ntica mais robusto e escal√°vel usando PostgreSQL e pgai e Clojure.

```clojure
;; src/docai/pg.clj
(ns docai.pg
  (:require [next.jdbc :as jdbc]
            [clojure.data.json :as json]))

(def db-spec
  {:dbtype "postgresql"
   :dbname "postgres"
   :host "localhost"
   :user "postgres"
   :password "password"})

(defn query-semantic-search
  "Realiza busca sem√¢ntica via PostgreSQL"
  [query limit]
  (let [conn (jdbc/get-connection db-spec)
        sql (str "WITH query_embedding AS ("
                 "  SELECT ai.ollama_embed('nomic-embed-text', ?, host => 'http://ollama:11434') AS embedding"
                 ")"
                 "SELECT"
                 "  d.titulo,"
                 "  d.conteudo,"
                 "  d.categoria,"
                 "  t.embedding <=> (SELECT embedding FROM query_embedding) AS distancia"
                 " FROM documentos_embeddings t"
                 " LEFT JOIN documentos d ON t.id = d.id"
                 " ORDER BY distancia"
                 " LIMIT ?")
        results (jdbc/execute! conn [sql query limit])]
    results))
```

> **NOTA**: O c√≥digo acima √© um exemplo de como integrar a busca sem√¢ntica no PostgreSQL com uma aplica√ß√£o Clojure. O c√≥digo completo est√° dispon√≠vel no [https://github.com/scovl/docai](https://github.com/scovl/docai).

## Configura√ß√£o de Cont√™ineres e Resolu√ß√£o de Problemas

Ao trabalhar com cont√™ineres Docker ou Podman, voc√™ pode encontrar alguns desafios espec√≠ficos relacionados √† comunica√ß√£o entre servi√ßos. Vamos explorar algumas dicas para garantir que sua configura√ß√£o funcione sem problemas:

### Nomea√ß√£o de Cont√™ineres e Comunica√ß√£o entre Servi√ßos

Quando os servi√ßos est√£o em cont√™ineres separados, a comunica√ß√£o entre eles pode ser complicada. Existem v√°rias maneiras de referenciar um cont√™iner a partir de outro:

```clojure
;; Exemplo de diferentes URLs para alcan√ßar o servi√ßo Ollama
(def alternative-hosts 
  ["http://pgai-ollama-1:11434"    ;; Nome do cont√™iner espec√≠fico (mais confi√°vel)
   "http://ollama:11434"           ;; Nome do servi√ßo (conforme definido no arquivo docker/podman-compose)
   "http://172.18.0.2:11434"       ;; IP do cont√™iner (pode mudar entre reinicializa√ß√µes)
   "http://host.docker.internal:11434" ;; Especial para acessar o host a partir do cont√™iner
   "http://localhost:11434"])      ;; Funciona apenas se mapeado para a porta do host
```

O m√©todo mais confi√°vel √© usar o nome exato do cont√™iner (algo como `pgai-ollama-1`), que pode ser descoberto com o comando `docker ps` ou `podman ps`.

### Solu√ß√£o de Problemas de Conex√£o

Se voc√™ estiver enfrentando problemas de conex√£o, uma abordagem robusta √© implementar um sistema de fallback que tente diferentes URLs:

```clojure
(defn call-ollama-api
  "Chama a API do Ollama com m√∫ltiplas tentativas de conex√£o"
  [prompt]
  (let [primary-url "http://ollama:11434/api/generate"
        options {:headers {"Content-Type" "application/json"}
                 :body (json/write-str {:model "deepseek-r1"
                                       :prompt prompt})}
        
        ;; Tentar primeiro com a URL prim√°ria
        primary-result (try-single-url primary-url options)]
    
    (if (:success primary-result)
      (:result primary-result)
      (do
        (println "‚ö†Ô∏è Erro na chamada prim√°ria, tentando URLs alternativas...")
        
        ;; Tentar URLs alternativas
        (let [alternative-hosts ["http://pgai-ollama-1:11434" 
                                "http://172.18.0.2:11434" 
                                "http://host.docker.internal:11434" 
                                "http://localhost:11434"]
              successful-result (some (fn [host]
                                       (let [alt-url (str host "/api/generate")
                                             result (try-single-url alt-url options)]
                                         (when (:success result)
                                           (println "‚úÖ Conex√£o bem-sucedida com" alt-url)
                                           (:result result))))
                                     alternative-hosts)]
          (or successful-result
              (str "N√£o foi poss√≠vel conectar ao Ollama usando nenhum dos endpoints dispon√≠veis.")))))))
```

Esta abordagem tenta v√°rios endpoints diferentes e usa o primeiro que funcionar. A fun√ß√£o `call-ollama-api` primeiro tenta se conectar a uma URL prim√°ria e, caso falhe, percorre uma lista de URLs alternativas at√© encontrar uma conex√£o bem-sucedida. Para cada tentativa, ela utiliza a fun√ß√£o auxiliar `try-single-url` que encapsula a l√≥gica de tratamento de erros.

A implementa√ß√£o segue um padr√£o de fallback, onde a fun√ß√£o retorna o resultado da primeira conex√£o bem-sucedida ou uma mensagem de erro caso todas as tentativas falhem. Este m√©todo √© particularmente √∫til em ambientes containerizados, onde os endere√ßos de rede podem variar dependendo da configura√ß√£o do [Docker](https://www.docker.com/) ou [Podman](https://podman.io/) e da rede interna, garantindo maior resili√™ncia √† aplica√ß√£o.

Acessando [https://github.com/scovl/docai](https://github.com/scovl/docai), voc√™ pode ver o c√≥digo completo e testar a aplica√ß√£o. Ao executar por exemplo `./run.bat postgres` temos o seguinte output:

```bash
Inicializando DocAI...
Modo PostgreSQL ativado!
‚ÑπÔ∏è Para usar o Ollama, certifique-se de que ele est√° em execu√ß√£o com o comando: ollama serve
‚ÑπÔ∏è Usando o modelo deepseek-r1. Se voc√™ ainda n√£o o baixou, execute: ollama pull deepseek-r1
Configurando ambiente PostgreSQL para RAG...
‚úÖ Configurado para usar Ollama dentro do cont√™iner Docker/Podman
üöÄ Configurando PostgreSQL para RAG...
‚úÖ Extens√µes vector e ai habilitadas com sucesso
‚úÖ Tabela de documentos criada com sucesso
‚úÖ Configurado para usar Ollama dentro do cont√™iner Docker/Podman
‚úÖ Vectorizer j√° configurado (tabela documentos_embeddings j√° existe)
Importando documentos para o PostgreSQL...
‚úÖ Documento inserido com ID: 5
‚úÖ Arquivo importado com sucesso: resources\docs\example.md
PostgreSQL RAG pronto! Fa√ßa sua pergunta:
Como implementar JWT em Clojure?
Processando...
DEBUG - Processando query no PostgreSQL: Como implementar JWT em Clojure?
DEBUG - Detectada consulta relacionada a JWT, usando busca especial
DEBUG - Encontrados 5 documentos relacionados a JWT
DEBUG - Enviando prompt para o Ollama usando o modelo deepseek-r1
DEBUG - Tamanho do prompt ap√≥s truncamento: 4442 caracteres
DEBUG - Usando URL do Ollama: http://ollama:11434/api/generate
‚ö†Ô∏è Erro na chamada prim√°ria: Erro ao chamar a API do Ollama:  - 
üîÑ Tentando URLs alternativas...
üîÑ Tentando conectar ao Ollama em http://pgai-ollama-1:11434/api/generate
‚ö†Ô∏è Erro ao chamar a API do Ollama:  Erro ao chamar a API do Ollama:  - 
üîÑ Tentando conectar ao Ollama em http://172.18.0.2:11434/api/generate
‚ö†Ô∏è Erro ao chamar a API do Ollama:  Erro ao chamar a API do Ollama:  - 
üîÑ Tentando conectar ao Ollama em http://host.docker.internal:11434/api/generate
‚ö†Ô∏è Erro ao chamar a API do Ollama:  Erro ao chamar a API do Ollama:  - 
üîÑ Tentando conectar ao Ollama em http://localhost:11434/api/generate
‚úÖ Conex√£o bem-sucedida com http://localhost:11434/api/generate
<think>
Primeiro, preciso entender como a implementa√ß√£o de JWT em Clojure est√° relacionada com a integra√ß√£o do Ollama. Sabemos que o documento aborda a cria√ß√£o de tokens JWT usando a biblioteca `buddy.sign.jwt` e a manipula√ß√£o de chaves privadas com `clojure.java.security`. Al√©m disso, √© usada a biblioteca `http-kit` para intera√ß√£o HTTP com o Ollama.

Vou come√ßar analisando os passos necess√°rios para criar um token JWT. Primeiro, √© preciso definir os claims que compreendem informa√ß√µes como ID do usu√°rio, nome de usu√°rio e roles. Em seguida, associar um secret key ao token. No documento, h√° exemplos de como usar uma string secreta ou chaves assim√©tricas. 

A seguir, entendo que √© necess√°rio configurar as depend√™ncias no arquivo `project.clj` para incluir as bibliotecas necess√°rias: `buddy/sign` e `http-kit`. Tamb√©m √© importante garantir que o Ollama esteja rodando com a comando adequado para pulling os modelos e executar as infer√™ncias.

Para testar, seria √∫til executar uma requisi√ß√£o POST para /login usando curl, passando os dados de login como JSON. Depois, usar o token obtido na requisi√ß√£o POST para /rag/query, Including o campo Authorization com o Bearer do token.

Al√©m disso, devo considerar como lidar com as fun√ß√µes de Wrapping em Clojure para garantir que as requisi√ß√µes HTTP sejam encadeadas corretamente. Talvez seja √∫til estabelecer uma rotina de login que gera o token e a envia, seguida de usar esse token nas consultas RAG.

Finalmente, tenho que lidar com poss√≠veis erros, como se o Ollama n√£o est√° executando ou houver problemas de autentica√ß√£o. √â importante inspecionar os logs e verificar as respostas das requisi√ß√µes HTTP para entender quais erros estiverem ocorrendo.

No final, vou needear a documenta√ß√£o officially para confirmar se h√° mais funcionalidades dispon√≠veis que posso explorar ap√≥s a implementa√ß√£o b√°sica de JWT.
</think>

Para implementar a autentica√ß√£o com JWT em Clojure juntamente com a integra√ß√£o do Ollama, siga os passos abaixo. Isso permitir√° que voc√™ utilize tokens JWT para proteger suas requisi√ß√µes RAG.

### Passo 1: Configurar as depend√™ncias

Adicione as seguintes depend√™ncias ao seu `project.clj`:

[buddy/sign "3.4.0"]    ; Para gera√ß√£o de signatures e verifica√ß√£o de validade
[buddy/auth "2.6.1"]     ; Para fun√ß√µes de autentica√ß√£o
[http-kit "2.6.0"]      ; Para manipula√ß√£o de requisi√ß√µes HTTP
[buddy.core.keys :as keys]  ; Para gera√ß√£o de chaves privadas
[buddy.data.json :as json]  ; Para processamento JSON
```

Sucesso total!
Temos um sistema de busca sem√¢ntica com PostgreSQL, pgvector, pgai e Ollama em Clojure funcionando! üéâ

Este projeto de busca sem√¢ntica com PostgreSQL pode ser expandido de v√°rias maneiras interessantes. Uma possibilidade √© implementar um sistema de feedback do usu√°rio que capture as intera√ß√µes e avalia√ß√µes das respostas geradas, permitindo o refinamento cont√≠nuo dos resultados. Isso poderia ser feito adicionando uma tabela `feedback_usuarios` que registre a consulta original, a resposta fornecida e a avalia√ß√£o do usu√°rio (positiva ou negativa). Esses dados poderiam ent√£o ser utilizados para ajustar os par√¢metros de similaridade ou at√© mesmo para treinar um modelo de reranking que melhore a relev√¢ncia dos resultados ao longo do tempo.

Outra expans√£o valiosa seria a integra√ß√£o com fontes de dados externas em tempo real. Por exemplo, poder√≠amos criar um sistema de ingest√£o autom√°tica que monitore feeds RSS, APIs ou reposit√≥rios Git espec√≠ficos, extraindo novos conte√∫dos periodicamente e atualizando nossa base de conhecimento. Isso manteria o sistema sempre atualizado com as informa√ß√µes mais recentes, especialmente √∫til em dom√≠nios que evoluem rapidamente como tecnologia e ci√™ncia. A implementa√ß√£o poderia utilizar workers ass√≠ncronos em Clojure que processam novas entradas em background, vetorizam o conte√∫do e o inserem automaticamente no PostgreSQL sem interrup√ß√£o do servi√ßo principal. Muito legal n√£o √©?

---

### Persist√™ncia de Modelos entre Reinicializa√ß√µes

Um problema comum ao trabalhar com Ollama em cont√™ineres √© que os modelos s√£o baixados repetidamente quando os cont√™ineres s√£o recriados. Para evitar isso:

1. Use volumes para armazenar os dados do Ollama:
   ```yaml
   volumes:
     ollama_data:/root/.ollama
   ```

2. Ao parar os cont√™ineres, evite remover os volumes:
   ```bash
   # Incorreto (remove volumes)
   docker compose down --volumes
   
   # Correto (preserva volumes)
   docker compose down
   ```

3. Implemente verifica√ß√µes antes de baixar modelos:
   ```bash
   # Verificar se o modelo j√° existe antes de baix√°-lo
   docker exec pgai-ollama-1 ollama list | grep "nomic-embed-text" > /dev/null
   if [ $? -ne 0 ]; then
     echo "Baixando modelo nomic-embed-text..."
     docker exec pgai-ollama-1 ollama pull nomic-embed-text
   else
     echo "Modelo nomic-embed-text j√° est√° dispon√≠vel"
   fi
   ```

Seguindo essas pr√°ticas, voc√™ economizar√° largura de banda e tempo, al√©m de melhorar significativamente a experi√™ncia do usu√°rio.

### Buscas Especializadas para T√≥picos Espec√≠ficos

Ao implementar seu sistema RAG, considere adicionar rotas especializadas de busca para certos t√≥picos. Por exemplo, se seu sistema precisa responder bem a consultas sobre JWT (JSON Web Tokens):

```clojure
(defn query-pg-rag
  "Processa uma consulta com tratamento especial para certos t√≥picos"
  [query]
  ;; Verificar primeiro se √© uma consulta relacionada a JWT
  (let [lower-query (str/lower-case query)
        jwt-keywords ["jwt" "token" "autentica√ß√£o"]]
    
    (if (some #(str/includes? lower-query %) jwt-keywords)
      ;; Busca especializada para JWT usando SQL direto
      (let [conn (jdbc/get-connection db-spec)
            docs (jdbc/execute! 
                   conn 
                   ["SELECT id, titulo, conteudo FROM documentos 
                     WHERE LOWER(conteudo) LIKE ? LIMIT 5"
                    "%jwt%"])]
        ;; Processar resultados espec√≠ficos de JWT...
        )
      
      ;; Busca sem√¢ntica padr√£o para outros t√≥picos
      (semantic-search query 5))))
```

Esta abordagem h√≠brida combina busca por palavras-chave para t√≥picos espec√≠ficos com busca sem√¢ntica para consultas gerais, melhorando a precis√£o global do sistema.

---

## Conclus√£o

Neste artigo, exploramos como construir um sistema de busca sem√¢ntica robusto usando PostgreSQL, pgvector, pgai e Ollama. Esta abordagem n√£o s√≥ oferece melhor precis√£o em compara√ß√£o com m√©todos tradicionais baseados em palavras-chave, mas tamb√©m √© altamente escal√°vel e adequada para ambientes de produ√ß√£o.

Vimos como configurar o ambiente usando Docker/Podman, como lidar com desafios comuns de comunica√ß√£o entre cont√™ineres, e implementamos estrat√©gias para manter a persist√™ncia de modelos e melhorar a experi√™ncia do usu√°rio. A combina√ß√£o de busca sem√¢ntica com t√©cnicas espec√≠ficas para t√≥picos especiais, como JWT, demonstra a flexibilidade desta abordagem.

Para quem j√° trabalhou com RAG usando abordagens mais simples, como TF-IDF, esta implementa√ß√£o representa um salto significativo em termos de capacidades, mantendo a simplicidade operacional gra√ßas √†s ferramentas modernas que utilizamos.

Quer saber mais sobre como implementar sistemas RAG avan√ßados em seus projetos? Confira nossos outros artigos sobre o assunto e experimente o c√≥digo completo dispon√≠vel no [reposit√≥rio do DocAI](https://github.com/scovl/docai). Estamos ansiosos para ver o que voc√™ vai construir!

---

## Refer√™ncias

- [Documenta√ß√£o do pgvector](https://github.com/pgvector/pgvector) - Extens√£o do PostgreSQL para armazenar, indexar e consultar embeddings vetoriais de alta dimensionalidade.
- [Documenta√ß√£o do pgai](https://github.com/timescale/pgai) - Extens√£o do PostgreSQL que simplifica o armazenamento e recupera√ß√£o de dados para RAG e outras aplica√ß√µes de IA.
- [Embeddings Eficientes com PostgreSQL](https://supabase.com/blog/openai-embeddings-postgres-vector) - Artigo sobre como usar embeddings com PostgreSQL.
- [HNSW vs. IVFFlat para Busca de Similaridade](https://www.pinecone.io/learn/hnsw-ivfflat/) - Artigo sobre as diferen√ßas entre HNSW e IVFFlat para busca de similaridade.
- [Ollama - Rodando LLMs localmente](https://ollama.com/) - Documenta√ß√£o do Ollama, uma ferramenta open-source para executar modelos de linguagem de grande escala localmente.
- [Artigo anterior sobre RAG com Clojure](/post/rag/) - Artigo sobre como implementar RAG com Clojure.