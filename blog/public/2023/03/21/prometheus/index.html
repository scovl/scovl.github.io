<!DOCTYPE html>
<html lang="pt">
<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <title>Prometheus | scovl</title>
    <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="Under the hood">


<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css">
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>


<script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
<script>
    document.addEventListener("DOMContentLoaded", function() {
        mermaid.initialize({
            startOnLoad: true,
            theme: 'light',
            align: 'center'
        });
    });
</script>
 
</head>
<body>
    
    
    <header class="header">
    <div class="container">
        <div class="header-content">
            <a href="http://localhost:1313/" class="site-title">scovl</a>
            
            <nav>
                <ul class="nav-menu">
                    
                    
                    <li>
                        <a href="/page/about/" class="nav-link ">
                            About
                        </a>
                    </li>
                    
                    <li>
                        <a href="/page/contact/" class="nav-link ">
                            Contact
                        </a>
                    </li>
                    
                </ul>
            </nav>
        </div>
    </div>
</header> 
    
    
    
    <main>
        <div class="container">
            
<article class="post">
    <header class="post-header">
        <h1 class="post-title">Prometheus</h1>
        <div class="post-meta">
            
            <time datetime="2023-03-21T23:18:18-03:00">
                Tue, Mar 21, 2023
            </time>
            
            
            
            
            
            <div class="post-tags">
                
                <a href="/tags/prometheus/" class="tag">Prometheus</a>
                
                <a href="/tags/grafana/" class="tag">Grafana</a>
                
                <a href="/tags/monitoring/" class="tag">Monitoring</a>
                
                <a href="/tags/tsdb/" class="tag">TSDB</a>
                
                <a href="/tags/devops/" class="tag">DevOps</a>
                
                <a href="/tags/observability/" class="tag">Observability</a>
                
            </div>
            
            
            
            <div class="reading-time">
                Estimated reading time: 50 min
            </div>
            
            
            
            <div class="post-description">
                Under the hood
            </div>
            
        </div>
    </header>
    
    <div class="post-content">
        <h2 id="√≠ndice">√çndice</h2>
<ul>
<li><strong><a href="/2023/03/21/prometheus/#introdu%c3%a7%c3%a3o">Introdu√ß√£o</a></strong></li>
<li><strong><a href="/2023/03/21/prometheus/#instala%c3%a7%c3%a3o">Instala√ß√£o</a></strong></li>
<li><strong><a href="/2023/03/21/prometheus/#promtool">Promtool</a></strong></li>
<li><strong><a href="/2023/03/21/prometheus/#instrumenta%c3%a7%c3%a3o">Instrumenta√ß√£o</a></strong></li>
<li><strong><a href="/2023/03/21/prometheus/#alertmanager">Alertmanager</a></strong></li>
<li><strong><a href="/2023/03/21/prometheus/#pushgateway">PushGateway</a></strong></li>
<li><strong><a href="/2023/03/21/prometheus/#federa%c3%a7%c3%a3o">Federa√ß√£o</a></strong></li>
<li><strong><a href="/2023/03/21/prometheus/#under-the-hood">Under the Hood</a></strong></li>
<li><strong><a href="/2023/03/21/prometheus/#melhores-pr%c3%a1ticas">Melhores Pr√°ticas</a></strong></li>
<li><strong><a href="/2023/03/21/prometheus/#conclus%c3%a3o">Conclus√£o</a></strong></li>
</ul>
<h2 id="introdu√ß√£o">Introdu√ß√£o</h2>
<p>O <strong><a href="https://prometheus.io/">Prometheus</a></strong> √© uma ferramenta open-source de monitoramento de sistemas e aplica√ß√µes que revolucionou a forma de pensar observabilidade em ambientes distribu√≠dos. Ele coleta e armazena m√©tricas como s√©ries temporais, ou seja, valores num√©ricos associados a um carimbo de tempo e a pares chave-valor chamados <strong><a href="https://prometheus.io/docs/concepts/data_model/#metric-names-and-labels">labels</a></strong>. A pot√™ncia do Prometheus vem, em parte, da sua linguagem de consulta pr√≥pria, <strong><a href="https://prometheus.io/docs/prometheus/latest/querying/basics/">PromQL</a></strong>, que permite criar consultas complexas para analisar os dados coletados em tempo real. A interface web integrada (Expression browser) facilita visualizar e explorar m√©tricas, possibilitando an√°lises r√°pidas para identificar tend√™ncias e anomalias.</p>
<p>Desenvolvido inicialmente na SoundCloud em 2012 por <a href="https://github.com/juliusv">Julius Volz</a> e equipe, o Prometheus foi projetado para ser simples, eficiente e altamente dimension√°vel. Em 2016, o projeto foi adotado pela <strong><a href="https://www.cncf.io/">Cloud Native Computing Foundation (CNCF)</a></strong> como o segundo projeto hospedado (logo ap√≥s o <a href="https://kubernetes.io/">Kubernetes</a>), refor√ßando sua maturidade e ampla ado√ß√£o pela comunidade. Hoje, o Prometheus √© um pilar no ecossistema de observabilidade cloud-native, frequentemente usado em conjunto com o Grafana para visualiza√ß√µes avan√ßadas, formando uma poderosa stack de monitoramento.</p>
<blockquote>
<p><strong>Nota:</strong> Para um deep dive em PromQL, confira nosso artigo dedicado <strong><a href="https://scovl.github.io/2023/03/19/promql/">aqui</a></strong>.</p></blockquote>
<h3 id="tipos-de-m√©tricas">Tipos de m√©tricas</h3>
<p>O Prometheus suporta quatro tipos principais de m√©tricas:</p>
<ul>
<li>
<p><strong><a href="https://prometheus.io/docs/concepts/metric_types/#counter">Counter (Contador)</a></strong>: M√©trica cumulativa que apenas aumenta (ou zera). Indicada para quantificar eventos, como n√∫mero de requisi√ß√µes ou erros. Por exemplo, um contador <code>http_requests_total</code> incrementa a cada requisi√ß√£o recebida. Contadores nunca diminuem, exceto quando reiniciados. Consultas comuns envolvem a taxa de aumento usando fun√ß√µes como <code>rate()</code> ou <code>increase()</code>, calculando, por exemplo, quantas requisi√ß√µes por segundo ocorreram em determinado intervalo.</p>
</li>
<li>
<p><strong><a href="https://prometheus.io/docs/concepts/metric_types/#gauge">Gauge (Indicador)</a></strong>: M√©trica que representa um valor em um instante, podendo tanto aumentar quanto diminuir. Indicado para valores como utiliza√ß√£o de CPU, mem√≥ria ou tamanho de fila ‚Äì que sobem e descem livremente. N√£o possui limite m√≠nimo ou m√°ximo fixo. Fun√ß√µes como <code>avg_over_time()</code>, <code>min()</code>, <code>max()</code> e <code>sum()</code> s√£o frequentemente aplicadas sobre gauges para obter m√©dias, m√≠nimos, m√°ximos ou somas ao longo do tempo.</p>
</li>
<li>
<p><strong><a href="https://prometheus.io/docs/concepts/metric_types/#histogram">Histogram (Histograma)</a></strong>: M√©trica que contabiliza a distribui√ß√£o de valores observados em <em>buckets</em> (faixas) predefinidos. √â muito utilizada para medir lat√™ncias (e.g., dura√ß√£o de requisi√µes) ou outros valores cuja distribui√ß√£o importa. O Prometheus implementa histogramas atrav√©s de v√°rios contadores ‚Äì um por bucket ‚Äì al√©m de contadores especiais para total de observa√ß√µes (<code>_count</code>) e soma dos valores (<code>_sum</code>). Consultas tipicamente usam <code>histogram_quantile()</code> para extrair percentis a partir dos buckets e fun√ß√µes como <code>rate()</code> ou <code>increase()</code> nos contadores para ver taxas.</p>
</li>
<li>
<p><strong><a href="https://prometheus.io/docs/concepts/metric_types/#summary">Summary (Sum√°rio)</a></strong>: M√©trica similar ao histograma, mas os c√°lculos de percentis e m√©dias s√£o feitos pelo pr√≥prio alvo instrumentado. O summary fornece diretamente percentis (por exemplo, lat√™ncia p95) e contagens/agregados para um conjunto de observa√ß√µes. Entretanto, summaries t√™m a limita√ß√£o de n√£o poderem ser agregados facilmente entre m√∫ltiplas inst√¢ncias (diferente dos histogramas). Em geral, histogramas s√£o preferidos para m√©tricas de lat√™ncia quando se quer combinar valores de v√°rias fontes, enquanto summaries podem ser √∫teis para percentis muito espec√≠ficos em inst√¢ncias isoladas.</p>
</li>
</ul>
<p>Al√©m desses tipos principais, o Prometheus exp√µe m√©tricas especiais de estado ‚Äì por exemplo, a m√©trica interna <code>up</code> indica se um determinado alvo foi coletado com sucesso (valor 1) ou n√£o (0). Essa m√©trica √© muito √∫til para monitorar disponibilidade de servi√ßos: se um <strong>endpoint</strong> monitorado ficar indispon√≠vel, <code>up{instance=&quot;endpoint:porta&quot;} == 0</code> sinaliza falha. Vale notar que n√£o existe um &ldquo;tipo&rdquo; separado para essas m√©tricas de sa√∫de; elas normalmente s√£o gauges (0 ou 1) usadas para esse prop√≥sito.</p>
<h3 id="monitoramento-pull-vs-push">Monitoramento pull vs push</h3>
<p>Para entender <strong>pull</strong> vs <strong>push</strong>, imagine cuidar de plantas: no modelo <strong>pull</strong> voc√™ vai todo dia verificar se precisam de √°gua; no modelo <strong>push</strong> as pr√≥prias plantas enviam um sinal quando precisam ser regadas. Tecnicamente, no monitoramento <strong>pull</strong> um sistema central (como o Prometheus) consulta periodicamente os alvos para coletar m√©tricas ‚Äì ele &ldquo;puxa&rdquo; as informa√ß√µes. J√° no monitoramento <strong>push</strong>, os pr√≥prios alvos enviam (<em>empurram</em>) as m√©tricas para um coletor central sem serem solicitados.</p>
<p><img src="https://raw.githubusercontent.com/scovl/scovl.github.io/main/post/images/tsdb/prom-pullvspush.png" alt=""></p>
<p>No Prometheus, prevalece o modelo pull. O servidor Prometheus periodicamente faz <strong>scrape</strong> (raspagem) dos dados de cada alvo exportador via HTTP, no endpoint padr√£o <code>/metrics</code>. Cada scrape coleta o valor atual de todas as s√©ries expostas naquele alvo. Os alvos podem ser aplica√ß√µes instrumentadas que exp√µem suas m√©tricas diretamente, ou <strong>exporters</strong> (exportadores) que traduzem m√©tricas de sistemas externos para o formato do Prometheus. Assim, o Prometheus obt√©m em intervalos regulares (por padr√£o a cada 15s) as m√©tricas atuais de cada servi√ßo, armazenando-as localmente.</p>
<p>Na imagem acima, a compara√ß√£o dos modelos de coleta: √† esquerda, no modo push os clientes enviam suas m√©tricas proativamente a um gateway; √† direita, no modo pull o Prometheus consulta cada cliente periodicamente. O modelo pull tem vantagens em simplicidade e confiabilidade ‚Äì se um servi√ßo cair, o Prometheus sabe (a m√©trica <code>up</code> fica 0) e n√£o depende de buffers intermedi√°rios. J√° o modelo push pode ser √∫til para casos espec√≠ficos, como <em>jobs</em> de curta dura√ß√£o ou ambientes onde n√£o √© poss√≠vel expor um endpoint (nesses casos usa-se o <strong>Pushgateway</strong>, discutido adiante). Em suma, o Prometheus, por padr√£o, <strong>n√£o</strong> recebe m√©tricas ativamente; ele mesmo vai colet√°-las, evitando sobrecarga nos aplicativos monitorados e detectando automaticamente indisponibilidades.</p>
<h3 id="arquitetura-do-prometheus">Arquitetura do Prometheus</h3>
<p>A arquitetura do Prometheus foi concebida para facilitar a coleta de dados de m√∫ltiplas fontes de forma confi√°vel e distribu√≠da. O cora√ß√£o do sistema √© o <strong><a href="https://prometheus.io/docs/prometheus/latest/components/prometheus/">Prometheus Server</a></strong> principal, respons√°vel por agendar e realizar as coletas (<em>scrapes</em>) de cada alvo monitorado e armazenar as s√©ries temporais resultantes localmente. A configura√ß√£o dessas coletas √© definida em um arquivo YAML (geralmente <code>prometheus.yml</code>), especificando <strong><a href="https://prometheus.io/docs/prometheus/latest/configuration/configuration/#job_name">jobs</a></strong> e <strong><a href="https://prometheus.io/docs/prometheus/latest/configuration/configuration/#static_configs">targets</a></strong> ‚Äì por exemplo, &ldquo;coletar m√©tricas do servi√ßo X na URL Y a cada 15 segundos&rdquo;. A figura abaixo (extra√≠da da documenta√ß√£o oficial) ilustra a arquitetura e os componentes do ecossistema Prometheus:</p>
<p><img src="https://raw.githubusercontent.com/scovl/scovl.github.io/refs/heads/main/blog/content/post/images/tsdb/arch.png" alt=""></p>
<p>Em resumo, o fluxo √©: o Prometheus <strong>raspa (pull)</strong> m√©tricas dos jobs instrumentados, diretamente dos servi√ßos ou via um componente intermedi√°rio de push para jobs ef√™meros. Todos os samples coletados s√£o armazenados localmente no banco de dados de s√©ries temporais embutido (<a href="https://prometheus.io/docs/prometheus/latest/storage/tsdb/">TSDB</a>). Regras definidas podem ser executadas continuamente sobre esses dados ‚Äì seja para gravar novas s√©ries agregadas (<a href="https://prometheus.io/docs/prometheus/latest/configuration/recording_rules/">recording rules</a>) ou para acionar <strong><a href="https://prometheus.io/docs/prometheus/latest/configuration/alerting_rules/">alertas</a></strong>. Os alertas gerados pelo Prometheus s√£o ent√£o enviados para o <strong><a href="https://prometheus.io/docs/alerting/latest/alertmanager/">Alertmanager</a></strong> processar. Por fim, ferramentas de visualiza√ß√£o como o <strong><a href="https://grafana.com/">Grafana</a></strong> podem consultar o Prometheus para exibir dashboards das m√©tricas coletadas.</p>
<p>O ecossistema Prometheus possui diversos componentes (muitos opcionais) que interagem nessa arquitetura:</p>
<ul>
<li><strong><a href="https://prometheus.io/docs/prometheus/latest/components/prometheus/">Servidor Prometheus</a></strong> ‚Äì o servidor principal que coleta e armazena as m√©tricas e processa consultas PromQL.</li>
<li><strong><a href="https://prometheus.io/docs/instrumenting/clientlibs/">Bibliotecas cliente</a></strong> ‚Äì usadas para instrumentar c√≥digo de aplica√ß√µes (expondo m√©tricas via /metrics). H√° libs oficiais em Go, Java, Ruby, Python, etc.</li>
<li><strong><a href="https://prometheus.io/docs/instrumenting/exporters/">Exporters</a></strong> ‚Äì programas externos que coletam m√©tricas de servi√ßos ou sistemas terceiros (bancos de dados, servidores web, sistemas operacionais) e as exp√µem no formato Prometheus. Exemplos: Node Exporter (m√©tricas de sistema Linux), Blackbox Exporter (monitoramento de endpoints externos), etc.</li>
<li><strong><a href="https://prometheus.io/docs/instrumenting/pushing/">Pushgateway</a></strong> ‚Äì gateway para receber m√©tricas <em>pushed</em> por aplicativos de curta dura√ß√£o ou ambientes onde n√£o d√° para o Prometheus puxar diretamente.</li>
<li><strong><a href="https://prometheus.io/docs/alerting/latest/alertmanager/">Alertmanager</a></strong> ‚Äì componente respons√°vel por receber alertas enviados pelo Prometheus e gerenciar o envio de notifica√ß√µes (email, Slack, PagerDuty etc.), realizando agrupamento, deduplica√ß√£o e silenciamento conforme configurado.</li>
<li><strong><a href="https://prometheus.io/docs/prometheus/latest/tools/">Ferramentas de suporte</a></strong> ‚Äì englobam utilit√°rios de linha de comando (como o promtool), exportadores de terceiros, dashboards pr√©-configurados, entre outros, que facilitam operar e integrar o Prometheus.</li>
</ul>
<p>Essa arquitetura descentralizada (com coleta <strong><a href="https://prometheus.io/docs/prometheus/latest/configuration/configuration/#pull_interval">pull</a></strong> e componentes distintos) torna o Prometheus especialmente adequado a ambientes modernos com microsservi√ßos e orquestra√ß√£o de cont√™ineres (<a href="https://www.docker.com/">Docker</a>, <a href="https://kubernetes.io/">Kubernetes</a>). Ele foi projetado para funcionar de forma aut√¥noma em cada n√≥ (cada servidor Prometheus √© independente, sem depend√™ncia de armazenamento distribu√≠do), privilegiando confiabilidade mesmo durante falhas de rede ou de outros servi√ßos. Em caso de problemas graves na infraestrutura, voc√™ ainda consegue acessar m√©tricas recentes localmente no Prometheus, que atua como fonte de verdade para diagnosticar incidentes.</p>
<h3 id="labels-e-samples">Labels e Samples</h3>
<p>No Prometheus, <strong><a href="https://prometheus.io/docs/concepts/data_model/#metric-names-and-labels">labels</a></strong> (r√≥tulos) e <strong><a href="https://prometheus.io/docs/concepts/data_model/#samples-and-series">samples</a></strong> (amostras) s√£o conceitos-chave para organizar os dados monitorados. Uma analogia simples: imagine um guarda-roupa onde cada roupa tem etiquetas indicando cor, tamanho e tipo. Essas etiquetas ajudam a encontrar rapidamente, por exemplo, &ldquo;camisetas verdes tamanho M&rdquo;. Da mesma forma, no Prometheus cada m√©trica pode ter v√°rios <strong><a href="https://prometheus.io/docs/concepts/data_model/#metric-names-and-labels">labels</a></strong> (chave=valor) que a qualificam. Por exemplo, uma m√©trica <code>app_memory_usage_bytes</code> poderia ter labels como <code>host=&quot;servidor1&quot;</code> e <code>region=&quot;us-east&quot;</code>. Assim podemos filtrar/consultar &ldquo;uso de mem√≥ria no servidor1&rdquo; apenas buscando por <code>host=&quot;servidor1&quot;</code>.</p>
<p>Os <strong><a href="https://prometheus.io/docs/concepts/data_model/#metric-names-and-labels">labels</a></strong> permitem um modelo de dados multidimensional ‚Äì ou seja, uma mesma m√©trica (ex: <code>http_requests_total</code>) √© armazenada separadamente para cada combina√ß√£o de labels (rota=&quot;/login&quot;, m√©todo=&ldquo;GET&rdquo;, c√≥digo=&ldquo;200&rdquo;, etc.). Isso enriquece as an√°lises, pois podemos agregar ou dividir m√©tricas por essas dimens√µes conforme necess√°rio.</p>
<p><img src="https://raw.githubusercontent.com/scovl/scovl.github.io/master/post/images/tsdb/samples01.png" alt=""></p>
<p>J√° os <strong><a href="https://prometheus.io/docs/concepts/data_model/#samples-and-series">samples</a></strong> s√£o as unidades de dado coletadas ao longo do tempo ‚Äì cada medi√ß√£o individual de uma m√©trica em um determinado instante. Voltando √† analogia, se ped√≠ssemos a cada crian√ßa numa pesquisa que escolhesse 3 balas, as balas escolhidas por cada crian√ßa seriam uma <strong>amostra</strong> da prefer√™ncia de balas. No contexto do Prometheus, a cada scrape o valor de cada m√©trica coletada √© um sample (com timestamp e valor). Esses samples ficam armazenados como uma s√©rie temporal etiquetada, permitindo ver a evolu√ß√£o daquele valor no tempo.</p>
<p>Por exemplo, considere a m√©trica gauge <code>node_cpu_usage</code> com label <code>host</code>. Para cada host monitorado, teremos uma s√©rie separada, e a cada intervalo de coleta obtemos um sample novo do uso de CPU daquele host. Assim, podemos consultar a s√©rie para ver como a CPU variou ao longo de um dia inteiro para cada m√°quina.</p>
<blockquote>
<p><strong>Exemplo de s√©ries temporais no Prometheus</strong>: cada ponto representa um sample (valor observado) etiquetado por inst√¢ncia ou outra dimens√£o, armazenado em sequ√™ncia temporal.</p></blockquote>
<p>Em resumo, <strong><a href="https://prometheus.io/docs/concepts/data_model/#metric-names-and-labels">labels</a></strong> fornecem contexto (quem, onde, o qu√™) e <strong><a href="https://prometheus.io/docs/concepts/data_model/#samples-and-series">samples</a></strong> fornecem o valor num√©rico no tempo. Essa combina√ß√£o √© o que torna o Prometheus poderoso para agregar m√©tricas semelhantes e, ao mesmo tempo, permitir recortes por dimens√£o. Vale ressaltar a import√¢ncia de escolher labels com cardinalidade controlada ‚Äì ou seja, evitar labels que possam assumir valores extremamente variados (como IDs √∫nicos, URLs completas ou timestamps). Labels com varia√ß√£o descontrolada podem causar uma explos√£o de s√©ries e sobrecarregar o Prometheus, conforme discutiremos em melhores pr√°ticas.</p>
<h2 id="instala√ß√£o">Instala√ß√£o</h2>
<p>Existem diversas maneiras de instalar e executar o Prometheus. Aqui vou demonstrar uma configura√ß√£o simples usando <strong><a href="https://www.docker.com/">Docker</a></strong> e <strong><a href="https://docs.docker.com/compose/">Docker Compose</a></strong>, incluindo o Grafana e uma ferramenta de simula√ß√£o de m√©tricas chamada <strong><a href="https://github.com/dmitsh/promsim">PromSim</a></strong> (√∫til para testes). Essa stack de exemplo traz:</p>
<ul>
<li><strong><a href="https://prometheus.io/">Prometheus</a></strong> ‚Äì servidor de m√©tricas.</li>
<li><strong><a href="https://grafana.com/">Grafana</a></strong> ‚Äì para dashboards e visualiza√ß√£o.</li>
<li><strong><a href="https://github.com/dmitsh/promsim">PromSim</a></strong> ‚Äì um simulador que exp√µe m√©tricas aleat√≥rias para exercitar o Prometheus.</li>
</ul>
<p>Comece criando um arquivo <code>docker-compose.yml</code> com o seguinte conte√∫do:</p>


  <pre><code class="language-yaml">version: &#34;3&#34;
services:
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    ports:
      - &#34;9090:9090&#34;
    volumes:
      - &#34;./prometheus.yml:/etc/prometheus/prometheus.yml&#34;
    depends_on:
      - promsim

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - &#34;3000:3000&#34;

  promsim:
    image: sysdigtraining/promsim:latest
    container_name: promsim
    ports:
      - &#34;8080:8080&#34;</code></pre>
 <p>No mesmo diret√≥rio, crie o arquivo de configura√ß√£o <code>prometheus.yml</code> para o Prometheus:</p>


  <pre><code class="language-yaml">global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: &#34;promsim&#34;
    static_configs:
      - targets: [&#34;promsim:8080&#34;]</code></pre>
 <p>Esse arquivo define que o Prometheus far√° scrape a cada 15s (<code>scrape_interval</code>) e avalia regras na mesma frequ√™ncia (<code>evaluation_interval</code>). Em <code>scrape_configs</code>, temos um job chamado &ldquo;promsim&rdquo; que coleta m√©tricas do endere√ßo <code>promsim:8080</code> (nosso container PromSim simulando um alvo de m√©tricas). Agora suba os servi√ßos:</p>


  <pre><code class="language-bash">docker-compose up -d</code></pre>
 <p>Isso iniciar√° os containers Prometheus, Grafana e PromSim em segundo plano. Ap√≥s o start, acesse o Grafana em <strong><a href="http://localhost:3000">http://localhost:3000</a></strong> (usu√°rio <strong>admin</strong>, senha <strong>admin</strong> padr√£o). No Grafana, adicione o Prometheus como fonte de dados: v√° em <em>Configuration (engrenagem) &gt; Data Sources</em>, adicione nova fonte do tipo Prometheus com URL <strong><a href="http://prometheus:9090">http://prometheus:9090</a></strong> (que, devido ao Docker Compose, resolve para o container do Prometheus).</p>
<p>Feito isso, voc√™ j√° pode importar ou criar pain√©is Grafana usando as m√©tricas do Prometheus (inclusive as geradas pelo PromSim). O PromSim estar√° expondo v√°rias m√©tricas aleat√≥rias ‚Äì por exemplo, simulando CPU, mem√≥ria, requisi√ß√µes ‚Äì permitindo testar consultas e alertas sem precisar de uma aplica√ß√£o real por tr√°s. Para mais detalhes do PromSim, veja <strong><a href="https://github.com/dmitsh/promsim">a documenta√ß√£o oficial</a></strong>.</p>
<p>Caso queira rodar apenas o Prometheus isoladamente, basta executar o container oficial: <code>docker run -p 9090:9090 prom/prometheus</code>. Depois acesse <strong><a href="http://localhost:9090">http://localhost:9090</a></strong> para abrir a UI nativa do Prometheus:</p>
<p><img src="https://raw.githubusercontent.com/scovl/scovl.github.io/master/post/images/tsdb/ui01.png" alt=""></p>
<p>A interface web padr√£o do Prometheus inclui os seguintes menus no topo:</p>
<ul>
<li><strong><a href="/alerts">Alerts</a></strong>: lista os alertas ativos e suas informa√ß√µes. Mostra tamb√©m alertas pendentes e silenciados.</li>
<li><strong><a href="/graph">Graph</a></strong>: permite rodar consultas PromQL e visualizar o resultado em formato gr√°fico (ou tabela). √â √∫til para explorar interativamente as m√©tricas.</li>
<li><strong><a href="/status">Status</a></strong>: informa√ß√µes sobre o status do servidor Prometheus ‚Äì mem√≥ria usada, n√∫mero de s√©ries ativas, status das coletas, etc.
<ul>
<li><strong><a href="/targets">Targets</a></strong> (na se√ß√£o Status): mostra todos os alvos configurados e se a coleta est√° OK (up) ou falhou.</li>
<li><strong><a href="/service-discovery">Service Discovery</a></strong> (tamb√©m em Status): lista os servi√ßos descobertos via mecanismos din√¢micos (Kubernetes, DNS, etc.).</li>
</ul>
</li>
<li><strong><a href="/classic/targets">Help</a></strong>: link para documenta√ß√£o e ajuda do Prometheus.</li>
</ul>
<p>Al√©m disso, logo abaixo dos menus, a UI oferece algumas op√ß√µes e campos importantes:</p>
<ul>
<li><strong><a href="https://prometheus.io/docs/prometheus/latest/querying/basics/#time-range-and-resolution-selection">Time range e refresh</a></strong>: controles para selecionar o intervalo de tempo da consulta e atualizar automaticamente.</li>
<li><strong><a href="https://prometheus.io/docs/prometheus/latest/querying/basics/#time-range-and-resolution-selection">Use local time</a></strong>: alterna entre exibir os timestamps no seu fuso hor√°rio local ou em UTC.</li>
<li><strong><a href="https://prometheus.io/docs/prometheus/latest/querying/basics/#query-history">Query history</a></strong>: op√ß√£o para habilitar hist√≥rico das consultas feitas (facilita repetir queries recentes).</li>
<li><strong><a href="https://prometheus.io/docs/prometheus/latest/querying/basics/#autocomplete">Autocomplete</a></strong>: op√ß√£o para habilitar auto-completar de m√©tricas e fun√ß√µes no campo de consulta.</li>
<li><strong><a href="https://prometheus.io/docs/prometheus/latest/querying/basics/#expression-language-promql">Campo de consulta PromQL</a></strong>: onde voc√™ escreve a express√£o a ser consultada. O Prometheus traz sugest√µes enquanto voc√™ digita (se autocomplete ligado).</li>
<li><strong><a href="https://prometheus.io/docs/prometheus/latest/querying/basics/#execute-and-reset">Bot√µes Execute / Reset</a></strong>: para executar a consulta ou limpar o campo.</li>
<li><strong><a href="https://prometheus.io/docs/prometheus/latest/querying/basics/#graph-and-table">Aba Graph / Table</a></strong>: seleciona se o resultado ser√° plotado em um gr√°fico ou mostrado como tabela bruta de valores.</li>
<li><strong><a href="https://prometheus.io/docs/prometheus/latest/querying/basics/#evaluation-time">Evaluation time</a></strong>: permite fixar um timestamp espec√≠fico para avaliar a query (por padr√£o √© &ldquo;now&rdquo;, mas voc√™ pode ver valores hist√≥ricos escolhendo um hor√°rio passado).</li>
</ul>
<blockquote>
<p><strong>Dica:</strong> a UI do Prometheus √© √≥tima para explorar e depurar m√©tricas rapidamente, mas para dashboards permanentes e mais bonitos geralmente usamos o Grafana. O Grafana se conecta ao Prometheus via API e permite combinar m√∫ltiplas consultas em gr√°ficos customizados.</p></blockquote>
<h3 id="configura√ß√£o">Configura√ß√£o</h3>
<p>Ap√≥s instalar, o principal arquivo a ajustar √© o de <strong><a href="https://prometheus.io/docs/prometheus/latest/configuration/configuration/">configura√ß√£o do Prometheus</a></strong> (<code>prometheus.yml</code>). Nele definimos os par√¢metros globais, jobs de scrape, regras de alerta, etc. Vamos examinar a estrutura b√°sica e algumas customiza√ß√µes comuns. Um exemplo m√≠nimo de <code>prometheus.yml</code> poderia ser:</p>


  <pre><code class="language-yaml">global:
  scrape_interval: 15s

scrape_configs:
  - job_name: &#39;prometheus&#39;
    static_configs:
      - targets: [&#39;localhost:9090&#39;]</code></pre>
 <p>Nesse caso, definimos um intervalo global de scrape de 15s e um job para monitorar o pr√≥prio Prometheus (expondo m√©tricas em <a href="http://localhost:9090">localhost:9090</a>). Para monitorar outras aplica√ß√µes, adicionamos novos blocos em <code>scrape_configs</code>. Por exemplo, para monitorar uma aplica√ß√£o web rodando na porta 8080 de um host chamado <code>my-app</code>:</p>


  <pre><code class="language-yaml">scrape_configs:
  - job_name: &#39;my-app&#39;
    static_configs:
      - targets: [&#39;my-app:8080&#39;]</code></pre>
 <p>Isso instruir√° o Prometheus a coletar periodicamente m√©tricas em <strong><a href="http://my-app:8080/metrics">http://my-app:8080/metrics</a></strong>. Podemos repetir o processo para cada servi√ßo ou componente que queremos incluir, definindo um <code>job_name</code> descritivo e a lista de endpoints (targets).</p>
<p>Para ambientes com muitos alvos ou infraestrutura din√¢mica, √© invi√°vel gerenciar esses targets manualmente. Nesses casos, o Prometheus oferece integra√ß√µes de <strong>Service Discovery</strong> (Kubernetes, AWS EC2, Consul, DNS, etc.) e tamb√©m o <strong>file-based discovery</strong> (descoberta via arquivos). Este √∫ltimo permite apontar para um ou mais arquivos JSON externos contendo a lista de targets. Assim, ferramentas externas ou scripts podem atualizar esses arquivos conforme os servi√ßos mudam, e o Prometheus percebe as altera√ß√µes automaticamente. Por exemplo, poder√≠amos alterar o job acima para usar arquivo:</p>


  <pre><code class="language-yaml">scrape_configs:
  - job_name: &#39;my-app&#39;
    file_sd_configs:
      - files:
          - /etc/prometheus/targets/my-app.json</code></pre>
 <p>E no arquivo <code>/etc/prometheus/targets/my-app.json</code> colocar algo como:</p>


  <pre><code class="language-json">[
  {
    &#34;labels&#34;: {
      &#34;job&#34;: &#34;my-app&#34;,
      &#34;env&#34;: &#34;production&#34;
    },
    &#34;targets&#34;: [
      &#34;my-app1:8080&#34;,
      &#34;my-app2:8080&#34;
    ]
  }
]</code></pre>
 <p>Nesse JSON, especificamos dois targets (dois inst√¢ncias da aplica√ß√£o <code>my-app</code>) e tamb√©m atribu√≠mos labels adicionais a essas inst√¢ncias (<code>env: production</code>, por exemplo). Assim, se futuramente adicionarmos <code>my-app3:8080</code>, basta atualizar o JSON ‚Äì o Prometheus recarrega periodicamente ou quando o arquivo muda. Esse m√©todo facilita escalabilidade e automa√ß√£o da configura√ß√£o de alvos.</p>
<p>Outro ponto de configura√ß√£o importante √© a <strong>reten√ß√£o de dados</strong>. Por padr√£o, o Prometheus guarda as s√©ries temporais localmente por 15 dias. Em ambientes de produ√ß√£o, pode ser necess√°rio ajustar esse per√≠odo. Voc√™ pode definir a flag de inicializa√ß√£o <code>--storage.tsdb.retention.time</code> (ou configurar no servi√ßo) para algo maior, por exemplo <code>30d</code> para reter ~1 m√™s de m√©tricas. Tenha em mente que aumentar a reten√ß√£o aumenta proporcionalmente o consumo de disco e mem√≥ria. Tamb√©m √© poss√≠vel limitar por tamanho de disco (<code>--storage.tsdb.retention.size</code>), se preferir. Caso precise de reten√ß√£o muito longa (meses/anos), √© recomend√°vel integrar com solu√ß√µes de armazenamento remoto em vez de manter tudo no Prometheus (falaremos disso em <em>Melhores Pr√°ticas</em>). Exemplo de defini√ß√£o de reten√ß√£o no <strong><a href="https://prometheus.io/docs/prometheus/latest/configuration/configuration/#configuration-file">systemd</a></strong> (ExecStart):</p>


  <pre><code class="language-bash">/opt/prometheus/prometheus \
  --config.file=/opt/prometheus/prometheus.yml \
  --storage.tsdb.retention.time=30d</code></pre>
 <blockquote>
<p><strong>Nota:</strong> O formato aceita unidades como <code>h</code>, <code>d</code>, <code>w</code>, <code>y</code>. Voc√™ tamb√©m pode usar a op√ß√£o <code>--storage.tsdb.retention.size</code> para definir um tamanho m√°ximo (por ex: <code>50GB</code>), o que ocorrer primeiro (tempo ou tamanho) aciona a limpeza de dados antigos.</p></blockquote>
<p>Em instala√ß√µes via pacote ou container, normalmente a estrutura de diret√≥rios do Prometheus √© assim:</p>


  <pre><code class="language-">/opt/prometheus/
‚îú‚îÄ‚îÄ prometheus (bin√°rio)
‚îú‚îÄ‚îÄ promtool   (bin√°rio utilit√°rio)
‚îú‚îÄ‚îÄ prometheus.yml (configura√ß√£o)
‚îú‚îÄ‚îÄ consoles/  (arquivos HTML da UI &#34;classic&#34;)
‚îú‚îÄ‚îÄ console_libraries/ (bibliotecas JS para consoles)
‚îî‚îÄ‚îÄ data/      (armazenamento local das s√©ries temporais)</code></pre>
 <p>A pasta <code>data/</code> merece destaque ‚Äì ali ficam todos os dados das m√©tricas coletadas. Abordaremos sua estrutura interna na se√ß√£o &ldquo;Under the Hood&rdquo;.</p>
<blockquote>
<p>Em resumo, ap√≥s instalar, voc√™ deve editar o <code>prometheus.yml</code> para incluir todos os targets que deseja monitorar (seja listando estaticamente ou via mecanismos din√¢micos) e ajustar par√¢metros globais (intervalos, regras, reten√ß√£o).</p></blockquote>
<p>Depois reinicie o servi√ßo/container do Prometheus para aplicar as altera√ß√µes. Para validar se a sintaxe do arquivo est√° correta antes de reiniciar, podemos usar o <strong><a href="https://prometheus.io/docs/prometheus/latest/tools/promtool/">promtool</a></strong> conforme abaixo.</p>
<h2 id="promtool">Promtool</h2>
<p>O <strong>promtool</strong> √© uma ferramenta de linha de comando que acompanha o Prometheus, fornecendo utilit√°rios para verificar configura√ß√µes e depurar dados. Algumas utiliza√ß√µes comuns do promtool:</p>
<ul>
<li><strong>Checar sintaxe de configura√ß√£o:</strong> Antes de subir uma altera√ß√£o no <code>prometheus.yml</code>, rode <code>promtool check config prometheus.yml</code>. Ele apontar√° erros de sintaxe ou campos desconhecidos, ajudando a evitar falhas no start do servidor.</li>
<li><strong>Validar regras de alerta ou grava√ß√£o:</strong> Se voc√™ definiu arquivos externos de regras (YAML de alertas ou recording rules), use <code>promtool check rules minhas_regras.yml</code>. Ele analisar√° as express√µes PromQL e a formata√ß√£o.</li>
<li><strong>Testar express√£o de alerta:</strong> O promtool permite avaliar manualmente express√µes em um dado instant√¢neo ou s√©rie de tempo para ver se disparariam alerta. √ötil em CI ou para garantir que a l√≥gica est√° correta.</li>
<li><strong>Checar integridade do TSDB:</strong> Com o comando <code>promtool tsdb check /path/para/dados</code> √© poss√≠vel inspecionar o banco local de s√©ries temporais em busca de inconsist√™ncias ou corrup√ß√£o.</li>
<li><strong>Converter formatos de dados de m√©trica:</strong> H√° como transformar arquivos de m√©tricas entre formatos (por exemplo, de texto para JSON e vice-versa) usando <code>promtool convert metrics --from=txt --to=json arquivo.txt</code>.</li>
</ul>
<p>Essas s√£o apenas algumas fun√ß√µes. Em suma, o promtool √© seu amigo para garantir que o ambiente Prometheus est√° consistente e saud√°vel ‚Äì use-o sempre que fizer mudan√ßas significativas na configura√ß√£o.</p>
<h2 id="-instrumenta√ß√£o">üîç Instrumenta√ß√£o</h2>
<p>A <strong>instrumenta√ß√£o</strong> √© o processo de inserir coleta de m√©tricas em sistemas e aplica√ß√µes. No contexto Prometheus, podemos dividir em dois tipos:</p>
<h3 id="-instrumenta√ß√£o-direta-na-aplica√ß√£o">üìä Instrumenta√ß√£o direta (na aplica√ß√£o)</h3>
<p>Significa instrumentar o pr√≥prio c√≥digo da aplica√ß√£o ou servi√ßo para expor m√©tricas de neg√≥cio ou de desempenho relevantes. Voc√™ adiciona pontos de m√©trica no c√≥digo (<a href="https://prometheus.io/docs/concepts/metric_types/#counter">counters</a>, <a href="https://prometheus.io/docs/concepts/metric_types/#gauge">gauges</a>, etc.) usando uma biblioteca cliente do Prometheus. Assim, a pr√≥pria aplica√ß√£o passa a expor um endpoint <code>/metrics</code> com dados em tempo real sobre si mesma (lat√™ncia de requisi√ß√µes, uso de mem√≥ria interno, tamanho de fila, etc.). Essa abordagem d√° controle granular ‚Äì os desenvolvedores escolhem o que medir ‚Äì e tende a fornecer m√©tricas altamente espec√≠ficas e √∫teis para diagnosticar o comportamento da aplica√ß√£o.</p>
<h3 id="-instrumenta√ß√£o-indireta-via-exporters">üîÑ Instrumenta√ß√£o indireta (via exporters)</h3>
<p>Refere-se a coletar m√©tricas de sistemas externos ou legados atrav√©s de componentes intermedi√°rios chamados <strong><a href="https://prometheus.io/docs/instrumenting/exporters/">exporters</a></strong>. Em vez de modificar o sistema alvo, voc√™ roda um exporter que coleta informa√ß√µes daquele sistema (geralmente via APIs existentes, comandos ou leitura de arquivos) e as exp√µe no formato Prometheus. O Prometheus ent√£o faz scrape nesse exporter. Essa abordagem √© comum para: sistemas operacionais, bancos de dados, servidores web, ou qualquer software que n√£o tenha suporte nativo ao Prometheus. Por exemplo, h√° exporters para <strong><a href="https://github.com/prometheus/mysqld_exporter">MySQL</a></strong>, <strong><a href="https://github.com/prometheus/postgres_exporter">PostgreSQL</a></strong>, <strong><a href="https://github.com/nginxinc/nginx-prometheus-exporter">Apache/Nginx</a></strong>, <strong><a href="https://github.com/oliver006/redis_exporter">Redis</a></strong>, entre muitos outros, que traduzem m√©tricas desses sistemas para o formato esperado.</p>
<p>Ambos os tipos s√£o importantes. A instrumenta√ß√£o direta fornece m√©tricas sob medida da aplica√ß√£o (por exemplo, quantas transa√ß√µes processou, quantos usu√°rios ativos, etc.), enquanto a indireta garante visibilidade de componentes de infraestrutura e softwares de terceiros sem precisar alterar eles. A seguir, veremos exemplos de instrumenta√ß√£o indireta (principais exporters) e de instrumenta√ß√£o direta em algumas linguagens.</p>
<h3 id="instrumenta√ß√£o-indireta-exporters">Instrumenta√ß√£o indireta: Exporters</h3>
<p><strong>Ecossistema nativo:</strong> O Prometheus j√° oferece diversos exporters oficiais ou mantidos pela comunidade para sistemas populares. Alguns exemplos:</p>
<ul>
<li>
<p><strong><a href="https://github.com/prometheus/node_exporter">Node Exporter</a></strong> (Linux): Coleta m√©tricas de sistema operacional Linux ‚Äì CPU, mem√≥ria, disco, rede, entropia, stats de kernel, etc. √â imprescind√≠vel para monitorar VMs ou servidores bare metal. Basta executar o bin√°rio do node_exporter no host; ele abre :9100/metrics com dezenas de m√©tricas padronizadas (cpu_seconds_total, node_filesystem_usage_bytes, etc.). Essas m√©tricas d√£o uma visibilidade completa do estado do host, permitindo identificar gargalos de recurso.</p>
</li>
<li>
<p><strong><a href="https://github.com/prometheus/wmic_exporter">Windows Exporter</a></strong> (Windows): Equivalente para plataformas Windows (antigo WMI exporter). Coleta CPU, mem√≥ria, disco, contadores do Windows, etc., expondo em :9182/metrics (porta padr√£o). Assim, ambiente heterog√™neos tamb√©m podem ser monitorados.</p>
</li>
<li>
<p><strong><a href="https://github.com/prometheus/blackbox_exporter">Blackbox Exporter</a></strong>: √ötil para monitorar <em>externamente</em> a disponibilidade de servi√ßos. Ele executa <em>probes</em> do tipo ICMP (ping), HTTP(S), DNS, TCP, etc., simulando a experi√™ncia do usu√°rio externo. Voc√™ configura m√≥dulos de probe (ex: checar HTTP 200 em determinada URL dentro de 2s) e o Prometheus chama o Blackbox passando o alvo a testar. Se a resposta falha ou excede tempo, m√©tricas como <code>probe_success</code>=0 ou <code>probe_duration_seconds</code> indicam problema. √â excelente para monitorar uptime de sites e endpoints de fora para dentro.</p>
</li>
<li>
<p><strong><a href="https://prometheus.io/docs/instrumenting/exporters/">Exporters de aplica√ß√µes</a></strong>: H√° muitos: PostgreSQL exporter, Redis exporter, JMX exporter (Java), SNMP exporter (equipamentos de rede), etc. Em geral, se voc√™ usar alguma tecnologia popular, provavelmente j√° existe um exporter pronto (a documenta√ß√£o oficial lista dezenas: <strong><a href="https://prometheus.io/docs/instrumenting/exporters/">Exporters e integra√ß√µes</a></strong>).</p>
</li>
</ul>
<blockquote>
<p><strong>Como usar exporters?</strong> Normalmente √© executar o bin√°rio do exporter pr√≥ximo do servi√ßo alvo, e ent√£o adicionar um job no <code>prometheus.yml</code> apontando para o endpoint do exporter. Por exemplo, para Node Exporter em v√°rias m√°quinas, voc√™ rodaria node_exporter em cada host (porta 9100) e adicionaria algo como:</p></blockquote>


  <pre><code class="language-yaml">scrape_configs:
  - job_name: &#39;node&#39;
    static_configs:
      - targets: [&#39;host1:9100&#39;, &#39;host2:9100&#39;, ...]</code></pre>
 <p>Assim o Prometheus coletar√° as m√©tricas de cada m√°quina. Cada m√©trica vir√° automaticamente com labels como <code>instance=&quot;host1:9100&quot;</code> e outras espec√≠ficas (o Node Exporter adiciona label <code>job=&quot;node&quot;</code> e por vezes labels como <code>cpu=&quot;0&quot;</code> para m√©tricas por CPU, etc.).</p>
<blockquote>
<p>Em resumo, a instrumenta√ß√£o indireta via exporters √© fundamental para trazer para o Prometheus dados de componentes que n√£o exp√µem nativamente as m√©tricas. √â um jeito de <em>bridge</em> (ponte) entre sistemas legados e o moderno mundo do Prometheus.</p></blockquote>
<h3 id="instrumenta√ß√£o-direta-exemplos-por-linguagem">Instrumenta√ß√£o direta: exemplos por linguagem</h3>
<p>Agora vejamos como instrumentar aplica√ß√µes escritas em algumas linguagens populares. A ideia geral em qualquer linguagem √©: instalar a biblioteca cliente do Prometheus, criar m√©tricas (<a href="https://prometheus.io/docs/concepts/metric_types/#counter">counters</a>, <a href="https://prometheus.io/docs/concepts/metric_types/#gauge">gauges</a>, etc.) em pontos estrat√©gicos do c√≥digo, e expor um endpoint HTTP <code>/metrics</code> onde essas m√©tricas s√£o servidas (em formato de texto). O Prometheus ent√£o coleta nesse endpoint.</p>
<h4 id="java-micrometer--cliente-java-do-prometheus">Java (Micrometer / Cliente Java do Prometheus)</h4>
<p>Em Java, uma abordagem comum √© usar o <strong><a href="https://micrometer.io/">Micrometer</a></strong> ‚Äì uma biblioteca de instrumenta√ß√£o que suporta m√∫ltiplos backends (Prometheus, Graphite, etc.). O Micrometer foi adotado pelo Spring Boot, por exemplo, facilitando a exposi√ß√£o de m√©tricas. Passos b√°sicos:</p>
<ol>
<li>
<p><strong>Depend√™ncias:</strong> Adicione ao seu projeto (pom.xml ou build.gradle) a depend√™ncia do Micrometer e do registry Prometheus. Exemplo (Maven):</p>


  <pre><code class="language-xml">&lt;dependency&gt;
    &lt;groupId&gt;io.micrometer&lt;/groupId&gt;
    &lt;artifactId&gt;micrometer-core&lt;/artifactId&gt;
    &lt;version&gt;1.10.4&lt;/version&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
    &lt;groupId&gt;io.micrometer&lt;/groupId&gt;
    &lt;artifactId&gt;micrometer-registry-prometheus&lt;/artifactId&gt;
    &lt;version&gt;1.10.4&lt;/version&gt;
&lt;/dependency&gt;</code></pre>
 </li>
<li>
<p><strong>Registrar m√©tricas:</strong> Em sua aplica√ß√£o, configure um <code>MeterRegistry</code> do Prometheus e registre m√©tricas. Por exemplo, em uma classe de configura√ß√£o Spring:</p>


  <pre><code class="language-java">@Bean
PrometheusMeterRegistry prometheusRegistry() {
    return new PrometheusMeterRegistry(PrometheusConfig.DEFAULT);
}</code></pre>
 <p>Voc√™ pode ent√£o criar contadores, gauges, etc. usando esse registry:</p>


  <pre><code class="language-java">Counter requestCount = Counter.builder(&#34;myapp_requests_total&#34;)
                              .description(&#34;Total de requisi√ß√µes&#34;)
                              .register(prometheusRegistry());
// Usar requestCount.inc(); em pontos apropriados do c√≥digo</code></pre>
 <p>Ou usar anota√ß√µes/filtros prontos do Spring Boot Actuator que medem tempos de resposta automaticamente.</p>
</li>
<li>
<p><strong>Expor endpoint /metrics:</strong> Se estiver usando Spring Boot Actuator, habilite a endpoint Prometheus. No application.properties:</p>


  <pre><code class="language-">management.endpoints.web.exposure.include=prometheus
management.endpoint.prometheus.enabled=true</code></pre>
 <p>Isso far√° o Actuator expor <code>/actuator/prometheus</code> com as m√©tricas no formato Prometheus. O Prometheus pode ent√£o fazer scrape nessa URL. (Alternativamente, sem Spring, voc√™ poderia iniciar um HTTP server manualmente que responda com <code>prometheusRegistry.scrape()</code> output).</p>
</li>
<li>
<p><strong>Verificar m√©tricas:</strong> Ao rodar a aplica√ß√£o, acesse <a href="http://localhost:8080/actuator/prometheus">http://localhost:8080/actuator/prometheus</a> (por exemplo) e voc√™ ver√° todas as m√©tricas registradas, inclusive padr√µes do JVM (o Micrometer j√° fornece m√©tricas de mem√≥ria, CPU, GC, etc. por padr√£o) e as personalizadas que voc√™ adicionou.</p>
</li>
</ol>
<blockquote>
<p>Em resumo, no Java/Spring o processo pode ser muito simples aproveitando frameworks existentes. Para outras aplica√ß√µes Java sem Spring, existe tamb√©m o cliente Java do Prometheus (simpleclient) onde voc√™ manualmente gerencia as m√©tricas e HTTP endpoint.</p></blockquote>
<h4 id="javascriptnodejs">JavaScript/Node.js</h4>
<p>No Node.js podemos usar o pacote <strong>prom-client</strong> para instrumenta√ß√£o:</p>
<ol>
<li>
<p><strong>Instalar pacote:</strong> <code>npm install prom-client</code>.</p>
</li>
<li>
<p><strong>Criar m√©tricas no c√≥digo:</strong> Por exemplo, vamos medir o tempo de resposta de uma rota Express:</p>


  <pre><code class="language-js">const express = require(&#39;express&#39;);
const promClient = require(&#39;prom-client&#39;);
const app = express();

// Cria um histogram para tempos de resposta em segundos
const httpResponseHist = new promClient.Histogram({
  name: &#39;myapp_http_response_duration_seconds&#39;,
  help: &#39;Tempo de resposta das requisi√ß√µes HTTP (segundos)&#39;,
  labelNames: [&#39;route&#39;, &#39;method&#39;]
});</code></pre>
 <p>Aqui usamos um Histogram (poderia ser Summary tamb√©m). Antes de enviar a resposta na rota, registramos a observa√ß√£o:</p>


  <pre><code class="language-js">app.get(&#39;/example&#39;, (req, res) =&gt; {
  const end = httpResponseHist.startTimer({ route: &#39;/example&#39;, method: &#39;GET&#39; });
  // ... l√≥gica da rota ...
  res.send(&#34;Hello World&#34;);
  end(); // marca o fim do timer e observa a dura√ß√£o no histogram
});</code></pre>
 <p>O <em>prom-client</em> possui m√©todos convenientes para medir dura√ß√£o com <code>Histogram.startTimer()</code> que retorna uma fun√ß√£o para encerrar e registrar.</p>
</li>
<li>
<p><strong>Expor as m√©tricas:</strong> Precisamos servir as m√©tricas via HTTP para o Prometheus. Podemos criar um endpoint <code>/metrics</code>:</p>


  <pre><code class="language-js">app.get(&#39;/metrics&#39;, async (req, res) =&gt; {
  res.set(&#39;Content-Type&#39;, promClient.register.contentType);
  res.end(await promClient.register.metrics());
});</code></pre>
 <p>Isso coleta todas as m√©tricas registradas e retorna no formato de texto padr√£o.</p>
</li>
<li>
<p><strong>Iniciar server:</strong> Por fim, inicie seu servidor Node (por ex, <code>app.listen(3000)</code>). Ent√£o a URL <a href="http://localhost:3000/metrics">http://localhost:3000/metrics</a> mostrar√° as m√©tricas.</p>
</li>
<li>
<p><strong>Configurar Prometheus:</strong> Adicione no <code>prometheus.yml</code> um job apontando para o servi√ßo Node, porta 3000 (ou a porta usada) e path <code>/metrics</code>. Exemplo:</p>


  <pre><code class="language-yaml">scrape_configs:
  - job_name: &#39;my-nodeapp&#39;
    static_configs:
      - targets: [&#39;my-node-host:3000&#39;]</code></pre>
 <p>(Se o Node est√° no mesmo Docker Compose do Prometheus, pode usar o nome de servi√ßo do container e porta.)</p>
</li>
</ol>
<p>A partir da√≠, o Prometheus coletar√° as m√©tricas do seu app Node. Voc√™ poder√° consultar coisas como <code>rate(myapp_http_response_duration_seconds_count[5m])</code> ou <code>histogram_quantile(0.9, rate(myapp_http_response_duration_seconds_bucket[5m]))</code> para ver percentis de lat√™ncia.</p>
<h4 id="python-flask-etc">Python (Flask, etc.)</h4>
<p>Em Python, h√° o pacote <strong>prometheus_client</strong>. Exemplo integrando com Flask:</p>
<ol>
<li>
<p><strong>Instala√ß√£o:</strong> <code>pip install prometheus_client</code>.</p>
</li>
<li>
<p><strong>Cria√ß√£o de m√©tricas:</strong> Digamos que queremos contar requisi√ß√µes e medir dura√ß√£o. Podemos usar um Histogram ou Summary. Aqui um Summary:</p>


  <pre><code class="language-python">from flask import Flask, request
from prometheus_client import Summary, Counter, start_http_server

app = Flask(__name__)
REQUEST_TIME = Summary(&#39;myapp_request_processing_seconds&#39;, &#39;Tempo de processamento por rota&#39;, [&#39;endpoint&#39;])
REQUEST_COUNT = Counter(&#39;myapp_requests_total&#39;, &#39;Total de requisi√ß√µes&#39;, [&#39;endpoint&#39;, &#39;http_status&#39;])</code></pre>
 <p>Decoramos a rota para coletar m√©tricas:</p>


  <pre><code class="language-python">@app.route(&#34;/example&#34;)
def example():
    with REQUEST_TIME.labels(endpoint=&#34;/example&#34;).time():  # inicia timer autom√°tico
        # ... l√≥gica do endpoint ...
        response = &#34;Hello World&#34;
    REQUEST_COUNT.labels(endpoint=&#34;/example&#34;, http_status=200).inc()
    return response</code></pre>
 <p>O <code>Summary.time()</code> funciona como context manager medindo o tempo dentro do bloco. Tamb√©m incrementamos um counter de requests totais por endpoint e status.</p>
</li>
<li>
<p><strong>Expor m√©tricas:</strong> Podemos fazer de duas formas ‚Äì ou usamos o servidor HTTP interno do prometheus_client ou integramos com Flask. Uma maneira simples: iniciar um <em>thread</em> do servidor metrics separado:</p>


  <pre><code class="language-python">if __name__ == &#34;__main__&#34;:
    start_http_server(8000)  # inicia servidor em porta 8000
    app.run(host=&#34;0.0.0.0&#34;, port=5000)</code></pre>
 <p>O <code>start_http_server(8000)</code> far√° com que em <a href="http://localhost:8000/metrics">http://localhost:8000/metrics</a> tenhamos as m√©tricas (note: ele por default exp√µe em /metrics automaticamente). Nesse caso, o Prometheus deve apontar para porta 8000 do app. Alternativamente, h√° integra√ß√£o para Flask (via middleware) que poderia expor /metrics no pr√≥prio Flask app.</p>
</li>
<li>
<p><strong>Prometheus config:</strong> Similar aos anteriores, adicionar job apontando para o endpoint do metrics (host e porta usados).</p>
</li>
</ol>
<p>Ap√≥s esses passos, seu app Python estar√° fornecendo m√©tricas. Voc√™ pode conferir acessando <a href="http://localhost:8000/metrics">http://localhost:8000/metrics</a> e vendo as s√©ries nomeadas <code>myapp_request_processing_seconds_*</code> e <code>myapp_requests_total</code> entre outras (o client lib Python tamb√©m exp√µe m√©tricas padr√£o do processo Python como uso de mem√≥ria do processo, CPU, etc.).</p>
<h3 id="ferramentas-legadas-e-fechadas">Ferramentas legadas e fechadas</h3>
<p>Uma dificuldade comum √© monitorar sistemas legados ou softwares propriet√°rios que n√£o oferecem m√©tricas no formato Prometheus. Nesses casos, h√° alguns padr√µes de solu√ß√£o:</p>
<ul>
<li>
<p><strong><a href="https://prometheus.io/docs/instrumenting/exporters/">Exporters externos</a></strong>: Como j√° mencionado, se existir um exporter compat√≠vel (oficial ou da comunidade) para aquela ferramenta, ele √© o caminho mais f√°cil ‚Äì rodar o exporter e configur√°-lo como alvo. Por exemplo, para monitorar um servidor Oracle propriet√°rio, pode haver um exporter que conecta no Oracle e extrai estat√≠sticas via queries.</p>
</li>
<li>
<p><strong><a href="https://prometheus.io/docs/instrumenting/writing_exporters/#writing-a-bridge-exporter">Bridges personalizadas</a>:</strong> Caso n√£o exista um exporter pronto, podemos criar um processo intermedi√°rio (<em>bridge</em>) que consulta a ferramenta legada de alguma forma (API REST, CLI, leitura de arquivos de log) e exp√µe resultados em /metrics. Essencialmente, isso √© escrever um pequeno exporter sob medida. Ferramentas de script como Python facilitam isso ‚Äì voc√™ coleta os dados e usa <code>prometheus_client</code> para expor.</p>
</li>
<li>
<p><strong><a href="https://prometheus.io/docs/instrumenting/writing_exporters/#writing-a-bridge-exporter">Integra√ß√µes via gateway ou plugins</a>:</strong> Alguns ambientes possuem hooks para m√©tricas. Por exemplo, aplica√ß√µes .NET legadas podem exportar contadores no Windows Performance Counters ‚Äì a√≠ usar o Windows Exporter para peg√°-los. Em casos extremos, voc√™ pode usar o Pushgateway como ponte: o sistema legado faz push de alguma m√©trica b√°sica para o gateway (n√£o ideal, mas poss√≠vel).</p>
</li>
</ul>
<blockquote>
<p>Em resumo, <strong>sempre</strong> √© poss√≠vel integrar algo ao Prometheus, ainda que indiretamente. A comunidade j√° produziu exporters para muitos sistemas fechados (WebLogic, SAP, etc.). E como √∫ltimo recurso, extrair dados e expor manualmente n√£o √© t√£o complexo gra√ßas √†s bibliotecas cliente dispon√≠veis.</p></blockquote>
<h2 id="alertmanager">Alertmanager</h2>
<p>O <strong><a href="https://prometheus.io/docs/alerting/latest/alertmanager/">Alertmanager</a></strong> complementa o Prometheus no tratamento de alertas. Enquanto o Prometheus detecta condi√ß√µes de alerta (com base nas m√©tricas e regras definidas), ele delega ao Alertmanager a fun√ß√£o de envio de notifica√ß√µes e gerenciamento desses alertas. Isso inclui agregar alertas similares, evitar duplica√ß√µes, silenciar alertas durante manuten√ß√£o, e encaminh√°-los para canais apropriados (e-mail, sistemas de chat, PagerDuty, etc.).</p>
<p>Como funciona: voc√™ define no Prometheus regras de alerta (no arquivo de configura√ß√£o ou separado) com express√µes PromQL que identificam situa√ß√µes problem√°ticas. Por exemplo: &ldquo;se a m√©trica <code>up</code> de um servidor for 0 por 5 minutos, dispare alerta&rdquo;. Quando a condi√ß√£o √© verdadeira, o Prometheus gera um evento de alerta e o envia para o Alertmanager (que est√° configurado na se√ß√£o <code>alerting</code> do prometheus.yml). O Alertmanager ent√£o aplica suas pr√≥prias regras de roteamento: por exemplo, enviar alertas de severidade cr√≠tica para um webhook do Slack e para email da equipe X, alertas menos graves s√≥ para email, etc&hellip;</p>
<p><strong>Exemplo pr√°tico:</strong> Vamos configurar um alerta de servidor fora do ar com notifica√ß√£o no Slack.</p>
<ol>
<li><strong>Definir regra de alerta (Prometheus):</strong> Crie um arquivo <code>alert.rules.yml</code>:</li>
</ol>


  <pre><code class="language-yaml">groups:
- name: instance_down
  rules:
    - alert: InstanceDown
      expr: up == 0
      for: 1m
      labels:
        severity: critical
      annotations:
        summary: &#34;Inst√¢ncia {{ $labels.instance }} fora do ar&#34;
        description: &#34;O alvo {{ $labels.instance }} n√£o respondeu √†s coletas por mais de 1 minuto.&#34;</code></pre>
 <p>Essa regra verifica a m√©trica <code>up</code> de todos os alvos; se qualquer um estiver com valor 0 (significa alvo inacess√≠vel) por 1 minuto cont√≠nuo, aciona o alerta <strong>InstanceDown</strong> com severidade <strong>critical</strong>. As anota√ß√µes fornecem um resumo e descri√ß√£o usando templating (inserindo o label instance do alvo problem√°tico).</p>
<ol start="2">
<li><strong>Incluir regra e Alertmanager na config do Prometheus:</strong> No <code>prometheus.yml</code>, adicionar:</li>
</ol>


  <pre><code class="language-yaml">rule_files:
  - &#34;alert.rules.yml&#34;

alerting:
  alertmanagers:
    - static_configs:
        - targets: [&#39;alertmanager:9093&#39;]</code></pre>
 <p>Aqui presumimos que o Alertmanager est√° rodando e acess√≠vel no endere√ßo <code>alertmanager:9093</code> (no Docker Compose, por ex.). O Prometheus agora carrega as regras de alerta e sabe para onde enviar notifica√ß√µes.</p>
<ol start="3">
<li><strong>Configurar o Alertmanager (alertmanager.yml):</strong> Exemplo m√≠nimo para Slack:</li>
</ol>


  <pre><code class="language-yaml">route:
  group_by: [&#39;alertname&#39;]
  receiver: &#39;time-slack&#39;
receivers:
  - name: &#39;time-slack&#39;
    slack_configs:
      - api_url: &#39;https://hooks.slack.com/services/T000/B000/XXXXX&#39;  # Webhook do Slack
        channel: &#39;#alerts&#39;
        send_resolved: true
        title: &#34;{{ range .Alerts }}{{ .Annotations.summary }}{{ end }}&#34;
        text: &#34;{{ range .Alerts }}{{ .Annotations.description }}{{ end }}&#34;</code></pre>
 <p>Esse config muito b√°sico diz: todos alertas (n√£o importa o grupo_by, etc.) ir√£o para o receptor nomeado &rsquo;time-slack&rsquo;, que tem um slack_config apontando para um webhook do Slack no canal <strong>#alerts</strong>. O <code>title</code> e <code>text</code> da mensagem aproveitam as anota√ß√µes definidas na regra (summary e description). <code>send_resolved: true</code> indica para notificar tamb√©m quando o alerta for resolvido.</p>
<p>Em produ√ß√£o, o Alertmanager pode ter rotas mais elaboradas ‚Äì por exemplo, roteando com base em labels de alerta (team=A vai para equipe A, severidade critical pode mandar SMS, etc.), escalonamento, agrupamento por determinados campos (como agrupar todos alertas do mesmo datacenter numa s√≥ notifica√ß√£o), etc.</p>
<ol start="4">
<li><strong>Executar e testar:</strong> Rode o Alertmanager com esse config (no Docker ou bin√°rio). Quando um alerta InstanceDown ocorrer, o Prometheus vai enviar para o Alertmanager, que em seguida usar√° a integra√ß√£o <a href="https://prometheus.io/docs/alerting/latest/configuration/#slack-receiver">Slack</a> para postar no canal configurado uma mensagem com t√≠tulo &ldquo;Inst√¢ncia X fora do ar&rdquo; e descri√ß√£o com detalhes.</li>
</ol>
<p>Esse foi um exemplo focado em Slack, mas o Alertmanager suporta muitos outros <strong>receivers</strong>: e-mail (SMTP), PagerDuty, OpsGenie, VictorOps, Webhooks gen√©ricos, entre outros. Com ele, voc√™ ganha flexibilidade para gerenciar o &ldquo;barulho&rdquo; de alertas: por exemplo, suprimir alertas filhos quando um pai j√° ocorreu (<a href="https://prometheus.io/docs/alerting/latest/configuration/#inhibition">inhibition</a>), ou silenciar certos alertas durante janelas de manuten√ß√£o planejada.</p>
<blockquote>
<p><strong>Observa√ß√£o:</strong> O Alertmanager n√£o √© obrigat√≥rio ‚Äì voc√™ pode rodar o Prometheus sem ele se n√£o precisar de notifica√ß√µes externas. Por√©m, para qualquer ambiente de produ√ß√£o, √© altamente recomendado configur√°-lo para n√£o depender de ficar olhando a p√°gina /alerts manualmente. Em outro artigo abordaremos em detalhes boas pr√°ticas de configura√ß√£o do Alertmanager.</p></blockquote>
<h2 id="pushgateway">PushGateway</h2>
<p>O <strong><a href="https://prometheus.io/docs/instrumenting/pushing/">Pushgateway</a></strong> √© um componente auxiliar do ecossistema Prometheus que permite coletar m√©tricas via modelo <em>push</em> em situa√ß√µes espec√≠ficas. A ideia √© que certos jobs ou aplicativos ef√™meros, que n√£o t√™m como serem raspados diretamente (por exemplo, um script cron que executa e termina rapidamente), possam empurrar suas m√©tricas para um gateway intermedi√°rio. O Prometheus ent√£o coleta essas m√©tricas do Pushgateway posteriormente.</p>
<p>Funciona assim: o job de curta dura√ß√£o (ou qualquer processo que n√£o viva tempo suficiente para ser raspado) envia um HTTP POST para o Pushgateway com suas m√©tricas no formato Prometheus. O Pushgateway armazena essas m√©tricas em mem√≥ria e as exp√µe em seu pr√≥prio <code>/metrics</code>. O Prometheus configura um scrape no Pushgateway, coletando tudo que estiver l√°.</p>
<p><strong>Por√©m,</strong> √© importante entender que o Pushgateway deve ser usado com modera√ß√£o e prop√≥sito claro. Ele n√£o √© um agente gen√©rico para substituir o modelo pull. Alguns pontos de aten√ß√£o destacados pela documenta√ß√£o oficial:</p>
<ul>
<li>Se m√∫ltiplas inst√¢ncias usam um mesmo Pushgateway, ele vira um ponto central de falha e potencial gargalo.</li>
<li>Voc√™ perde a detec√ß√£o autom√°tica de <em>down</em> (j√° que as m√©tricas s√£o push, o Prometheus n√£o sabe se um job n√£o est√° rodando ou s√≥ n√£o teve m√©tricas recentes).</li>
<li>O Pushgateway <strong>n√£o expira</strong> automaticamente s√©ries que foram enviadas. Uma vez que uma m√©trica √© empurrada, ela ficar√° l√° at√© ser sobrescrita ou manualmente apagada via API do Pushgateway. Isso significa que m√©tricas de jobs antigos podem ficar persistindo como &ldquo;fantasmas&rdquo;, exigindo que voc√™ gerencie remo√ß√£o ou inclus√£o de algum label de <em>instance</em> para distingui-las.</li>
</ul>
<p>Devido a esses aspectos, o uso recomendado do Pushgateway √© <strong>capturar resultados de jobs batch de n√≠vel de servi√ßo</strong> ‚Äì isto √©, trabalhos que n√£o pertencem a uma √∫nica m√°quina ou inst√¢ncia espec√≠fica, mas sim algo como &ldquo;um script de limpeza de banco que roda uma vez por dia&rdquo;. Nesse caso, o job emite (push) uma m√©trica do tipo &ldquo;usuarios_deletados_total{job=&ldquo;cleanup&rdquo;} 123&rdquo; e termina. O Pushgateway guarda esse valor. O Prometheus, ao raspar, ter√° essa informa√ß√£o agregada do job. Como esse tipo de job n√£o tem um &ldquo;endpoint&rdquo; pr√≥prio para scrap, o Pushgateway serve como cache.</p>
<p>Para outros cen√°rios, onde o push √© considerado porque h√° firewall/NAT impedindo scrapes, a documenta√ß√£o sugere alternativas melhores ‚Äì como rodar Prometheus perto dos alvos (dentro da rede) ou usar algo como o <strong><a href="https://github.com/prometheus/pushprox">PushProx</a></strong> para atravessar firewalls mantendo o modelo pull. E para jobs cron por m√°quina, que t√™m contexto de host, recomenda-se usar o <strong><a href="https://github.com/prometheus/node_exporter#textfile-collector">Node Exporter Textfile Collector</a></strong> (escrever m√©tricas em um arquivo que o Node Exporter l√™), ao inv√©s do Pushgateway.</p>
<blockquote>
<p>Resumindo: o Pushgateway √© √∫til, mas <strong>somente</strong> em casos espec√≠ficos. Evite us√°-lo para coletar m√©tricas de servi√ßos normais (isso seria ‚Äúusar push por pregui√ßa‚Äù, e acarretaria problemas de dados stale e falta de detec√ß√£o de falha). Use-o para jobs batch pontuais, e mesmo assim, sem abusar ‚Äì lembre-se de limpar m√©tricas antigas se necess√°rio, ou projetar os labels de modo que cada job substitua seu pr√≥prio valor sem acumular lixo.</p></blockquote>
<h2 id="federa√ß√£o">Federa√ß√£o</h2>
<p>A <strong>federa√ß√£o</strong> no Prometheus permite que uma inst√¢ncia do Prometheus (geralmente chamada de <strong>federadora</strong> ou <strong>global</strong>) fa√ßa scrape em endpoints de outras inst√¢ncias do Prometheus (<strong>federadas</strong>) para obter um subconjunto de suas m√©tricas. Em outras palavras, √© uma forma de <strong>hierarquizar</strong> o monitoramento: por exemplo, voc√™ pode ter um Prometheus por data center coletando tudo localmente, e um Prometheus global que apenas busca m√©tricas j√° agregadas de cada data center para ter uma vis√£o geral corporativa. Existem dois casos de uso principais para federa√ß√£o:</p>
<ol>
<li>
<p><strong><a href="https://prometheus.io/docs/prometheus/latest/federation/">Agrega√ß√£o hier√°rquica</a></strong>: como no exemplo acima, onde cada Prometheus local faz o trabalho pesado e calcula agregados (soma de CPU por datacenter, lat√™ncia m√©dia de servi√ßo X por datacenter, etc.), e o Prometheus global s√≥ extrai essas s√©ries agregadas prontas. Isso d√° uma vis√£o do todo sem sobrecarregar a inst√¢ncia global com todas as s√©ries detalhadas.</p>
</li>
<li>
<p><strong><a href="https://prometheus.io/docs/prometheus/latest/federation/">Checagens cruzadas ou seletivas</a></strong>: Puxar algumas poucas m√©tricas de outra inst√¢ncia para compara√ß√µes. Exemplo: voc√™ tem um Prometheus dedicado a HAProxy e outro para um app front-end, pode federar a m√©trica de QPS do HAProxy no Prometheus do front-end para checar se ambos observam o mesmo tr√°fego. Normalmente, isso √© usado at√© mesmo apenas para alertas (voc√™ pode configurar alertas usando essas poucas m√©tricas federadas).</p>
</li>
</ol>
<p><strong><a href="https://prometheus.io/docs/prometheus/latest/federation/#when-not-to-use-federation">Quando N√ÉO usar federa√ß√£o</a>:</strong> a tenta√ß√£o de federar tudo de todos os Prometheus em um ‚Äúsuper Prometheus‚Äù central deve ser evitada. Pegar todas as s√©ries de inst√¢ncias filhas e centralizar em uma s√≥ inst√¢ncia global traz v√°rios problemas:</p>
<ul>
<li><strong>Escalabilidade limitada:</strong> O desempenho do Prometheus √© limitado pelos recursos de um √∫nico n√≥ (n√£o escala horizontalmente). Se voc√™ puxa tudo para um s√≥ servidor global, no fim do dia voc√™ est√° limitado ao throughput e mem√≥ria de uma m√°quina. Isso anula a distribui√ß√£o de carga que m√∫ltiplas inst√¢ncias proporcionam.</li>
<li><strong>Performance e carga duplicada:</strong> Al√©m de sobrecarregar a inst√¢ncia global ao ter que armazenar e consultar tudo, a pr√≥pria opera√ß√£o de federa√ß√£o (expor /federate e responder a scraping) gera carga nas inst√¢ncias filhas. Se a consulta federada n√£o for focada (usar express√µes match[] gen√©ricas demais), pode consumir muitos recursos para as inst√¢ncias fonte servirem esses dados.</li>
<li><strong>Confiabilidade reduzida:</strong> Voc√™ adiciona um ponto extra de falha. Se o link entre uma inst√¢ncia local e a global cair, a inst√¢ncia global ‚Äúfica cega‚Äù √†quele segmento. E pior, se voc√™ centralizou a avalia√ß√£o de certos alertas s√≥ no global, pode ficar sem alertas (falso negativo) caso o global perca conex√£o com os locais. A recomenda√ß√£o de especialistas √© sempre que poss√≠vel avaliar alertas o mais localmente poss√≠vel ‚Äì por exemplo, um alerta ‚Äúservi√ßo X caiu‚Äù deve ser definido no Prometheus que coleta servi√ßo X, n√£o em um global distante, exatamente para n√£o depender de rede.</li>
<li><strong>Delay e poss√≠veis inconsist√™ncias:</strong> A federa√ß√£o n√£o √© instant√¢nea; h√° lat√™ncia entre um dado ser coletado no Prometheus filho e ser federado pelo pai. Al√©m disso, condi√ß√µes de corrida podem fazer o global perder algumas amostras ou ver valores ligeiramente diferentes (por exemplo, contadores que resetaram podem parecer estranhos). Para uns poucos agregados isso √© toler√°vel, mas se voc√™ federar tudo e depender disso para alertar, pode ter sutilezas indesejadas.</li>
<li><strong>Complexidade de configura√ß√£o e seguran√ßa:</strong> √â mais complexo gerenciar dois n√≠veis de Prometheus, com configura√ß√µes de match[], externas labels √∫nicas por inst√¢ncia, etc. Tamb√©m √© necess√°rio expor o endpoint /federate das inst√¢ncias filhas ‚Äì o que pode ampliar a superf√≠cie de ataque ou requerer configura√ß√µes TLS, autentica√ß√£o, caso atravesse redes n√£o confi√°veis.</li>
</ul>
<p>Em raz√£o desses fatores, a federa√ß√£o deve ser usada <strong>apenas</strong> para casos de uso bem planejados (tipicamente agrega√ß√µes de baixo volume ou m√©tricas espec√≠ficas). N√£o √© a solu√ß√£o adequada para reten√ß√£o de longo prazo nem para alta disponibilidade.</p>
<blockquote>
<p><strong>NOTA:</strong> Para necessidades de <strong>escalabilidade horizontal</strong> e <strong>armazenamento de longo prazo</strong>, surgiram outros projetos que complementam o Prometheus, como <strong>Thanos</strong>, <strong>Cortex</strong> e <strong>Mimir</strong> (Grafana Labs). Essas solu√ß√µes armazenam as s√©ries em storage distribu√≠do (objeto, bigtable, etc.) e permitem ‚Äújuntar‚Äù m√∫ltiplas inst√¢ncias como se fossem uma s√≥, suportando consultas globais e reten√ß√£o virtualmente infinita. Exploraremos essas alternativas em outro artigo, mas adianta-se que elas resolvem muitos dos problemas de tentar usar federa√ß√£o pura para esses fins.</p></blockquote>
<h2 id="under-the-hood">Under the Hood</h2>
<p>Nesta se√ß√£o, vamos dissecar o funcionamento interno do armazenamento de dados do Prometheus ‚Äì o <strong><a href="https://prometheus.io/docs/introduction/architecture/#time-series-database">Time Series Database</a></strong> (TSDB) local ‚Äì e entender por que ele consome recursos como consome.</p>
<p>Quando instalamos o Prometheus, uma pasta de dados (por padr√£o chamada <code>data/</code>) √© usada para persistir as s√©ries temporais coletadas. Dentro dela, os dados s√£o organizados em blocos de tempo fixo. Por padr√£o, cada <strong>bloco</strong> cobre 2 horas de m√©tricas. Ap√≥s duas horas de coleta, o Prometheus fecha aquele bloco e inicia outro. Periodicamente, v√°rios blocos menores podem ser compactados em blocos maiores (por exemplo, 5 blocos de 2h podem ser mesclados num bloco de 10h de dados, e assim por diante). A estrutura de arquivos t√≠pica em <code>data/</code> √© assim (exemplo simplificado):</p>


  <pre><code class="language-">data/
‚îú‚îÄ‚îÄ 01GZY5ABCD.../       # pasta de um bloco de dados
‚îÇ   ‚îú‚îÄ‚îÄ meta.json        # metadados do bloco
‚îÇ   ‚îú‚îÄ‚îÄ index            # √≠ndice para busca das s√©ries no bloco
‚îÇ   ‚îú‚îÄ‚îÄ chunks/          # peda√ßos contendo os samples comprimidos
‚îÇ   ‚îî‚îÄ‚îÄ tombstones       # (pode estar vazio) marca√ß√µes de dele√ß√£o
‚îú‚îÄ‚îÄ 01GZY1WXYZ.../       # outro bloco (mais antigo, por ex)
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ chunks_head/         # chunks do bloco &#34;head&#34; atual (em uso)
‚îî‚îÄ‚îÄ wal/                 # Write-Ahead Log (log de escrita recente)
    ‚îú‚îÄ‚îÄ 00000000
    ‚îú‚îÄ‚îÄ 00000001
    ‚îî‚îÄ‚îÄ checkpoint.000001/ ...</code></pre>
 <p>Cada bloco de 2h √© identificado por um <strong><a href="https://github.com/prometheus/prometheus/blob/main/tsdb/encoding/ulid.go">ULID</a></strong> (ID √∫nico lexicograficamente orden√°vel) que comp√µe o nome da pasta. Dentro de um bloco, temos:</p>
<ul>
<li><strong>meta.json:</strong> arquivo JSON com metadados do bloco (faixa de tempo coberta, stats de quantas s√©ries/amostras cont√©m, hist√≥rico de compacta√ß√£o, etc.).</li>
<li><strong>index:</strong> arquivo de √≠ndice invertido para permitir procurar s√©ries rapidamente pelo nome e labels, e localizar em quais chunks est√£o seus dados.</li>
<li><strong>chunks/</strong>: diret√≥rio contendo os arquivos bin√°rios de chunks de dados. Os <em>chunks</em> s√£o os blocos comprimidos de amostras das s√©ries. Cada arquivo (nomeado como 000001, 000002, &hellip;) cont√©m muitos chunks. O tamanho m√°ximo de cada arquivo √© ~512MB para facilitar gerenciamento.</li>
<li><strong>tombstones:</strong> arquivo que registra intervalos de dados deletados manualmente (via API de delete), se houver.</li>
</ul>
<p>Al√©m dos blocos fechados, existe o <strong><a href="https://prometheus.io/docs/introduction/architecture/#head-block">Head block</a></strong> (bloco atual em mem√≥ria) que armazena as m√©tricas em curso. Os dados mais recentes (√∫ltimas ~2h) residem em mem√≥ria para escrita r√°pida e consultas de curt√≠ssimo prazo. A cada 2h, o Prometheus ‚Äúdissolve‚Äù parte do Head em um bloco persistente e libera daquela mem√≥ria. Vamos inspecionar um exemplo de <strong>meta.json</strong> para entender seus campos:</p>


  <pre><code class="language-json">{
    &#34;ulid&#34;: &#34;01BKGTZQ1SYQJTR4PB43C8PD98&#34;,
    &#34;minTime&#34;: 1602237600000,
    &#34;maxTime&#34;: 1602244800000,
    &#34;stats&#34;: {
        &#34;numSamples&#34;: 553673232,
        &#34;numSeries&#34;: 1346066,
        &#34;numChunks&#34;: 4440437
    },
    &#34;compaction&#34;: {
        &#34;level&#34;: 1,
        &#34;sources&#34;: [
            &#34;01EM65SHSX4VARXBBHBF0M0FDS&#34;,
            &#34;01EM6GAJSYWSQQRDY782EA5ZPN&#34;
        ]
    },
    &#34;version&#34;: 1
}</code></pre>
 <p>Explicando os campos principais:</p>
<ul>
<li><strong>ulid:</strong> Identificador √∫nico do bloco (um c√≥digo 128-bit parecido com <a href="https://en.wikipedia.org/wiki/Universally_unique_identifier">UUID</a>). Ele √© tamb√©m o nome da pasta do bloco.</li>
<li><strong>minTime e maxTime:</strong> Timestamp inicial e final (epoch em milissegundos) cobertos pelos samples deste bloco. No exemplo, corresponde a um intervalo de 2h.</li>
<li><strong>stats:</strong> Estat√≠sticas do bloco ‚Äì quantas amostras (<a href="https://prometheus.io/docs/introduction/architecture/#head-block">numSamples</a>), s√©ries (<a href="https://prometheus.io/docs/introduction/architecture/#head-block">numSeries</a>) e chunks (<a href="https://prometheus.io/docs/introduction/architecture/#head-block">numChunks</a>) est√£o armazenados nele. No exemplo real acima, temos ~1,34 milh√£o de s√©ries distintas, totalizando 553 milh√µes de amostras em ~4,44 milh√µes de chunks dentro desse bloco de 2h. Esses n√∫meros d√£o uma no√ß√£o do volume de dados.</li>
<li><strong>compaction:</strong> Informa o hist√≥rico de compacta√ß√£o. <strong><a href="https://prometheus.io/docs/introduction/architecture/#head-block">level</a></strong> indica quantas vezes j√° foi compactado (1 significa um bloco resultante da jun√ß√£o de outros menores). <strong><a href="https://prometheus.io/docs/introduction/architecture/#head-block">sources</a></strong> lista os IDs dos blocos que foram combinados para formar este (no caso, dois blocos anteriores). Se o bloco foi gerado direto do Head (dados ‚Äúoriginais‚Äù), √†s vezes sources cont√©m ele pr√≥prio.</li>
<li><strong>version:</strong> Vers√£o do formato do bloco/arquivo (para compatibilidade futura).</li>
</ul>
<p>Com isso, entendemos que cada bloco √© imut√°vel depois de escrito. Se novos dados chegam daquele intervalo, seria criado um bloco novo via compaction. Isso facilita a confiabilidade ‚Äì dados hist√≥ricos n√£o mudam.</p>
<p>O <strong>arquivo de √≠ndice (index)</strong> serve para mapear as s√©ries e labels aos chunks dentro do bloco. Ele funciona como um √≠ndice invertido: dado um nome de m√©trica e um conjunto de labels, encontra os IDs das s√©ries correspondentes e, ent√£o, aponta para os chunks onde est√£o os dados daquela s√©rie. Assim, ao fazer uma consulta, o Prometheus carrega o √≠ndice do bloco relevante e consegue buscar rapidamente somente os chunks necess√°rios (por exemplo, pula chunks inteiros que est√£o fora do range de tempo consultado, usando informa√ß√µes de minTime/maxtime dos chunks).</p>
<p>O √≠ndice √© altamente otimizado e comprimido ‚Äì usa conceitos de <a href="https://prometheus.io/docs/introduction/architecture/#posting-lists">posting lists</a> (listas de IDs de s√©ries para cada label-valor) e <a href="https://prometheus.io/docs/introduction/architecture/#symbol-table">tabelas de s√≠mbolos</a> para strings √∫nicas. Esses detalhes avan√ßados fogem do escopo aqui, mas o importante √©: o √≠ndice permite que mesmo com milh√µes de s√©ries por bloco, o Prometheus consiga localizar dados sem varrer tudo linearmente.</p>
<p>Finalmente, o <strong><a href="https://prometheus.io/docs/introduction/architecture/#write-ahead-log">WAL (Write-Ahead Log)</a></strong>: √© um log de transa√ß√µes recente onde cada amostra coletada √© gravada imediatamente no disco antes de ser inserida na mem√≥ria do Head. Isso garante que se o Prometheus cair inesperadamente, ao voltar ele pode reprocessar o WAL e recuperar as amostras que ainda n√£o tinham sido compactadas em blocos. O WAL consiste em arquivos sequenciais (<code>00000000</code>, <code>00000001</code>, etc.) que v√£o acumulando as escritas. Periodicamente, o Prometheus faz um checkpoint (snapshot do head) e limpa parte do WAL j√° aplicado. Em caso de crash, ele l√™ desde o √∫ltimo checkpoint para restaurar o estado do Head.</p>
<h3 id="gerenciamento-de-mem√≥ria-pelo-prometheus">Gerenciamento de mem√≥ria pelo Prometheus</h3>
<p>O Prometheus armazena as s√©ries temporais em mem√≥ria para r√°pido acesso √†s m√©tricas recentes, enquanto grava continuamente os novos dados no disco (WAL) para durabilidade. Isso pode levar a alto uso de RAM e espa√ßo em disco.</p>
<p><img src="https://raw.githubusercontent.com/scovl/scovl.github.io/main/post/images/tsdb/prom-mem02.png" alt=""></p>
<p>Como mencionado, o Prometheus mant√©m em RAM todas as s√©ries ativas do bloco atual (tipicamente √∫ltimas 2 horas de dados por s√©rie). Essa decis√£o arquitetural visa desempenho: consultas sobre dados recentes (que s√£o as mais comuns, e.g. alertas e dashboards de curto prazo) n√£o precisam esperar leitura de disco ‚Äì os valores j√° est√£o na mem√≥ria.</p>
<p>Al√©m disso, novas amostras sendo inseridas a cada segundo/minuto s√£o agregadas a estruturas em mem√≥ria (evitando I/O de disco a cada opera√ß√£o, que seria invi√°vel em alta escala). O resultado √© que o <strong>consumo de RAM</strong> do Prometheus cresce com o n√∫mero de s√©ries ativas e com a frequ√™ncia de coleta. Estima-se, por experi√™ncias reportadas, que cada s√©rie ativa consome em torno de <strong>~3 KB de RAM</strong> (depende de labels, comprimento do nome, etc.). Portanto, 1 milh√£o de s√©ries pode usar na ordem de 3‚Äì4 GB de RAM apenas para manter o head da TSDB.</p>
<p>Em paralelo, o Prometheus escreve todas as amostras no WAL (em disco) para n√£o perd√™-las em caso de crash. A cada 2 horas, ele ent√£o compacta esses dados quentes em um bloco de 2h comprimido e libera a mem√≥ria correspondente. Ou seja, h√° um ciclo onde a mem√≥ria vai sendo ocupada pelas amostras recentes, e de hora em hora (na verdade 2h) h√° um flush para disco que esvazia um pouco a mem√≥ria (mas novas s√©ries podem surgir e ocupar de novo).</p>
<p>O <em>design</em> de manter dados recentes em mem√≥ria traz a consequ√™ncia de que <strong>o uso de RAM aumenta com a carga de m√©tricas e n√£o √© liberado at√© que os blocos sejam fechados ou as s√©ries cessem</strong>. Em per√≠odos de pico (muitas s√©ries novas aparecendo rapidamente), o Prometheus pode chegar a consumir muita mem√≥ria para acompanhar. Se faltar RAM, o processo corre risco de OOM (matar por falta de mem√≥ria) ou, no melhor caso, o sistema operacional vai come√ßar a usar swap ‚Äì o que degrada muito a performance. Na imagem acima, vemos que tanto a RAM quanto o armazenamento em disco podem crescer substancialmente √† medida que aumentamos o volume de dados monitorados.</p>
<blockquote>
<p><strong>Quanto mais dias de reten√ß√£o mantidos no Prometheus, mais recursos s√£o usados e maior o esfor√ßo para consultas longas. Manter dados hist√≥ricos demais pode sobrecarregar a mem√≥ria e o disco, al√©m de dificultar encontrar informa√ß√µes recentes relevantes.</strong></p></blockquote>
<p>Embora possamos configurar reten√ß√µes longas (30, 60 dias), isso n√£o significa que o Prometheus foi otimizado para operar eficientemente com esse hist√≥rico todo localmente. Lembre-se: ele n√£o indexa por data de forma distribu√≠da ‚Äì consultas que abrangem muitos dias ter√£o que ler v√°rios blocos do disco e processar um grande volume de amostras. Na pr√°tica, reter al√©m de algumas semanas come√ßa a tornar as consultas bem lentas e o uso de disco muito alto (sem falar nos backups dessa quantidade de data). A imagem acima ilustra que, √† medida que guardamos mais dias, o custo de recursos cresce e pode inclusive ofuscar tend√™ncias atuais no meio de tanto dado antigo.</p>
<p><img src="https://raw.githubusercontent.com/scovl/scovl.github.io/main/post/images/tsdb/prom-mem03.png" alt=""></p>
<p>A filosofia do Prometheus √© ser a ferramenta de <strong>monitoramento em tempo real</strong> e de curto/m√©dio prazo. Para an√°lises hist√≥ricas longas ou compliance (guardar m√©tricas por 1 ano, por exemplo), a solu√ß√£o comum √© integrar um back-end de longo prazo (Thanos, Cortex, databases remotas) que arquivem esses dados, enquanto o Prometheus local mant√©m s√≥ o necess√°rio para opera√ß√£o/alertas recentes. Assim voc√™ tem o melhor dos dois mundos: rapidez no real-time e hist√≥rico completo dispon√≠vel quando precisar, sem sobrecarregar o Prometheus diariamente.</p>
<blockquote>
<p>Todas as amostras recentes residem na mem√≥ria principal (Head), com flush peri√≥dico para disco a cada 2 horas. O WAL no disco captura as escritas para garantir durabilidade. Em situa√ß√£o de carga extrema, o OS pode usar swap, mas isso deve ser evitado pois degrada o desempenho.</p></blockquote>
<p>Vamos recapitular o ciclo de vida dos dados no Prometheus e seu impacto em mem√≥ria/disco:</p>
<ul>
<li>
<p><strong>Head Block (mem√≥ria):</strong> Novas s√©ries e amostras entram aqui. As s√©ries ativas ocupam estruturas na heap da aplica√ß√£o Go do Prometheus. A cada amostra recebida, ela tamb√©m √© anexada no <strong><a href="https://prometheus.io/docs/introduction/architecture/#write-ahead-log">WAL</a></strong> (no SSD/disco) para registro permanente. Durante at√© ~2h, os dados ficam dispon√≠veis no Head para consultas instant√¢neas. Por isso, consultas e alertas em dados &ldquo;frescos&rdquo; s√£o muito r√°pidas.</p>
</li>
<li>
<p><strong>Flush para bloco persistente:</strong> Quando o intervalo de 2h se completa, o Prometheus corta o bloco (na verdade ele espera 2h ou 1h30 dependendo de certas condi√ß√µes) e escreve um <strong><a href="https://prometheus.io/docs/introduction/architecture/#head-block">novo bloco</a></strong> no diret√≥rio data (contendo aqueles 2h de amostras agora imut√°veis, j√° comprimidas). Em seguida, libera da mem√≥ria boa parte das estruturas referentes √†quele intervalo. O head ent√£o mant√©m somente as s√©ries ainda ativas que extrapolem o pr√≥ximo bloco.</p>
</li>
<li>
<p><strong>Compaction:</strong> Ap√≥s algumas rota√ß√µes de bloco, o Prometheus agrupa blocos menores em blocos maiores (por exemplo, une 5 blocos de 2h em 1 bloco de 10h, e assim por diante). Isso ocorre em segundo plano e ajuda a reduzir o n√∫mero de arquivos e melhorar compress√£o geral. Compaction consome CPU/disk I/O, mas √© intercalado para n√£o interferir muito.</p>
</li>
<li>
<p><strong>Reten√ß√£o e cleanup:</strong> Quando um bloco excede a reten√ß√£o configurada (ex: ficou mais velho que 15 dias), ele √© marcado para dele√ß√£o. A limpeza ocorre periodicamente e remove blocos expirados. Importante: a remo√ß√£o n√£o √© imediata ao passar do prazo ‚Äì o processo de cleanup roda em intervalos (at√© 2h de delay). Durante a limpeza, o Prometheus deleta os diret√≥rios daqueles blocos antigos, liberando espa√ßo em disco.</p>
</li>
<li>
<p><strong>Rein√≠cio e recupera√ß√£o:</strong> Se o Prometheus reiniciar ou cair, na inicializa√ß√£o ele precisa recarregar o estado. Ele vai abrir todos os blocos persistentes (apenas meta e √≠ndice, sem carregar todos os dados) e principalmente processar o WAL para recriar o Head com as amostras que ainda n√£o estavam em bloco. Esse processo de recupera√ß√£o do WAL pode demorar dependendo do tamanho (por isso h√° checkpoint para otimizar). Ao final, o sistema retorna ao estado como se nunca tivesse parado (exceto pelos minutos offline onde dados podem ter se perdido se os alvos n√£o suportam retroativa).</p>
</li>
</ul>
<p>Tudo isso explica por que o Prometheus consome <strong>bastante mem√≥ria</strong>: ele aposta em manter as s√©ries recentes acess√≠veis e indexadas para respostas r√°pidas. Num Prometheus com muitos alvos ou alta cardinalidade (muitas combina√ß√µes de labels), o consumo de RAM pode facilmente ser o principal limitador. Conforme mencionado anteriormente, 1 milh√£o de s√©ries ativas pode exigir v√°rios GB de RAM, portanto planeje a capacidade de acordo com o volume de m√©tricas esperado.</p>
<p>Infelizmente, n√£o h√° muito <strong>tunings</strong> manuais a fazer na mem√≥ria al√©m de reduzir a quantidade de dados: <strong>menos s√©ries ou menor frequ√™ncia de coleta</strong> = menos uso de RAM. O Prometheus n√£o tem um mecanismo interno de shard autom√°tico ou flush mais frequente (o flush √© fixo ~2h por design). Ent√£o, as solu√ß√µes se resumem a <strong>escalar verticalmente</strong> (m√°quinas com mais mem√≥ria, CPU, disco r√°pido) ou <strong>escalar horizontalmente</strong> (dividir a carga entre v√°rios Prometheus, cada um monitorando uma parte das targets). Nas melhores pr√°ticas a seguir, daremos dicas para mitigar esses desafios de desempenho e dimensionamento.</p>
<h2 id="melhores-pr√°ticas">Melhores Pr√°ticas</h2>
<p>Depois de entender a mec√¢nica interna do Prometheus, √© v√°lido reunir algumas recomenda√ß√µes para tirar o melhor proveito da ferramenta de forma escal√°vel e confi√°vel.</p>
<h3 id="planejamento-de-capacidade">Planejamento de Capacidade</h3>
<ul>
<li>
<p><strong>Estime volume de m√©tricas e reten√ß√£o:</strong> Antes de implantar, fa√ßa uma estimativa do n√∫mero de s√©ries que voc√™ vai coletar e defina uma reten√ß√£o condizente. Lembre que por padr√£o s√£o 15 dias. Se n√£o precisar de tudo isso para monitoramento di√°rio, reten√ß√µes menores aliviam recursos. Ao contr√°rio, se precisar de mais tempo hist√≥rico, esteja ciente do aumento de disco e possivelmente avalie armazenamento remoto.</p>
</li>
<li>
<p><strong>Monitore o Prometheus em si:</strong> &ldquo;Quis custodiet ipsos custodes?&rdquo; ‚Äì o Prometheus exp√µe suas pr√≥prias m√©tricas (no endpoint /metrics dele). Use um outro Prometheus ou a mesma inst√¢ncia para monitorar m√©tricas como <code>prometheus_tsdb_head_series</code> (n√∫mero de s√©ries no head), <code>prometheus_tsdb_head_samples_appended_total</code> (samples inseridos por segundo), <code>prometheus_engine_query_duration_seconds</code> (lat√™ncia das consultas), etc. Isso alerta para crescimento de cardinalidade inesperado ou consultas muito pesadas rodando.</p>
</li>
<li>
<p><strong>Dimensione hardware adequadamente:</strong> Regra emp√≠rica: 1 CPU core pode processar aproximadamente at√© 200k amostras por segundo (varia, mas √© uma ideia). Mem√≥ria, calcule ~3kB por s√©rie ativa. Disco: ~1-2 bytes por amostra armazenada comprimida (15 dias, 200 milh√µes de amostras ~ 200-300MB). Use SSDs r√°pidos ‚Äì opera√ß√µes de WAL e blocos beneficiam de I/O r√°pido.</p>
</li>
</ul>
<h3 id="organiza√ß√£o-de-m√©tricas-e-labels">Organiza√ß√£o de M√©tricas e Labels</h3>
<ul>
<li>
<p><strong>Consist√™ncia na nomea√ß√£o:</strong> Siga conven√ß√µes de nomenclatura para facilitar a vida. Use nomes descritivos e padronizados (letras min√∫sculas, separadas por underscores, unidade no sufixo se aplic√°vel: <code>_seconds</code>, <code>_bytes</code>, <code>_total</code> para contadores acumulativos). Por exemplo, prefira <code>app_memory_usage_bytes</code> a algo como <code>MemUsed</code> ou outras varia√ß√µes inconsistentes. Isso ajuda todo mundo a entender do que se trata sem ambiguidade.</p>
</li>
<li>
<p><strong>Labels estrat√©gicos:</strong> Anexe labels que fa√ßam sentido de consulta, mas evite rotular com informa√ß√µes que tenham alta cardinalidade ou unicidade. Um bom label √© algo como <code>region</code>, <code>datacenter</code>, <code>instance</code> (desde que este n√£o seja √∫nico por m√©trica ‚Äì use instance s√≥ onde faz sentido). Maus labels incluem: ID de requisi√ß√£o, nome de usu√°rio, URL completa (em vez de caminho gen√©rico), timestamp, IP din√¢mico de cliente. Esses valores criam um n√∫mero enorme de s√©ries distintas. Lembre-se: cada combina√ß√£o diferente de labels vira <strong>uma s√©rie separada</strong> no TSDB. Se voc√™ tiver 1000 usu√°rios e rotular m√©tricas por usu√°rio, virou 1000 s√©ries onde antes podia ser 1 ou algumas. Leve isso em conta.</p>
</li>
<li>
<p><strong>Explos√£o de cardinalidade:</strong> √â um dos problemas mais comuns. Por exemplo, adicionar um label <code>product_id</code> a uma m√©trica de pedidos, onde product_id pode assumir dezenas de milhares de valores, multiplicar√° as s√©ries. Isso pode levar o Prometheus a consumir toda mem√≥ria e travar. Portanto, s√≥ use labels cujo conjunto de valores poss√≠vel seja <strong>limitado e relativamente pequeno</strong>. (Regra de bolso: algumas dezenas ou poucas centenas de valores diferentes por label no m√°ximo. Mais que isso, pense duas vezes se √© necess√°rio.) Caso precise monitorar algo muito cardinal (ex: m√©tricas por usu√°rio √∫nico), talvez o Prometheus n√£o seja a ferramenta adequada ou voc√™ precisa agreg√°-las antes de expor.</p>
</li>
<li>
<p><strong>M√©tricas altas vs baixas cardinalidades:</strong> Prefira m√©tricas mais agregadas. Por exemplo, em vez de registrar uma m√©trica separada para cada item em fila (que n√£o faz sentido), registre o tamanho da fila como um gauge. Em vez de m√©tricas por sess√£o de usu√°rio, exponha total global ou por categoria de usu√°rio. Enfim, modele os dados de forma a minimizar detalhes desnecess√°rios.</p>
</li>
</ul>
<h3 id="consultas-promql-eficientes">Consultas (PromQL) Eficientes</h3>
<ul>
<li>
<p><strong>Cuidado com fun√ß√µes custosas:</strong> Algumas fun√ß√µes PromQL podem ser muito √∫teis, por√©m custosas. <code>topk()</code> e <code>bottomk()</code>, por exemplo, obrigam o engine a ordenar muitas s√©ries para achar o top N ‚Äì pode ser caro se aplicado numa m√©trica com milhares de s√©ries. Use-as com modera√ß√£o (talvez em queries de background para dashboard, mas evite em alertas cr√≠ticos se poss√≠vel). Similar para agrega√ß√µes sem restri√ß√£o: <code>sum by (label)</code> onde label tem muitos valores, o Prometheus ter√° que materializar todas combina√ß√µes.</p>
</li>
<li>
<p><strong>Use intervalos de tempo adequados:</strong> Querys do tipo <em>[5m]</em>, <em>[1h]</em> etc. definem quanto tempo de dados v√£o considerar. Evite pedir mais do que precisa. Por exemplo, se um alerta precisa saber a taxa nos √∫ltimos 5 minutos, n√£o use 1h. Intervalos maiores = mais dados lidos e processados. Num gr√°fico, tamb√©m n√£o exagere no zoom out se n√£o for necess√°rio ‚Äì muitos dados tornam a renderiza√ß√£o e transmiss√£o pesadas.</p>
</li>
<li>
<p><strong>Prefira <code>rate()</code> ou <code>increase()</code> para contadores ao inv√©s de <code>irate()</code> para alertas cont√≠nuos:</strong> A fun√ß√£o <code>irate()</code> calcula instantaneamente a derivada entre os dois √∫ltimos pontos ‚Äì isso √© √∫til √†s vezes, mas tende a ser muito &ldquo;barulhento&rdquo; (varia√ß√£o instante a instante). Em dashboards e alertas gerais, <code>rate()</code> numa janela de pelo menos 1m ou 5m √© mais est√°vel e representativo da taxa m√©dia. Use <code>irate</code> somente quando quer realmente capturar spikes moment√¢neos e tem alta frequ√™ncia de scrape.</p>
</li>
<li>
<p><strong>Agregue no scraping quando poss√≠vel:</strong> Se voc√™ j√° sabe que nunca vai olhar cada inst√¢ncia individual de certa m√©trica, poderia agreg√°-la antes mesmo de enviar. Exemplo: se voc√™ tem 10 threads fazendo trabalho id√™ntico e s√≥ quer saber o total combinado, exponha uma √∫nica m√©trica total e n√£o 10 separadas. Claro que isso depende do caso de uso ‚Äì muitas vezes queremos o detalhe ‚Äì mas √© algo a pensar.</p>
</li>
<li>
<p><strong>Limite consultas no UI:</strong> O Prometheus permite rodar qualquer PromQL ad-hoc no UI ou via API. Em ambientes compartilhados, controle o acesso ou conscientize os usu√°rios para n√£o rodarem consultas insanas (tipo um sum sem nenhum label em milh√µes de s√©ries por 365d) que possam afetar a performance. Voc√™ pode habilitar autentica√ß√£o/TLS e at√© colocar um proxy com quotas se for necess√°rio proteger a API de uso indevido.</p>
</li>
</ul>
<h3 id="arquitetura-e-escalabilidade">Arquitetura e Escalabilidade</h3>
<ul>
<li>
<p><strong>Sharding (divis√£o de carga):</strong> Se chegar ao ponto de um √∫nico Prometheus n√£o dar conta (seja por limite de CPU/RAM ou por quest√µes organizacionais), considere dividir os alvos entre m√∫ltiplas inst√¢ncias. Por exemplo, rodar um Prometheus por cluster Kubernetes, ou por ambiente (dev/prod), ou por regi√£o geogr√°fica. Cada um monitora s√≥ seu √¢mbito. Voc√™ pode replicar as regras de alertas em todos (assim cada local alerta independentemente). Para m√©tricas globais, use federa√ß√£o ou uma camada agregadora (como Thanos) para unificar se necess√°rio.</p>
</li>
<li>
<p><strong>Alta disponibilidade:</strong> O Prometheus em si n√£o √© HA ‚Äì ele √© stand-alone. Se cair, fica um buraco de coleta enquanto estiver fora. Uma pr√°tica comum em produ√ß√£o √© rodar <strong>dois Prometheus em paralelo coletando os mesmos alvos</strong> (nas mesmas configura√ß√µes) ‚Äì assim, se um falhar, o outro continua e nenhuma m√©trica se perde. O Alertmanager pode receber alertas duplicados de ambos, mas ele deduplica automaticamente (precisa configurar ambos Prometheus com o mesmo external_label cluster). Essa abordagem gasta mais recursos (coleta em dobro), mas √© simples e efetiva para HA de alertas.</p>
</li>
<li>
<p><strong>Longo prazo e agrega√ß√£o global:</strong> Conforme citado, se precisar <em>escalar horizontalmente</em> de verdade ou guardar m√©tricas por longos per√≠odos, vale integrar solu√ß√µes como <strong>Thanos, Cortex ou Grafana Mimir</strong>. Essas ferramentas armazenam dados em base de dados distribu√≠da (por exemplo, S3 ou BigTable no caso do Thanos/Cortex) e permitem rodar consultas PromQL que abrangem m√∫ltiplos Prometheus &ldquo;como se fosse um s√≥&rdquo;. O Thanos, por exemplo, atua como um <em>sidecar</em> pegando os dados de cada Prometheus e enviando para o objeto storage, depois uma camada de <em>querier</em> unifica as consultas. O Grafana Mimir segue arquitetura semelhante, nascida da experi√™ncia do Cortex, permitindo <strong>escala praticamente ilimitada (bilh√µes de s√©ries) e alta disponibilidade</strong>, com compatibilidade total com PromQL e remote write. Claro, adicionam complexidade ‚Äì mas s√£o solu√ß√µes maduras mantidas pela CNCF/Grafana Labs.</p>
</li>
<li>
<p><strong>Federa√ß√£o bem aplicada:</strong> Caso use federa√ß√£o, siga a orienta√ß√£o de federar apenas m√©tricas j√° agregadas e necess√°rias globalmente. Por exemplo, federar s√≥ m√©tricas come√ßando com <code>job:</code> (indicando que s√£o resultados de recording rules j√° agregadas). N√£o federar todas as m√©tricas crus. E realize alertas localmente, deixando o global s√≥ para visualiza√ß√£o.</p>
</li>
</ul>
<h3 id="seguran√ßa">Seguran√ßa</h3>
<ul>
<li>
<p><strong>N√£o exponha sem prote√ß√£o em redes inseguras:</strong> O Prometheus, por padr√£o, n√£o tem autentica√ß√£o nem TLS habilitados. Se voc√™ for disponibilizar a interface ou API em rede p√∫blica ou multi-tenant, coloque-o atr√°s de um proxy reverso que implemente TLS e autentica√ß√£o (b√°sica, OAuth, o que for). Alternativamente, rode em rede interna/VPN somente. H√° flags experimentais para TLS direto e auth no Prometheus, mas a abordagem recomendada ainda √© usar um proxy (por exemplo, Nginx, Traefik, etc).</p>
</li>
<li>
<p><strong>Controle acesso √† API:</strong> Considere habilitar autoriza√ß√£o se for um ambiente com v√°rios usu√°rios ou multi-time. Infelizmente, o Prometheus n√£o suporta m√∫ltiplos n√≠veis de usu√°rio nativamente. A solu√ß√£o costuma ser segregar inst√¢ncias ou novamente um proxy que filtre rotas. Por exemplo, impedir acesso direto ao <code>/api/v1/admin</code> (que possui comandos de dele√ß√£o de dados).</p>
</li>
<li>
<p><strong>Atualiza√ß√µes e patches:</strong> Mantenha o Prometheus atualizado ‚Äì a cada vers√£o h√° otimiza√ß√µes e corre√ß√µes, inclusive de seguran√ßa. E.g., compress√£o de WAL veio ativada por padr√£o na 2.20, reduzindo disco pela metade. Vers√µes mais novas introduziram <em>native histograms</em> (experimental) e melhorias de desempenho. Ent√£o acompanhe o changelog oficial e planeje upgrade regularmente (Prometheus √© bem compat√≠vel retroativamente em dados e configs, upgrades diretos costumam ser tranquilos).</p>
</li>
<li>
<p><strong>Isolamento de rede para exporters:</strong> Exporters muitas vezes exp√µem m√©tricas sens√≠veis (por exemplo, o Node Exporter exp√µe informa√ß√µes de hardware, usu√°rios logados etc.). √â boa pr√°tica deixar esses endpoints acess√≠veis s√≥ pelo Prometheus, n√£o abertos ao mundo. Use firewalls/regras de seguran√ßa nos hosts ou config de container network para limitar.</p>
</li>
<li>
<p><strong>Naming anti-collision:</strong> Se voc√™ usa r√≥tulos <em>externos</em> (external_labels) para identificar inst√¢ncias em um contexto federado ou HA, garanta que cada Prometheus tenha um label √∫nico (e.g., <code>cluster=&quot;eu-west-1&quot;</code>). Isso evita confus√£o de m√©tricas vindas de origens diferentes no caso de jun√ß√£o (Thanos, federa√ß√£o) e ajuda a filtrar.</p>
</li>
</ul>
<p>Seguindo essas pr√°ticas, voc√™ dever√° manter seu ambiente Prometheus funcionando de forma mais suave, evitando as armadilhas comuns de desempenho e garantindo que as m√©tricas coletadas realmente agreguem valor (e alertas disparem quando devem, sem falso positivos ou negativos).</p>
<h2 id="conclus√£o">Conclus√£o</h2>
<p>Neste artigo, exploramos em detalhes o Prometheus ‚Äì desde conceitos fundamentais at√© seu funcionamento interno e implica√ß√µes pr√°ticas de opera√ß√£o. Vimos como ele implementa um banco de dados de s√©ries temporais altamente eficiente, mantendo dados recentes em mem√≥ria para rapidez e usando compress√£o e segmenta√ß√£o em blocos para hist√≥rico em disco. Tamb√©m analisamos aspectos como modelo de coleta pull, linguagem de consulta poderosa, uso intensivo de recursos proporcionais ao volume de m√©tricas, e formas de contornar limita√ß√µes (sejam arquiteturais ou de escala) com boas pr√°ticas e ferramentas auxiliares.</p>
<p>O Prometheus se destaca no ecossistema de monitoramento por sua simplicidade de implanta√ß√£o e por ter sido projetado desde o in√≠cio para ambientes de microsservi√ßos e infraestrutura din√¢mica. Seu modelo multidimensional de m√©tricas com labels e o PromQL possibilitam an√°lises ricas e alertas robustos com relativamente pouco esfor√ßo de configura√ß√£o. √â not√°vel como em poucos anos ele se tornou um dos pilares da observabilidade moderna, ao lado de ferramentas complementares para logs (ELK stack) e <em>tracing</em> (Jaeger, etc.).</p>
<p>Por outro lado, entendemos que o Prometheus n√£o resolve tudo sozinho: reten√ß√£o de longo prazo, alta disponibilidade nativa e escalabilidade horizontal s√£o pontos fora do escopo do core do Prometheus. Em vez de tentar ser distribu√≠do, o projeto optou por interfaces (remote write/read) e pela filosofia de componibilidade ‚Äì cabendo a outras pe√ßas (como Thanos ou Mimir) suprir essas demandas quando necess√°rias. Essa decis√£o de design mant√©m o Prometheus &ldquo;enxuto&rdquo; e confi√°vel, mas significa que para crescer al√©m de certo limite, precisamos arquitetar bem a solu√ß√£o de monitoramento abrangendo outros componentes.</p>
<p>Recapitulando alguns aprendizados chave:</p>
<ul>
<li>Organize bem suas m√©tricas e labels para evitar sobrecarga de cardinalidade.</li>
<li>Monitore o pr√≥prio Prometheus e ajuste a capacidade conforme crescimento.</li>
<li>Use Alertmanager e outras integra√ß√µes para ter um uso completo (coleta, armazenamento, alerta, visualiza√ß√£o).</li>
<li>Em caso de grandes escalas, parta para sharding ou ferramentas de escala distribu√≠da ‚Äì n√£o force um Prometheus √∫nico a fazer trabalho demais.</li>
<li>Leve em conta seguran√ßa e isolamento, pois monitoramento tamb√©m lida com informa√ß√µes sens√≠veis do ambiente.</li>
</ul>
<p>Esperamos que este guia tenha fornecido insights valiosos, tanto para iniciantes entenderem os conceitos do Prometheus quanto para usu√°rios experientes refinarem sua utiliza√ß√£o. Compreender o &ldquo;under the hood&rdquo; do Prometheus ajuda a antecipar comportamentos, otimizar configura√ß√µes e evitar armadilhas comuns na opera√ß√£o di√°ria.</p>
<p>O Prometheus continua em r√°pida evolu√ß√£o (com melhorias na TSDB, novos recursos como Exemplos Exemplares e Native Histograms em teste, etc.), e o ecossistema ao seu redor tamb√©m. Fique atento a atualiza√ß√µes e boas pr√°ticas emergentes ‚Äì a comunidade CNCF e blogs como o <em>Robust Perception</em> regularmente publicam conte√∫dos de alto n√≠vel a respeito. No mais, boas m√©tricas e bons alertas!</p>
<hr>
<h2 id="refer√™ncias">Refer√™ncias</h2>
<ul>
<li><strong>Documenta√ß√£o Oficial do Prometheus</strong> ‚Äì especialmente a <a href="https://prometheus.io/docs/introduction/overview/">Overview</a> , <a href="https://prometheus.io/docs/concepts/metric_types/">Metric Types</a> , <a href="https://prometheus.io/docs/practices/naming/">Best Practices</a> e se√ß√£o de <a href="https://prometheus.io/docs/prometheus/latest/storage/">Storage</a> .</li>
<li><strong>Blog Robust Perception (Brian Brazil)</strong> ‚Äì v√°rias postagens aprofundadas, por exemplo: <a href="https://www.robustperception.io/federation-what-is-it-good-for/">&ldquo;Federation, what is it good for?&rdquo;</a> , <a href="https://www.robustperception.io/how-much-ram-does-prometheus-2-x-need-for-cardinality-and-ingestion/">&ldquo;How much RAM does Prometheus 2.x need&hellip;&rdquo;</a> , <a href="https://www.robustperception.io/using-json-file-service-discovery-with-prometheus">&ldquo;Using JSON file service discovery&rdquo;</a> .</li>
<li><strong>Ganesh Vernekar ‚Äì S√©rie de artigos &ldquo;Prometheus TSDB&rdquo;</strong> ‚Äì <em>Parts 1-7</em> no blog do Ganesh (engenheiro Grafana Labs) detalhando a fundo a arquitetura do TSDB. Em especial, <a href="https://ganeshvernekar.com/blog/prometheus-tsdb-persistent-block-and-its-index/">Parte 4: Blocos persistentes e √çndice</a> .</li>
<li><strong>Livro &ldquo;Prometheus Up &amp; Running&rdquo; (O&rsquo;Reilly, 2019)</strong> ‚Äì de Brian Brazil, √≥tima introdu√ß√£o abrangendo do b√°sico a casos avan√ßados.</li>
<li><strong>Livro &ldquo;The Prometheus Book&rdquo; de James Turnbull</strong> ‚Äì guia pr√°tico cobrindo instala√ß√£o, instrumenta√ß√£o e alertas (dispon√≠vel online).</li>
<li><strong>Hands-On Infrastructure Monitoring with Prometheus</strong> (Packt) ‚Äì livro focado em exemplos pr√°ticos de uso do Prometheus em cen√°rios reais.</li>
<li><strong>Monitoring Microservices and Containerized Applications</strong> (Apress) ‚Äì aborda Prometheus em contexto de microsservi√ßos/Kubernetes.</li>
<li><strong>Comparativos Prometheus vs. outras ferramentas:</strong> Artigos como <em>&ldquo;Prometheus vs. ELK&rdquo;</em>, <em>&ldquo;Prometheus vs. Grafana Mimir (Cortex)&rdquo;</em>, e posts do blog da BetterStack sobre melhores pr√°ticas.</li>
<li><strong>Grafana Mimir</strong> ‚Äì <a href="https://grafana.com/oss/mimir/">P√°gina oficial</a>  e an√∫ncio do lan√ßamento em 2022, mostrando como escalar Prometheus para 1 bilh√£o de s√©ries.</li>
<li><strong>Datadog e New Relic</strong> ‚Äì documenta√ß√µes e sites oficiais para entender ofertas de monitoramento propriet√°rias integradas (APM, Logs, etc.), √∫til para ver diferen√ßas de escopo.</li>
<li><strong>Nagios/Core e Zabbix</strong> ‚Äì documenta√ß√£o e comunidade, para contexto hist√≥rico de monitoramento (foco em disponibilidade, sem TSDB nativo).</li>
<li><strong>ELK Stack</strong> ‚Äì docs Elastic e blogs de terceiros comparando com Prometheus (focando que ELK √© logs e Prometheus m√©tricas).</li>
<li><strong>CNCF Observability Landscape</strong> ‚Äì projetos e ferramentas relacionadas, para quem quiser explorar al√©m (OpenTelemetry, Fluentd, etc.).</li>
</ul>

    </div>
    
    


<div class="post-comments">
    <h3>Coment√°rios</h3>
    <div id="disqus_thread"></div>
    <script>
        var disqus_config = function () {
            this.page.url = 'http:\/\/localhost:1313\/2023\/03\/21\/prometheus\/';
            this.page.identifier = '\/2023\/03\/21\/prometheus\/';
            this.page.title = 'Prometheus';
        };
        (function() {
            var d = document, s = d.createElement('script');
            s.src = 'https://lobocode.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();
    </script>
    <noscript>Por favor, habilite JavaScript para ver os coment√°rios do <a href="https://disqus.com/?ref_noscript">Disqus</a>.</noscript>
</div>
 
</article>

        </div>
    </main>
    
    
    
    <footer class="footer">
    <div class="container">
        <div class="footer-content">
            <div class="footer-links">
                
                <a href="https://github.com/scovl" target="_blank" rel="noopener noreferrer" class="footer-link">
                    GitHub
                </a>
                
                
                
                <a href="https://linkedin.com/in/vitor-lobo" target="_blank" rel="noopener noreferrer" class="footer-link">
                    LinkedIn
                </a>
                
                
                
                <a href="mailto:lobocode@gmail.com" class="footer-link">
                    Email
                </a>
                

                
                <a href="https://hachyderm.io/@lobocode" target="_blank" rel="noopener noreferrer" class="footer-link">
                    Mastodon
                </a>
                

                
                <a href="https://scovl.github.io/index.xml" target="_blank" rel="noopener noreferrer" class="footer-link">
                    RSS
                </a>
                
            </div>
            
            <div class="copyright">
                &copy; 2025 Vitor Lobo
            </div>
        </div>
    </div>
</footer> 
    
    
    
    <script src="/js/main-minimal.js"></script>
    
    
    
</body>
</html> 